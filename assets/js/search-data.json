{
  
    
        "post0": {
            "title": "Russian - Fastbook Chapter 8 questionnaire solutions",
            "content": "Ответы на русском языке на вопросы к восьмой части курса Deep Learning 2020 на Fast.ai. Если есть притензии к переводу, как и к осталььным частям прошу писать в коментариях - поправлю. . 1. Какую проблему решает коллаборативная фильтрация? . Она решает задачу прогнозирования интересов пользователей на основе интересов других пользователей и рекомендации на основе этих интересов. . 2. Как она работает? . Ключевая идея коллаборативной фильтрации-скрытые (латентные) факторы. Идея заключается в том, что модель может сказать, какие предметы вам могут понравиться (например, вам нравятся научно-фантастические фильмы/книги), и эти факторы изучаются (с помощью базового градиентного спуска) на основе того, какие предметы нравятся другим пользователям со схожими интересами. . 3. Почему прогностическая модель коллаборативной фильтрации может быть не очень полезной рекомендательной системой? . Если для обучения модели не так много рекомендаций или не достаточно данных о пользователе, чтобы дать полезные рекомендации, то такие системы коллаборативной фильтрации могут оказаться бесполезными. . 4. Как выглядит перекрестное представление данных совместной фильтрации? . В представлении перекрестной таблицы пользователи и элементы представляют собой строки и столбцы (или наоборот) большой матрицы со значениями, заполненными на основе рейтинга элемента выставленного пользователем. . 5. Напишите код для создания перекрестного представления данных MovieLens (возможно, вам придется выполнить некоторый поиск в интернете!) . Выполняется самостоятельно. . 6. Что такое латентный фактор? Почему он “латентный”? . Как описано выше, латентный фактор - это факторы, которые важны для прогнозирования рекомендаций, но явно не указаны модели, а вместо этого исследованы (отсюда и “латентные”). . 7. Что такое скалярное произведение? Вычислить скалярное произведение вручную с использованием чистого питона и списков. . Скалярное произведение - это когда вы умножаете соответствующие элементы двух векторов и складываете их. Если мы представим векторы в виде списков одинакового размера, то вот как мы можем выполнить скалярное произведение: . a = [1, 2, 3, 4] b = [5, 6, 7, 8] dot_product = sum(i[0]*i[1] for i in zip(a,b)) . 8. Что делает pandas.DataFrame.merge? . Он позволяет объединять несколько DataFrame в один. . 9. Что такое матрица эмбедингов? . Это то, что вы получаете через умножение и в случае совместной фильтрации изучаете. . 10. Какова связь между эмбедингом и матрицей one-hot encoded векторов? . Эмбединг - это матрица one-hot encoded векторов, которая в вычислительном отношении более эффективна. . 11. Зачем нам нужен эмбендинг, если мы можем использовать one-hot encoded векторы для того же самого? . Вычислительная эфективность эмбендинга более эфективна. Умножение с помощью one-hot encoded векторов эквивалентно индексации в эмбендинг матрице, что делает эмбендинг слой. Однако градиент вычисляется таким образом, что он эквивалентен умножению с one-hot encoded вектором. . 12. Что содержит эмбендинг перед началом обучения (предполагая, что мы не используем предварительно обученную модель)? . Эмбендинг инициализируется случайным образом. . 13. Создайте класс (по возможности не подглядывая!) и используйте его. . Делать это должен читатель. Пример в главе: . class Example: def __init__(self, a): self.a = a def say(self,x): return f&#39;Hello {self.a}, {x}.&#39; . 14. Что возвращает x[:,0]? . Идентификаторы пользователей . 15. Перепишите класс DotProduct (по возможности не подглядывая!) и обучите с его помощью модель. . Код, приведенный в главе: . class DotProduct(Module): def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)): self.user_factors = Embedding(n_users, n_factors) self.movie_factors = Embedding(n_movies, n_factors) self.y_range = y_range def forward(self, x): users = self.user_factors(x[:,0]) movies = self.movie_factors(x[:,1]) return sigmoid_range((users * movies).sum(dim=1), *self.y_range) . 16. Какая неплохая функция потерь используется для MovieLens? Почему? . Мы можем использовать среднеквадратичную ошибку (MSE), которая является вполне разумной потерей, поскольку у нас в качестве целей используются количественные значения, и данная ошибка позволяет получить точность модели. . 17. Что произойдет, если мы используем CrossEntropy потери в MovieLens? Как нам нужно будет изменить модель? . Нам нужно было бы обеспечить, чтобы модель выводила 5 прогнозов. Например, с помощью нейросетевой модели нам нужно изменить последний линейный слой, чтобы вывести 5, а не 1, предсказаний. Затем они передаются в CrossEntropy потери. . 18. Что есть использование предвзятости в модели скалярного умножения? . Предвзятость компенсирует тот факт, что некоторые фильмы просто потрясающие или довольно плохие. Это также компенсирует пользователей, которым свойственно давать больше положительных или отрицательных рекомендаций в целом. . 19. Как еще называется понижение веса? . L2 регуляризация. . 20. Напишите уравнение для снижения веса (не подглядывая!) . loss_with_wd = loss + wd * (parameters**2).sum() . 21. Напишите уравнение для градиента снижения веса. Почему он работает? . Добавим к градиентам 2*wd*parameters. Это помогает создавать небольшие, менее неровные/островыпуклые поверхности, которые лучше обобщаются и предотвращают переобучение.,, . 22. Почему уменьшение веса приводит к лучшему обобщению? . Так как оно приведит к более пологим поверхностям, так как более крутые приводят к переобочению. . 23. Что делает argsort в PyTorch? . Получает индексы в том порядке, в котором сортируется исходный тензор в PyTorch. . 24. Дает ли сортировка предубеждений к фильмам тот же результат, что и усреднение в целом рейтингов фильмов? Почему / почему нет? . Нет и есть большое отличие. Предубеждение учитывает жанр, актеров или другие факторы. Например, фильмы с низким значением предубеждения означают, что даже если вам нравятся эти типы фильмов, то вам может все равно не понравиться этот фильм из-за других характеристик. . 25. Как вывести на печать имена и детали слоев в модели? . Просто набрав learn.model . 26. Что такое “проблема начальной загрузки(bootstrapping problem)” в коллаборативной фильтрации? . Что модель / система не может давать никаких рекомендаций или делать какие-либо выводы для пользователей или элементов, о которых она еще не собрала достаточной информации. Это также называется проблемой холодного старта. . 27. Как вы могли бы справиться с проблемой начальной загрузки для новых пользователей? Для новых фильмов? . Вы можете решить эту проблему, придумав среднее подставляемое значение для пользователя или фильма. Или подобрать среднего пользователя/фильм. Кроме того, вы можете задать несколько вопросов, которые помогут инициализировать векторы внедряемых значений для новых пользователей и фильмов. . 28. Как циклы обратной связи могут влиять на системы коллаборативной фильтрации? . Рекомендации могут страдать от предвзятости из-за того, что небольшое количество людей сильно влияет на систему. Например: Очень восторженные поклонники аниме, которые оценивают фильмы гораздо чаще, чем другие, могут заставить систему рекомендовать аниме чаще, чем ожидалось (также и для нелюбителей аниме). . 29. При использовании нейронной сети в коллаборативной фильтрации почему у нас может быть разное количество факторов для фильма и пользователя? . В этом случае мы не берем скалярное произведение, а вместо этого объединяем включаемые матрицы. Поэтому количество факторов может быть разным. . 30. Для чего существует nn.Sequential в модели CollabNN? . Он позволяет нам соединить несколько слоев nn.Module вместе для использования. В этом случае два линейных слоя соединяются вместе, и включения могут быть непосредственно переданы в линейные слои. . 31. Какую модель следует использовать, если мы хотим добавить метаданные о пользователях и элементах или такую информацию, как дата и время, в модель коллабартивной фильтрации? . Мы должны использовать табличную модель, которая обсуждается в следующей главе! .",
            "url": "https://zmey56.github.io/blog//markdown/fastai/russian/deep%20learning/2021/01/17/fastai-chapter6-solution.html",
            "relUrl": "/markdown/fastai/russian/deep%20learning/2021/01/17/fastai-chapter6-solution.html",
            "date": " • Jan 17, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Russian - Solution Lesson 6 on Fast.ai",
            "content": "&#1044;&#1088;&#1091;&#1075;&#1080;&#1077; &#1055;&#1088;&#1086;&#1073;&#1083;&#1077;&#1084;&#1099; &#1057; &#1050;&#1086;&#1084;&#1087;&#1100;&#1102;&#1090;&#1077;&#1088;&#1085;&#1099;&#1084; &#1047;&#1088;&#1077;&#1085;&#1080;&#1077;&#1084; . В предыдущей главе вы познакомились с некоторыми важными практическими приемами обучения моделей на практике. Такие соображения, как выбор скорости обучения и количества эпох, очень важны для получения хороших результатов. . В этой главе мы рассмотрим два других типа проблем компьютерного зрения:многозначную классификацию и регрессию. Первый - это когда вы хотите предсказать более одной метки (а иногда и вовсе ни одной), а второй—когда ваши метки представляют собой одно или несколько чисел (количество, а не категорию). . В процессе будет более глубоко изучаться выходная активация, цели и функции потерь в моделях глубокого обучения. . &#1050;&#1083;&#1072;&#1089;&#1089;&#1080;&#1092;&#1080;&#1082;&#1072;&#1094;&#1080;&#1103; &#1057; &#1053;&#1077;&#1089;&#1082;&#1086;&#1083;&#1100;&#1082;&#1080;&#1084;&#1080; &#1052;&#1077;&#1090;&#1082;&#1072;&#1084;&#1080; . Классификация с несколькими метками относится к проблеме идентификации категорий объектов на изображениях. В классах, которые вы ищете, может быть несколько типов объектов, а может и вовсе не быть объектов. . На практике мы не видели много примеров, когда люди обучали мультиметочные классификаторы для этой цели, но мы очень часто видим, как пользователи и разработчики жалуются на эту проблему. Похоже, что это простое решение совсем не широко понимается и не ценится! Поскольку на практике, вероятно, чаще встречаются некоторые изображения с нулевым совпадением или более чем одним совпадением, мы, вероятно, должны ожидать на практике, что классификаторы с несколькими метками более широко применимы, чем классификаторы с одной меткой. . Сначала давайте посмотрим, как выглядит набор данных с несколькими метками, а затем объясним, как подготовить его для нашей модели. Вы увидите, что архитектура модели не изменилась по сравнению с предыдущей главой; изменилась только функция потерь. Начнем с данных. . &#1044;&#1072;&#1085;&#1085;&#1099;&#1077; . В нашем примере мы будем использовать набор данных PASCAL, который может содержать более одного вида классифицируемых объектов на изображение. . Мы начинаем с загрузки и извлечения набора данных как обычно: . from fastai.vision.all import * path = untar_data(URLs.PASCAL_2007) . Этот набор данных отличается от тех, которые мы видели раньше, тем, что они не структурирован по имени файла или папке, а вместо этого предоставляются CSV-файлом (значения, разделенные запятыми), сообщающим нам, какие метки использовать для каждого изображения. Мы можем проверить CSV-файл, прочитав его в DataFrame Pandas: . df = pd.read_csv(path/&#39;train.csv&#39;) df.head() . fname labels is_valid . 0 000005.jpg | chair | True | . 1 000007.jpg | car | True | . 2 000009.jpg | horse person | True | . 3 000012.jpg | car | False | . 4 000016.jpg | bicycle | True | . Как вы можете видеть, список категорий на каждом изображении отображается в виде строки, разделенной пробелами. . Sidebar: Pandas &#1080; DataFrames . Нет, на самом деле это не панда! Pandas-это библиотека Python, которая используется для обработки и анализа табличных данных и данных временных рядов. Основным классом является DataFrame, который представляет собой таблицу состоящую из строк и столбцов. Вы можете получить DataFrame из CSV-файла, таблицы базы данных, словарей Python и многих других источников. В Jupiter DataFrame выводится в виде форматированной таблицы, как показано здесь. . Вы можете получить доступ к строкам и столбцам DataFrame с помощью свойства iloc, как если бы это была матрица: . df.iloc[:,0] . 0 000005.jpg 1 000007.jpg 2 000009.jpg 3 000012.jpg 4 000016.jpg ... 5006 009954.jpg 5007 009955.jpg 5008 009958.jpg 5009 009959.jpg 5010 009961.jpg Name: fname, Length: 5011, dtype: object . df.iloc[0,:] # Trailing :s are always optional (in numpy, pytorch, pandas, etc.), # so this is equivalent: df.iloc[0] . fname 000005.jpg labels chair is_valid True Name: 0, dtype: object . Вы также можете получить столбец по имени, непосредственно индексируя DataFrame: . df[&#39;fname&#39;] . 0 000005.jpg 1 000007.jpg 2 000009.jpg 3 000012.jpg 4 000016.jpg ... 5006 009954.jpg 5007 009955.jpg 5008 009958.jpg 5009 009959.jpg 5010 009961.jpg Name: fname, Length: 5011, dtype: object . tmp_df = pd.DataFrame({&#39;a&#39;:[1,2], &#39;b&#39;:[3,4]}) tmp_df . a b . 0 1 | 3 | . 1 2 | 4 | . tmp_df[&#39;c&#39;] = tmp_df[&#39;a&#39;]+tmp_df[&#39;b&#39;] tmp_df . a b c . 0 1 | 3 | 4 | . 1 2 | 4 | 6 | . &#1055;&#1086;&#1089;&#1090;&#1088;&#1086;&#1077;&#1085;&#1080;&#1077; DataBlock . Как мы преобразуем объект DataFrame в объект DataLoaders? Обычно мы предлагаем использовать API блока данных для создания объекта DataLoaders, где это возможно, поскольку он обеспечивает хорошее сочетание гибкости и простоты. Здесь мы покажем вам шаги, которые мы предпринимаем, чтобы использовать API блоков данных для построения объекта DataLoaders на практике, используя этот набор данных в качестве примера. . Как мы уже видели, PyTorch и fastai имеют два основных класса для представления и доступа к обучающему набору или набору проверки: . Dataset:: Коллекция, которая возвращает кортеж вашей независимой и зависимой переменной для одного элемента | DataLoader:: Итератор, который обеспечивает поток мини-пакетов, где каждый мини-пакет является кортежем пакета независимых переменных и пакета зависимых переменных | . Кроме того, fastai предоставляет два класса для объединения ваших обучающих и проверочных наборов: . Datasets:: Объект, содержащий обучающий набор данных и проверочный набор данных | DataLoaders:: Объект, содержащий обучающий загрузчик данных и загрузчик данных проверки | . Поскольку DataLoader строится поверх Dataset и добавляет к нему дополнительные функции (сортировка нескольких элементов в мини-пакет), часто проще всего начать с создания и тестирования Datasets, а затем посмотреть на DataLoaders после того, как они заработают. . Когда мы создаем DataBlock, мы создаем его постепенно, шаг за шагом, и используем блокнот для проверки ваших данных. Это отличный способ убедиться, что вы следите за любыми проблемами. Легко отлаживать, потому что вы знаете, что если возникает проблема, то она находится в строке кода, который вы только что набрали! . Начнем с простейшего случая, который представляет собой блок данных, созданный без параметров: . dblock = DataBlock() . Из этого мы можем создать объект Datasets. Единственное, что нужно, - это источник-в данном случае наш DataFrame: . dsets = dblock.datasets(df) . Он содержит тренировочный и проверочный набор данных, который мы можем индексировать: . len(dsets.train),len(dsets.valid) . (4009, 1002) . x,y = dsets.train[0] x,y . (fname 008663.jpg labels car person is_valid False Name: 4346, dtype: object, fname 008663.jpg labels car person is_valid False Name: 4346, dtype: object) . Как вы можете видеть, возвращается строка DataFrame дважды. Это происходит потому, что по умолчанию блок данных предполагает, что у нас есть две вещи: входные данные и целевые значения. Нам нужно будет получить соответствующие поля из DataFrame, что мы можем сделать, передав функции get_x и get_y: . x[&#39;fname&#39;] . &#39;008663.jpg&#39; . dblock = DataBlock(get_x = lambda r: r[&#39;fname&#39;], get_y = lambda r: r[&#39;labels&#39;]) dsets = dblock.datasets(df) dsets.train[0] . (&#39;005620.jpg&#39;, &#39;aeroplane&#39;) . Как вы можете видеть, вместо того, чтобы определять функцию обычным способом, мы используем ключевое слово Python lambda. Это просто кратчайший путь для определения и последующей ссылки на функцию. Следующий более подробный подход идентичен: . def get_x(r): return r[&#39;fname&#39;] def get_y(r): return r[&#39;labels&#39;] dblock = DataBlock(get_x = get_x, get_y = get_y) dsets = dblock.datasets(df) dsets.train[0] . (&#39;002549.jpg&#39;, &#39;tvmonitor&#39;) . Лямбда-функции отлично подходят для быстрой итерации, но они несовместимы с сериализацией, поэтому мы советуем вам использовать более подробный подход, если вы хотите экспортировать своего Learner после обучения (лямбды хороши, если вы просто экспериментируете). . Мы видим, что независимая переменная должна быть преобразована в полный путь, чтобы мы могли открыть ее как изображение, а зависимая переменная должна быть разделена символом пробела( который используется по умолчанию для функции разделения Python), чтобы она стала списком: . def get_x(r): return path/&#39;train&#39;/r[&#39;fname&#39;] def get_y(r): return r[&#39;labels&#39;].split(&#39; &#39;) dblock = DataBlock(get_x = get_x, get_y = get_y) dsets = dblock.datasets(df) dsets.train[0] . (Path(&#39;/storage/data/pascal_2007/train/002844.jpg&#39;), [&#39;train&#39;]) . Чтобы действительно открыть изображение и выполнить преобразование его в тензоры, нам нужно будет использовать набор преобразований, которые нам предоставляют. Мы можем использовать те же типы блоков, что и раньше, за одним исключением: ImageBlock снова будет работать нормально, потому что у нас есть путь, который указывает на допустимое изображение, но CategoryBlock не будет работать. Проблема в том, что блок возвращает одно целое число, но нам нужно иметь возможность иметь несколько меток для каждого элемента. Чтобы решить эту проблему, мы используем MultiCategoryBlock. Этот тип блока ожидает получить список строк, как и в данном случае, поэтому давайте проверим его: . dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock), get_x = get_x, get_y = get_y) dsets = dblock.datasets(df) dsets.train[0] . (PILImage mode=RGB size=500x375, TensorMultiCategory([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])) . Как вы можете видеть, наш список категорий не закодирован таким же образом, как это было для обычного блока категорий. В том случае у нас было одно целое число, представляющее, какая это категория, основываясь на ее местоположении в нашем vocab. В этом случае, однако, у нас вместо этого есть список нулей с единицей. Например, если есть единица во второй и четвертой позициях, то это означает, что элементы vocab под номером два и четыре присутствуют на этом изображении. Это известно как one-hot encoding. Причина, по которой мы не можем просто использовать список индексов категорий, заключается в том, что каждый список будет иметь разную длину, а PyTorch требует тензоров одинаковой длины. . Давайте проверим, что представляют собой категории для этого примера (мы используем удобную функцию torch.where, которая возращает нам все индексы, где наше условие истинно или ложно): . idxs = torch.where(dsets.train[0][1]==1.)[0] dsets.train.vocab[idxs] . (#1) [&#39;dog&#39;] . С массивами NumPy, тензорами PyTorch и классом L fastai мы можем индексировать непосредственно с помощью списка или вектора, что делает большой код (например, этот пример) гораздо более ясным и кратким. . До сих пор мы игнорировали столбец is_valid, что означает, что блок данных по умолчанию использует случайное разделение. Чтобы явно выбрать элементы нашего набора проверки, нам нужно написать функцию и передать ее splitter (или использовать одну из предопределенных функций или классов fastai). Он будет принимать элементы (здесь весь наш фрейм данных) и должен возвращать два (или более) списка целых чисел: . def splitter(df): train = df.index[~df[&#39;is_valid&#39;]].tolist() valid = df.index[df[&#39;is_valid&#39;]].tolist() return train,valid dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock), splitter=splitter, get_x=get_x, get_y=get_y) dsets = dblock.datasets(df) dsets.train[0] . (PILImage mode=RGB size=500x333, TensorMultiCategory([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])) . Как мы уже обсуждали, DataLoader собирает элементы из Dataset в мини-пакет. Это кортеж тензоров, где каждый тензор просто куча элементов из местоположений в элементе Dataset. . Теперь, когда мы убедились, что отдельные элементы выглядят нормально, нам нужно сделать еще один шаг, чтобы убедиться, что мы можем создать наши DataLoaders, а именно убедиться, что каждый элемент имеет одинаковый размер. Для этого мы можем использовать RandomResizedCrop: . dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock), splitter=splitter, get_x=get_x, get_y=get_y, item_tfms = RandomResizedCrop(128, min_scale=0.35)) dls = dblock.dataloaders(df) . И теперь мы можем показать элемент наших данных: . dls.show_batch(nrows=1, ncols=3) . Помните, что если что-то пойдет не так при создании DataLoaders из вашего DataBlock или если вы хотите точно увидеть, что происходит с вашим DataBlock, вы можете использовать метод краткого изложения, который мы представили в предыдущей главе. . Наши данные теперь готовы для обучения модели. Как мы увидим, ничего не изменится, когда мы создадим нашего Learner, но за кулисами fastai библиотека выберет для нас новую функцию потерь: двоичную кросс-энтропию. . &#1041;&#1080;&#1085;&#1072;&#1088;&#1085;&#1072;&#1103; &#1082;&#1088;&#1086;&#1089;&#1089;-&#1101;&#1085;&#1090;&#1088;&#1086;&#1087;&#1080;&#1103; . Теперь создадим нашего Learner. . learn = cnn_learner(dls, resnet18) . Мы также знаем, что модель в Learner, как правило, является объектом класса, наследуемого от nn.Module, и что мы можем вызвать его с помощью скобок, и он будет возвращать активации модели. Вы должны передать ему свою независимую переменную, как мини-пакет. Мы можем попробовать его, взяв мини-пакет из нашего загрузчика данных, а затем передав его модели: . x,y = to_cpu(dls.train.one_batch()) activs = learn.model(x) activs.shape . torch.Size([64, 20]) . Подумайте о том, почему activs имеет такую форму—у нас есть размер пакета 64, и нам нужно рассчитать вероятность каждой из 20 категорий. Вот как выглядит одна из этих активаций: . activs[0] . tensor([ 0.7476, -1.1988, 4.5421, -1.5915, -0.6749, 0.0343, -2.4930, -0.8330, -0.3817, -1.4876, -0.1683, 2.1547, -3.4151, -1.1743, 0.1530, -1.6801, -2.3067, 0.7063, -1.3358, -0.3715], grad_fn=&lt;SelectBackward&gt;) . Данные еще не масштабированы до 0 и 1 . def binary_cross_entropy(inputs, targets): inputs = inputs.sigmoid() return -torch.where(targets==1, inputs, 1-inputs).log().mean() . Обратите внимание, что поскольку у нас есть one-hot-encoded зависимая переменная, мы не можем напрямую использовать nll_loss или softmax (и поэтому мы не можем использовать cross_entropy): . softmax, как мы знаем, требует, чтобы сумма всех предсказаний равнялась 1 и за счет использования exp значительно выделяет одну активацию из других. Однако у нас вполне может быть несколько объектов, которые имеются на изображении, поэтому ограничение максимальной суммы активаций до 1 не является хорошей идеей. Исходя из того же рассуждения, мы также можем хотеть, чтобы сумма была меньше 1, если мы не уверены что какая то категория появиться на изображении. | nll_loss, как мы знаем, возвращает значение только одной активации: единственной активации, соответствующей одной метке для элемента. Это не имеет смысла, когда у нас есть несколько категорий. | . С другой стороны, функция binary_cross_entropy, которая является просто mnist_loss вместе с log, обеспечивает именно то, что нам нужно, благодаря магии элементарных операций PyTorch. Каждая активация будет сравниваться с каждой целью для каждого столбца, поэтому нам не нужно ничего делать, чтобы заставить эту функцию работать для нескольких столбцов. . Python уже предоставляет нам эту функцию. На самом деле, он предоставляет ряд версий, с довольно запутанными названиями! . F.binary_cross_entropy и его модульный эквивалент nn.BCELoss вычисляют кросс-энтропию для одной one-hot-encoded цели, но не включают начальную сигмоиду. Обычно для one-hot-encoded целей вы захотите F.binary_cross_entropy_with_logits (или НН.BCEWithLogitsLoss), которые выполняют как сигмоидную, так и двоичную кросс-энтропию в одной функции, как в предыдущем примере. . Эквивалентом для наборов данных с одной меткой (например, MNIST или Pet dataset), где цель кодируется как одно целое число, является F.nll_loss или nn.NLLLoss для версии без начального softmax и F.cross_entropy или nn.CrossEntropyLoss для версии с начальным softmax. . Поскольку у нас есть цель с one-hot-encoded кодированием, мы будем использовать BCEWithLogitsLoss . loss_func = nn.BCEWithLogitsLoss() loss = loss_func(activs, y) loss . TensorMultiCategory(1.0342, grad_fn=&lt;AliasBackward&gt;) . На самом деле нам не нужно указывать fastai, что необходимо использовать эту функцию потерь (хотя мы можем, если захотим), так как она установлена автоматически. fastai знает, что DataLoaders имеют многокатегориальные метки, поэтому по умолчанию он будет использовать nn.BCEWithLogitsLoss. . Одно изменение по сравнению с предыдущей главой-это метрика, которую мы используем: поскольку это проблема с несколькими метками, мы не можем использовать функцию точности. Почему это? Ну, точность сравнивала наши результаты с нашими целями следующим образом: . def accuracy(inp, targ, axis=-1): &quot;Compute accuracy with `targ` when `pred` is bs * n_classes&quot; pred = inp.argmax(dim=axis) return (pred == targ).float().mean() . Предсказанный класс был тем, у кого была самая высокая активация (это то, что делает argmax). Здесь это не работает, потому что у нас может быть более одного предсказания на одном изображении. После применения сигмоиды к нашим активациям (чтобы сопоставить их между 0 и 1), нам нужно решить, какие из них являются 0, а какие 1 за счет порога. Каждое значение выше порога будет рассматриваться как 1, а каждое значение ниже порога будет считаться 0: . def accuracy_multi(inp, targ, thresh=0.5, sigmoid=True): &quot;Compute accuracy when `inp` and `targ` are the same size.&quot; if sigmoid: inp = inp.sigmoid() return ((inp&gt;thresh)==targ.bool()).float().mean() . Если мы передадим accuracy_multi непосредственно в качестве метрики, она будет использовать значение по умолчанию для порога, которое равно 0,5. Возможно мы захотим изменить это значение по умолчанию и создать новую версию accuracy_multi, которая имеет другое значение по умолчанию. Чтобы помочь в этом, в Python есть функция, называемая partial. Это позволяет нам связать функцию с некоторыми аргументами, создавая новую версию этой функции, которая, когда бы она ни вызывалась, всегда включает эти аргументы. Например, вот простая функция, принимающая два аргумента: . def say_hello(name, say_what=&quot;Hello&quot;): return f&quot;{say_what} {name}.&quot; say_hello(&#39;Jeremy&#39;),say_hello(&#39;Jeremy&#39;, &#39;Ahoy!&#39;) . (&#39;Hello Jeremy.&#39;, &#39;Ahoy! Jeremy.&#39;) . Мы можем переключиться на французскую версию этой функции с помощью partial: . f = partial(say_hello, say_what=&quot;Bonjour&quot;) f(&quot;Jeremy&quot;),f(&quot;Sylvain&quot;) . (&#39;Bonjour Jeremy.&#39;, &#39;Bonjour Sylvain.&#39;) . Теперь мы можем тренировать нашу модель. Давайте попробуем установить порог точности для нашей метрики равным 0,2: . learn = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2)) learn.fine_tune(3, base_lr=3e-3, freeze_epochs=4) . epoch train_loss valid_loss accuracy_multi time . 0 | 0.940148 | 0.697462 | 0.236952 | 00:12 | . 1 | 0.822964 | 0.557433 | 0.286056 | 00:12 | . 2 | 0.602061 | 0.198278 | 0.833446 | 00:12 | . 3 | 0.358782 | 0.123523 | 0.944383 | 00:12 | . epoch train_loss valid_loss accuracy_multi time . 0 | 0.130395 | 0.112252 | 0.949342 | 00:14 | . 1 | 0.116924 | 0.105566 | 0.952171 | 00:14 | . 2 | 0.097506 | 0.101672 | 0.951912 | 00:14 | . Выбор порога очень важен. Если вы выберете слишком низкий порог, вы часто не сможете выбрать правильно объекты. Мы можем увидеть это, изменив нашу метрику, а затем вызвав validate, который возвращает ошибку проверки и метрики: . learn.metrics = partial(accuracy_multi, thresh=0.1) learn.validate() . (#2) [0.10167204588651657,0.9306574463844299] . Если вы выберете слишком высокий порог, вы будете получать только те объекты, для которых ваша модель очень уверена: . learn.metrics = partial(accuracy_multi, thresh=0.99) learn.validate() . (#2) [0.10167204588651657,0.9425497055053711] . Мы можем найти лучший порог, попробовав несколько уровней и увидев, что работает лучше всего. Это намного быстрее, если мы просто возьмем предсказания один раз: . preds,targs = learn.get_preds() . Тогда мы можем вызвать метрику напрямую. Обратите внимание, что по умолчанию get_press применяет для нас результирующую функцию активации (в данном случае сигмоида), поэтому нам нужно будет сказать accuracy_multi, чтобы он ее не применял: . accuracy_multi(preds, targs, thresh=0.9, sigmoid=False) . TensorMultiCategory(0.9574) . Теперь мы можем использовать этот подход для поиска наилучшего порогового уровня: . xs = torch.linspace(0.05,0.95,29) accs = [accuracy_multi(preds, targs, thresh=i, sigmoid=False) for i in xs] plt.plot(xs,accs); . В этом случае мы используем проверочный набор для выбора гиперпараметра (порога), который является его задачей. Иногда студенты выражают озабоченность тем, что мы, возможно, можем переобучить проверочный набор, поскольку мы пробуем множество значений, чтобы увидеть, какое из них является лучшим. Однако, как вы видите на графике, изменение порога в этом случае приводит к плавной кривой, поэтому мы явно не выбираем какой-то неуместный выброс. Это хороший пример того, где вы должны быть осторожны с различием между теорией (не пытайтесь использовать много значений гиперпараметров, иначе вы можете переобучить) и практикой (если связь гладкая, то это нормально). . На этом заканчивается часть этой главы, посвященная классификации с несколькими метками. Далее мы рассмотрим проблему регрессии. . &#1056;&#1077;&#1075;&#1088;&#1077;&#1089;&#1089;&#1080;&#1103; . Легко представить себе, что модели глубокого обучения делятся на такие области, как компьютерное зрение, НЛП и так далее. И действительно, именно так fastai классифицирует свои приложения-в основном потому, что именно так большинство людей привыкли думать о вещах. . Но на самом деле за этим скрывается более интересная и глубокая перспектива. Модель определяется ее независимыми и зависимыми переменными, а также функцией потерь. Это означает, что на самом деле существует гораздо более широкий спектр моделей, чем просто разделение на основе области. Возможно, у нас есть независимая переменная, которая является изображением, и зависимая, которая является текстом (например, генерируя подпись из изображения); или, возможно, у нас есть независимая переменная, которая является текстом, и зависимая, которая является изображением (например, генерируя изображение из подписи—что на самом деле возможно для глубокого обучения!); или, возможно, у нас есть изображения, тексты и табличные данные в качестве независимых переменных, и мы пытаемся предсказать покупку продукта... возможности действительно безграничны. . Возможность выйти за рамки фиксированных приложений, чтобы создавать свои собственные новые решения для новых проблем, помогает понять API блоков данных (и, возможно, также API среднего уровня, который мы увидим позже в этой книге). В качестве примера рассмотрим проблему регрессии изображений. Это относится к обучению на основе набора данных, где независимая переменная представляет собой изображение, а зависимая переменная-одно или несколько чисел типа float. Часто мы видим, что люди относятся к регрессии изображений как к целому отдельному приложению, но, как вы увидите здесь, мы можем рассматривать его как просто еще один CNN поверх API блока данных. . Мы сразу перейдем к довольно сложному варианту регрессии изображений, потому что мы знаем, что вы к этому готовы! Мы собираемся сделать модель ключевой точки. Ключевой момент относится к определенному месту, представленному на изображении—в этом случае мы будем использовать изображения людей и будем искать центр лица человека на каждом изображении. Это означает, что мы фактически будем предсказывать два значения для каждого изображения: строку и столбец центра лица. . Assemble the Data . Мы будем использовать Biwi Kinect Head Pose dataset для этого раздела. Начнем с загрузки набора данных как обычно . path = untar_data(URLs.BIWI_HEAD_POSE) . Давайте посмотрим, что у нас есть! . path.ls().sorted() . (#50) [Path(&#39;01&#39;),Path(&#39;01.obj&#39;),Path(&#39;02&#39;),Path(&#39;02.obj&#39;),Path(&#39;03&#39;),Path(&#39;03.obj&#39;),Path(&#39;04&#39;),Path(&#39;04.obj&#39;),Path(&#39;05&#39;),Path(&#39;05.obj&#39;)...] . Есть 24 каталога, пронумерованные от 01 до 24 (они соответствуют разным сфотографированным людям), и соответствующий файл .obj для каждого (они нам здесь не понадобятся). Давайте заглянем в один из этих каталогов: . (path/&#39;01&#39;).ls().sorted() . (#1000) [Path(&#39;01/depth.cal&#39;),Path(&#39;01/frame_00003_pose.txt&#39;),Path(&#39;01/frame_00003_rgb.jpg&#39;),Path(&#39;01/frame_00004_pose.txt&#39;),Path(&#39;01/frame_00004_rgb.jpg&#39;),Path(&#39;01/frame_00005_pose.txt&#39;),Path(&#39;01/frame_00005_rgb.jpg&#39;),Path(&#39;01/frame_00006_pose.txt&#39;),Path(&#39;01/frame_00006_rgb.jpg&#39;),Path(&#39;01/frame_00007_pose.txt&#39;)...] . Внутри подкаталогов у нас есть разные фреймы, каждый из которых поставляется с изображением (_rgb.jpg) и файлом позы (_pose.txt). Мы можем легко получить все файлы изображений рекурсивно с помощью get_image_files, а затем написать функцию, которая преобразует имя файла изображения в связанный с ним файл позы: . img_files = get_image_files(path) def img2pose(x): return Path(f&#39;{str(x)[:-7]}pose.txt&#39;) img2pose(img_files[0]) . Path(&#39;16/frame_00182_pose.txt&#39;) . Давайте взглянем на наше первое изображение: . im = PILImage.create(img_files[0]) im.shape . (480, 640) . im.to_thumb(160) . Веб-сайт набора данных Biwi используется для объяснения формата связи текстового файла post с каждым изображением, который показывает расположение центра головы. Детали этого не важны для наших целей, поэтому мы просто покажем функцию, которую мы используем для извлечения центральной точки головы: . cal = np.genfromtxt(path/&#39;01&#39;/&#39;rgb.cal&#39;, skip_footer=6) def get_ctr(f): ctr = np.genfromtxt(img2pose(f), skip_header=3) c1 = ctr[0] * cal[0][0]/ctr[2] + cal[0][2] c2 = ctr[1] * cal[1][1]/ctr[2] + cal[1][2] return tensor([c1,c2]) . Мы можем передать эту функцию DataBlock как get_y, так как она отвечает за маркировку каждого элемента. Мы изменим размер изображений до половины их входного размера, просто чтобы немного ускорить обучение. . Один важный момент, который следует отметить, заключается в том, что мы не должны просто использовать случайный сплиттер. Причина этого заключается в том, что одни и те же люди появляются на нескольких изображениях в этом наборе данных, но мы хотим убедиться, что наша модель может обобщать людей, которых она еще не видела. Каждая папка в наборе данных содержит изображения для одного человека. Поэтому мы можем создать функцию splitter, которая возвращает true только для одного человека, в результате чего набор проверки содержит только изображения этого человека. . Единственное другое отличие от предыдущих примеров блоков данных состоит в том, что второй блок является точечным блоком. Это необходимо для того, чтобы fastai знал, что метки представляют координаты; таким образом, он знает, что при увеличении данных он должен делать то же самое увеличение для координат, что и для изображений: . get_ctr(img_files[0]) . tensor([324.0023, 251.5637]) . biwi = DataBlock( blocks=(ImageBlock, PointBlock), get_items=get_image_files, get_y=get_ctr, splitter=FuncSplitter(lambda o: o.parent.name==&#39;13&#39;), batch_tfms=[*aug_transforms(size=(240,320)), Normalize.from_stats(*imagenet_stats)] ) . Прежде чем делать какое-либо моделирование, мы должны посмотреть на наши данные, чтобы убедиться, что все в порядке: . dls = biwi.dataloaders(path) dls.show_batch(max_n=9, figsize=(8,6)) . Это выглядит хорошо! Помимо визуального просмотра пакета, неплохо также посмотреть на лежащие в его основе тензоры (особенно если вы студент; это поможет прояснить ваше понимание того, что на самом деле видит ваша модель): . xb,yb = dls.one_batch() xb.shape,yb.shape . ((64, 3, 240, 320), (64, 1, 2)) . Убедитесь, что вы понимаете, почему именно эти формы используются для наших мини-партий. . Вот пример одной строки из зависимой переменной: . yb[0] . TensorPoint([[-0.2811, -0.0472]], device=&#39;cuda:0&#39;) . Как вы можете видеть, нам не нужно было использовать отдельное приложение регрессии изображений; все, что нам нужно было сделать, это пометить данные и сказать fastai, какие типы данных представляют независимые и зависимые переменные. . То же самое относится и к созданию нашего Learner. Мы будем использовать ту же функцию, что и раньше, с одним новым параметром,и будем готовы обучить нашу модель. . &#1054;&#1073;&#1091;&#1095;&#1077;&#1085;&#1080;&#1077; &#1084;&#1086;&#1076;&#1077;&#1083;&#1080; . Как обычно, мы можем использовать cnn_learner для создания нашего ученика. . learn = cnn_learner(dls, resnet18, y_range=(-1,1)) . y_range реализуется в fastai с помощью sigmoid_range, который определяется как: . def sigmoid_range(x, lo, hi): return torch.sigmoid(x) * (hi-lo) + lo . Он устанавливается в качестве конечного слоя модели, если определен y_range. Подумайте о том, что делает эта функция и почему она заставляет модель выводить активации в диапазоне (lo,hi). . plot_function(partial(sigmoid_range,lo=-1,hi=1), min=-4, max=4) . Мы не указали функцию потерь и это означает fastai выбирает по умолчанию. Давайте посмотрим, что он выбрал для нас: . dls.loss_func . FlattenedLoss of MSELoss() . Это имеет смысл, поскольку, когда координаты используются в качестве зависимой переменной, большую часть времени мы, вероятно, пытаемся предсказать что-то как можно более близкое; это в основном то, что делает MSELoss (mean squared error loss). Если вы хотите использовать другую функцию потерь, вы можете передать ее cnn_learner с помощью параметра loss_func. . Обратите внимание также, что мы не указали никаких метрик. Это потому, что MSE уже является необходимой метрикой для этой задачи (хотя она, вероятно, более интерпретируема после того, как мы возьмем квадратный корень). . Мы можем выбрать лучшую скорость обучения с помощью искателя скорости обучения: . learn.lr_find() . SuggestedLRs(lr_min=0.004786301031708717, lr_steep=0.03981071710586548) . Мы попробуем LR 1e-2: . lr = 1e-2 learn.fine_tune(3, lr) . epoch train_loss valid_loss time . 0 | 0.050240 | 0.016628 | 01:12 | . epoch train_loss valid_loss time . 0 | 0.007083 | 0.002008 | 01:30 | . 1 | 0.002808 | 0.000214 | 01:31 | . 2 | 0.001404 | 0.000119 | 01:31 | . Обычно, когда мы запускаем это, мы получаем потерю около 0,0001, что соответствует средней ошибке предсказания координат: . math.sqrt(0.0001) . 0.01 . Это звучит очень точно! Но очень важно взглянуть на наши результаты с помощью Learner.show_results. Левая сторона-это фактические (истинные) координаты, а правая - предсказания нашей модели: . learn.show_results(ds_idx=1, nrows=3, figsize=(6,8)) . Просто удивительно, что всего за несколько минут вычислений мы создали такую точную модель ключевых точек и без какого-либо специального приложения для конкретной области. Это сила построения гибких API и использования трансфертного обучения! Особенно поразительно, что мы смогли так эффективно использовать трансферное обучение даже между совершенно разными задачами; наша предварительно обученная модель была обучена классификации изображений, и мы точно настроились на регрессию изображений. . &#1047;&#1072;&#1082;&#1083;&#1102;&#1095;&#1077;&#1085;&#1080;&#1077; . В задачах, которые на первый взгляд совершенно различны (классификация с одной меткой, классификация с несколькими метками и регрессия), мы в конечном итоге используем одну и ту же модель с разным количеством выходов. Функция потерь-это единственное, что меняется, поэтому важно дважды проверить, что вы используете правильную функцию потерь для своей проблемы. . fastai автоматически попытается выбрать правильный вариант из построенных вами данных, но если вы используете чистый PyTorch для создания своих загрузчиков данных, убедитесь, что вы хорошо проработали вопрос о том, какую функцию потерь, и помните, что вы, скорее всего, захотите: . nn.CrossEntropyLoss для классификации с одной меткой | nn.BCEWithLogitsLoss для классификации с множесством меток | nn.MSELoss для регрессии | .",
            "url": "https://zmey56.github.io/blog//russian/fast.ai/solution/2021/01/17/06-multicat-copy.html",
            "relUrl": "/russian/fast.ai/solution/2021/01/17/06-multicat-copy.html",
            "date": " • Jan 17, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Russian - Solution Lesson 6 on Fast.ai",
            "content": "&#1044;&#1088;&#1091;&#1075;&#1080;&#1077; &#1055;&#1088;&#1086;&#1073;&#1083;&#1077;&#1084;&#1099; &#1057; &#1050;&#1086;&#1084;&#1087;&#1100;&#1102;&#1090;&#1077;&#1088;&#1085;&#1099;&#1084; &#1047;&#1088;&#1077;&#1085;&#1080;&#1077;&#1084; . В предыдущей главе вы познакомились с некоторыми важными практическими приемами обучения моделей на практике. Такие соображения, как выбор скорости обучения и количества эпох, очень важны для получения хороших результатов. . В этой главе мы рассмотрим два других типа проблем компьютерного зрения:многозначную классификацию и регрессию. Первый - это когда вы хотите предсказать более одной метки (а иногда и вовсе ни одной), а второй—когда ваши метки представляют собой одно или несколько чисел (количество, а не категорию). . В процессе будет более глубоко изучаться выходная активация, цели и функции потерь в моделях глубокого обучения. . &#1050;&#1083;&#1072;&#1089;&#1089;&#1080;&#1092;&#1080;&#1082;&#1072;&#1094;&#1080;&#1103; &#1057; &#1053;&#1077;&#1089;&#1082;&#1086;&#1083;&#1100;&#1082;&#1080;&#1084;&#1080; &#1052;&#1077;&#1090;&#1082;&#1072;&#1084;&#1080; . Классификация с несколькими метками относится к проблеме идентификации категорий объектов на изображениях. В классах, которые вы ищете, может быть несколько типов объектов, а может и вовсе не быть объектов. . На практике мы не видели много примеров, когда люди обучали мультиметочные классификаторы для этой цели, но мы очень часто видим, как пользователи и разработчики жалуются на эту проблему. Похоже, что это простое решение совсем не широко понимается и не ценится! Поскольку на практике, вероятно, чаще встречаются некоторые изображения с нулевым совпадением или более чем одним совпадением, мы, вероятно, должны ожидать на практике, что классификаторы с несколькими метками более широко применимы, чем классификаторы с одной меткой. . Сначала давайте посмотрим, как выглядит набор данных с несколькими метками, а затем объясним, как подготовить его для нашей модели. Вы увидите, что архитектура модели не изменилась по сравнению с предыдущей главой; изменилась только функция потерь. Начнем с данных. . &#1044;&#1072;&#1085;&#1085;&#1099;&#1077; . В нашем примере мы будем использовать набор данных PASCAL, который может содержать более одного вида классифицируемых объектов на изображение. . Мы начинаем с загрузки и извлечения набора данных как обычно: . from fastai.vision.all import * path = untar_data(URLs.PASCAL_2007) . Этот набор данных отличается от тех, которые мы видели раньше, тем, что они не структурирован по имени файла или папке, а вместо этого предоставляются CSV-файлом (значения, разделенные запятыми), сообщающим нам, какие метки использовать для каждого изображения. Мы можем проверить CSV-файл, прочитав его в DataFrame Pandas: . df = pd.read_csv(path/&#39;train.csv&#39;) df.head() . fname labels is_valid . 0 000005.jpg | chair | True | . 1 000007.jpg | car | True | . 2 000009.jpg | horse person | True | . 3 000012.jpg | car | False | . 4 000016.jpg | bicycle | True | . Как вы можете видеть, список категорий на каждом изображении отображается в виде строки, разделенной пробелами. . Sidebar: Pandas &#1080; DataFrames . Нет, на самом деле это не панда! Pandas-это библиотека Python, которая используется для обработки и анализа табличных данных и данных временных рядов. Основным классом является DataFrame, который представляет собой таблицу состоящую из строк и столбцов. Вы можете получить DataFrame из CSV-файла, таблицы базы данных, словарей Python и многих других источников. В Jupiter DataFrame выводится в виде форматированной таблицы, как показано здесь. . Вы можете получить доступ к строкам и столбцам DataFrame с помощью свойства iloc, как если бы это была матрица: . df.iloc[:,0] . 0 000005.jpg 1 000007.jpg 2 000009.jpg 3 000012.jpg 4 000016.jpg ... 5006 009954.jpg 5007 009955.jpg 5008 009958.jpg 5009 009959.jpg 5010 009961.jpg Name: fname, Length: 5011, dtype: object . df.iloc[0,:] # Trailing :s are always optional (in numpy, pytorch, pandas, etc.), # so this is equivalent: df.iloc[0] . fname 000005.jpg labels chair is_valid True Name: 0, dtype: object . Вы также можете получить столбец по имени, непосредственно индексируя DataFrame: . df[&#39;fname&#39;] . 0 000005.jpg 1 000007.jpg 2 000009.jpg 3 000012.jpg 4 000016.jpg ... 5006 009954.jpg 5007 009955.jpg 5008 009958.jpg 5009 009959.jpg 5010 009961.jpg Name: fname, Length: 5011, dtype: object . tmp_df = pd.DataFrame({&#39;a&#39;:[1,2], &#39;b&#39;:[3,4]}) tmp_df . a b . 0 1 | 3 | . 1 2 | 4 | . tmp_df[&#39;c&#39;] = tmp_df[&#39;a&#39;]+tmp_df[&#39;b&#39;] tmp_df . a b c . 0 1 | 3 | 4 | . 1 2 | 4 | 6 | . &#1055;&#1086;&#1089;&#1090;&#1088;&#1086;&#1077;&#1085;&#1080;&#1077; DataBlock . Как мы преобразуем объект DataFrame в объект DataLoaders? Обычно мы предлагаем использовать API блока данных для создания объекта DataLoaders, где это возможно, поскольку он обеспечивает хорошее сочетание гибкости и простоты. Здесь мы покажем вам шаги, которые мы предпринимаем, чтобы использовать API блоков данных для построения объекта DataLoaders на практике, используя этот набор данных в качестве примера. . Как мы уже видели, PyTorch и fastai имеют два основных класса для представления и доступа к обучающему набору или набору проверки: . Dataset:: Коллекция, которая возвращает кортеж вашей независимой и зависимой переменной для одного элемента | DataLoader:: Итератор, который обеспечивает поток мини-пакетов, где каждый мини-пакет является кортежем пакета независимых переменных и пакета зависимых переменных | . Кроме того, fastai предоставляет два класса для объединения ваших обучающих и проверочных наборов: . Datasets:: Объект, содержащий обучающий набор данных и проверочный набор данных | DataLoaders:: Объект, содержащий обучающий загрузчик данных и загрузчик данных проверки | . Поскольку DataLoader строится поверх Dataset и добавляет к нему дополнительные функции (сортировка нескольких элементов в мини-пакет), часто проще всего начать с создания и тестирования Datasets, а затем посмотреть на DataLoaders после того, как они заработают. . Когда мы создаем DataBlock, мы создаем его постепенно, шаг за шагом, и используем блокнот для проверки ваших данных. Это отличный способ убедиться, что вы следите за любыми проблемами. Легко отлаживать, потому что вы знаете, что если возникает проблема, то она находится в строке кода, который вы только что набрали! . Начнем с простейшего случая, который представляет собой блок данных, созданный без параметров: . dblock = DataBlock() . Из этого мы можем создать объект Datasets. Единственное, что нужно, - это источник-в данном случае наш DataFrame: . dsets = dblock.datasets(df) . Он содержит тренировочный и проверочный набор данных, который мы можем индексировать: . len(dsets.train),len(dsets.valid) . (4009, 1002) . x,y = dsets.train[0] x,y . (fname 008663.jpg labels car person is_valid False Name: 4346, dtype: object, fname 008663.jpg labels car person is_valid False Name: 4346, dtype: object) . Как вы можете видеть, возвращается строка DataFrame дважды. Это происходит потому, что по умолчанию блок данных предполагает, что у нас есть две вещи: входные данные и целевые значения. Нам нужно будет получить соответствующие поля из DataFrame, что мы можем сделать, передав функции get_x и get_y: . x[&#39;fname&#39;] . &#39;008663.jpg&#39; . dblock = DataBlock(get_x = lambda r: r[&#39;fname&#39;], get_y = lambda r: r[&#39;labels&#39;]) dsets = dblock.datasets(df) dsets.train[0] . (&#39;005620.jpg&#39;, &#39;aeroplane&#39;) . Как вы можете видеть, вместо того, чтобы определять функцию обычным способом, мы используем ключевое слово Python lambda. Это просто кратчайший путь для определения и последующей ссылки на функцию. Следующий более подробный подход идентичен: . def get_x(r): return r[&#39;fname&#39;] def get_y(r): return r[&#39;labels&#39;] dblock = DataBlock(get_x = get_x, get_y = get_y) dsets = dblock.datasets(df) dsets.train[0] . (&#39;002549.jpg&#39;, &#39;tvmonitor&#39;) . Лямбда-функции отлично подходят для быстрой итерации, но они несовместимы с сериализацией, поэтому мы советуем вам использовать более подробный подход, если вы хотите экспортировать своего Learner после обучения (лямбды хороши, если вы просто экспериментируете). . Мы видим, что независимая переменная должна быть преобразована в полный путь, чтобы мы могли открыть ее как изображение, а зависимая переменная должна быть разделена символом пробела( который используется по умолчанию для функции разделения Python), чтобы она стала списком: . def get_x(r): return path/&#39;train&#39;/r[&#39;fname&#39;] def get_y(r): return r[&#39;labels&#39;].split(&#39; &#39;) dblock = DataBlock(get_x = get_x, get_y = get_y) dsets = dblock.datasets(df) dsets.train[0] . (Path(&#39;/storage/data/pascal_2007/train/002844.jpg&#39;), [&#39;train&#39;]) . Чтобы действительно открыть изображение и выполнить преобразование его в тензоры, нам нужно будет использовать набор преобразований, которые нам предоставляют. Мы можем использовать те же типы блоков, что и раньше, за одним исключением: ImageBlock снова будет работать нормально, потому что у нас есть путь, который указывает на допустимое изображение, но CategoryBlock не будет работать. Проблема в том, что блок возвращает одно целое число, но нам нужно иметь возможность иметь несколько меток для каждого элемента. Чтобы решить эту проблему, мы используем MultiCategoryBlock. Этот тип блока ожидает получить список строк, как и в данном случае, поэтому давайте проверим его: . dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock), get_x = get_x, get_y = get_y) dsets = dblock.datasets(df) dsets.train[0] . (PILImage mode=RGB size=500x375, TensorMultiCategory([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])) . Как вы можете видеть, наш список категорий не закодирован таким же образом, как это было для обычного блока категорий. В том случае у нас было одно целое число, представляющее, какая это категория, основываясь на ее местоположении в нашем vocab. В этом случае, однако, у нас вместо этого есть список нулей с единицей. Например, если есть единица во второй и четвертой позициях, то это означает, что элементы vocab под номером два и четыре присутствуют на этом изображении. Это известно как one-hot encoding. Причина, по которой мы не можем просто использовать список индексов категорий, заключается в том, что каждый список будет иметь разную длину, а PyTorch требует тензоров одинаковой длины. . Давайте проверим, что представляют собой категории для этого примера (мы используем удобную функцию torch.where, которая возращает нам все индексы, где наше условие истинно или ложно): . idxs = torch.where(dsets.train[0][1]==1.)[0] dsets.train.vocab[idxs] . (#1) [&#39;dog&#39;] . С массивами NumPy, тензорами PyTorch и классом L fastai мы можем индексировать непосредственно с помощью списка или вектора, что делает большой код (например, этот пример) гораздо более ясным и кратким. . До сих пор мы игнорировали столбец is_valid, что означает, что блок данных по умолчанию использует случайное разделение. Чтобы явно выбрать элементы нашего набора проверки, нам нужно написать функцию и передать ее splitter (или использовать одну из предопределенных функций или классов fastai). Он будет принимать элементы (здесь весь наш фрейм данных) и должен возвращать два (или более) списка целых чисел: . def splitter(df): train = df.index[~df[&#39;is_valid&#39;]].tolist() valid = df.index[df[&#39;is_valid&#39;]].tolist() return train,valid dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock), splitter=splitter, get_x=get_x, get_y=get_y) dsets = dblock.datasets(df) dsets.train[0] . (PILImage mode=RGB size=500x333, TensorMultiCategory([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])) . Как мы уже обсуждали, DataLoader собирает элементы из Dataset в мини-пакет. Это кортеж тензоров, где каждый тензор просто куча элементов из местоположений в элементе Dataset. . Теперь, когда мы убедились, что отдельные элементы выглядят нормально, нам нужно сделать еще один шаг, чтобы убедиться, что мы можем создать наши DataLoaders, а именно убедиться, что каждый элемент имеет одинаковый размер. Для этого мы можем использовать RandomResizedCrop: . dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock), splitter=splitter, get_x=get_x, get_y=get_y, item_tfms = RandomResizedCrop(128, min_scale=0.35)) dls = dblock.dataloaders(df) . И теперь мы можем показать элемент наших данных: . dls.show_batch(nrows=1, ncols=3) . Помните, что если что-то пойдет не так при создании DataLoaders из вашего DataBlock или если вы хотите точно увидеть, что происходит с вашим DataBlock, вы можете использовать метод краткого изложения, который мы представили в предыдущей главе. . Наши данные теперь готовы для обучения модели. Как мы увидим, ничего не изменится, когда мы создадим нашего Learner, но за кулисами fastai библиотека выберет для нас новую функцию потерь: двоичную кросс-энтропию. . &#1041;&#1080;&#1085;&#1072;&#1088;&#1085;&#1072;&#1103; &#1082;&#1088;&#1086;&#1089;&#1089;-&#1101;&#1085;&#1090;&#1088;&#1086;&#1087;&#1080;&#1103; . Теперь создадим нашего Learner. . learn = cnn_learner(dls, resnet18) . Мы также знаем, что модель в Learner, как правило, является объектом класса, наследуемого от nn.Module, и что мы можем вызвать его с помощью скобок, и он будет возвращать активации модели. Вы должны передать ему свою независимую переменную, как мини-пакет. Мы можем попробовать его, взяв мини-пакет из нашего загрузчика данных, а затем передав его модели: . x,y = to_cpu(dls.train.one_batch()) activs = learn.model(x) activs.shape . torch.Size([64, 20]) . Подумайте о том, почему activs имеет такую форму—у нас есть размер пакета 64, и нам нужно рассчитать вероятность каждой из 20 категорий. Вот как выглядит одна из этих активаций: . activs[0] . tensor([ 0.7476, -1.1988, 4.5421, -1.5915, -0.6749, 0.0343, -2.4930, -0.8330, -0.3817, -1.4876, -0.1683, 2.1547, -3.4151, -1.1743, 0.1530, -1.6801, -2.3067, 0.7063, -1.3358, -0.3715], grad_fn=&lt;SelectBackward&gt;) . Данные еще не масштабированы до 0 и 1 . def binary_cross_entropy(inputs, targets): inputs = inputs.sigmoid() return -torch.where(targets==1, inputs, 1-inputs).log().mean() . Обратите внимание, что поскольку у нас есть one-hot-encoded зависимая переменная, мы не можем напрямую использовать nll_loss или softmax (и поэтому мы не можем использовать cross_entropy): . softmax, как мы знаем, требует, чтобы сумма всех предсказаний равнялась 1 и за счет использования exp значительно выделяет одну активацию из других. Однако у нас вполне может быть несколько объектов, которые имеются на изображении, поэтому ограничение максимальной суммы активаций до 1 не является хорошей идеей. Исходя из того же рассуждения, мы также можем хотеть, чтобы сумма была меньше 1, если мы не уверены что какая то категория появиться на изображении. | nll_loss, как мы знаем, возвращает значение только одной активации: единственной активации, соответствующей одной метке для элемента. Это не имеет смысла, когда у нас есть несколько категорий. | . С другой стороны, функция binary_cross_entropy, которая является просто mnist_loss вместе с log, обеспечивает именно то, что нам нужно, благодаря магии элементарных операций PyTorch. Каждая активация будет сравниваться с каждой целью для каждого столбца, поэтому нам не нужно ничего делать, чтобы заставить эту функцию работать для нескольких столбцов. . Python уже предоставляет нам эту функцию. На самом деле, он предоставляет ряд версий, с довольно запутанными названиями! . F.binary_cross_entropy и его модульный эквивалент nn.BCELoss вычисляют кросс-энтропию для одной one-hot-encoded цели, но не включают начальную сигмоиду. Обычно для one-hot-encoded целей вы захотите F.binary_cross_entropy_with_logits (или НН.BCEWithLogitsLoss), которые выполняют как сигмоидную, так и двоичную кросс-энтропию в одной функции, как в предыдущем примере. . Эквивалентом для наборов данных с одной меткой (например, MNIST или Pet dataset), где цель кодируется как одно целое число, является F.nll_loss или nn.NLLLoss для версии без начального softmax и F.cross_entropy или nn.CrossEntropyLoss для версии с начальным softmax. . Поскольку у нас есть цель с one-hot-encoded кодированием, мы будем использовать BCEWithLogitsLoss . loss_func = nn.BCEWithLogitsLoss() loss = loss_func(activs, y) loss . TensorMultiCategory(1.0342, grad_fn=&lt;AliasBackward&gt;) . На самом деле нам не нужно указывать fastai, что необходимо использовать эту функцию потерь (хотя мы можем, если захотим), так как она установлена автоматически. fastai знает, что DataLoaders имеют многокатегориальные метки, поэтому по умолчанию он будет использовать nn.BCEWithLogitsLoss. . Одно изменение по сравнению с предыдущей главой-это метрика, которую мы используем: поскольку это проблема с несколькими метками, мы не можем использовать функцию точности. Почему это? Ну, точность сравнивала наши результаты с нашими целями следующим образом: . def accuracy(inp, targ, axis=-1): &quot;Compute accuracy with `targ` when `pred` is bs * n_classes&quot; pred = inp.argmax(dim=axis) return (pred == targ).float().mean() . Предсказанный класс был тем, у кого была самая высокая активация (это то, что делает argmax). Здесь это не работает, потому что у нас может быть более одного предсказания на одном изображении. После применения сигмоиды к нашим активациям (чтобы сопоставить их между 0 и 1), нам нужно решить, какие из них являются 0, а какие 1 за счет порога. Каждое значение выше порога будет рассматриваться как 1, а каждое значение ниже порога будет считаться 0: . def accuracy_multi(inp, targ, thresh=0.5, sigmoid=True): &quot;Compute accuracy when `inp` and `targ` are the same size.&quot; if sigmoid: inp = inp.sigmoid() return ((inp&gt;thresh)==targ.bool()).float().mean() . Если мы передадим accuracy_multi непосредственно в качестве метрики, она будет использовать значение по умолчанию для порога, которое равно 0,5. Возможно мы захотим изменить это значение по умолчанию и создать новую версию accuracy_multi, которая имеет другое значение по умолчанию. Чтобы помочь в этом, в Python есть функция, называемая partial. Это позволяет нам связать функцию с некоторыми аргументами, создавая новую версию этой функции, которая, когда бы она ни вызывалась, всегда включает эти аргументы. Например, вот простая функция, принимающая два аргумента: . def say_hello(name, say_what=&quot;Hello&quot;): return f&quot;{say_what} {name}.&quot; say_hello(&#39;Jeremy&#39;),say_hello(&#39;Jeremy&#39;, &#39;Ahoy!&#39;) . (&#39;Hello Jeremy.&#39;, &#39;Ahoy! Jeremy.&#39;) . Мы можем переключиться на французскую версию этой функции с помощью partial: . f = partial(say_hello, say_what=&quot;Bonjour&quot;) f(&quot;Jeremy&quot;),f(&quot;Sylvain&quot;) . (&#39;Bonjour Jeremy.&#39;, &#39;Bonjour Sylvain.&#39;) . Теперь мы можем тренировать нашу модель. Давайте попробуем установить порог точности для нашей метрики равным 0,2: . learn = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2)) learn.fine_tune(3, base_lr=3e-3, freeze_epochs=4) . epoch train_loss valid_loss accuracy_multi time . 0 | 0.940148 | 0.697462 | 0.236952 | 00:12 | . 1 | 0.822964 | 0.557433 | 0.286056 | 00:12 | . 2 | 0.602061 | 0.198278 | 0.833446 | 00:12 | . 3 | 0.358782 | 0.123523 | 0.944383 | 00:12 | . epoch train_loss valid_loss accuracy_multi time . 0 | 0.130395 | 0.112252 | 0.949342 | 00:14 | . 1 | 0.116924 | 0.105566 | 0.952171 | 00:14 | . 2 | 0.097506 | 0.101672 | 0.951912 | 00:14 | . Выбор порога очень важен. Если вы выберете слишком низкий порог, вы часто не сможете выбрать правильно объекты. Мы можем увидеть это, изменив нашу метрику, а затем вызвав validate, который возвращает ошибку проверки и метрики: . learn.metrics = partial(accuracy_multi, thresh=0.1) learn.validate() . (#2) [0.10167204588651657,0.9306574463844299] . Если вы выберете слишком высокий порог, вы будете получать только те объекты, для которых ваша модель очень уверена: . learn.metrics = partial(accuracy_multi, thresh=0.99) learn.validate() . (#2) [0.10167204588651657,0.9425497055053711] . Мы можем найти лучший порог, попробовав несколько уровней и увидев, что работает лучше всего. Это намного быстрее, если мы просто возьмем предсказания один раз: . preds,targs = learn.get_preds() . Тогда мы можем вызвать метрику напрямую. Обратите внимание, что по умолчанию get_press применяет для нас результирующую функцию активации (в данном случае сигмоида), поэтому нам нужно будет сказать accuracy_multi, чтобы он ее не применял: . accuracy_multi(preds, targs, thresh=0.9, sigmoid=False) . TensorMultiCategory(0.9574) . Теперь мы можем использовать этот подход для поиска наилучшего порогового уровня: . xs = torch.linspace(0.05,0.95,29) accs = [accuracy_multi(preds, targs, thresh=i, sigmoid=False) for i in xs] plt.plot(xs,accs); . В этом случае мы используем проверочный набор для выбора гиперпараметра (порога), который является его задачей. Иногда студенты выражают озабоченность тем, что мы, возможно, можем переобучить проверочный набор, поскольку мы пробуем множество значений, чтобы увидеть, какое из них является лучшим. Однако, как вы видите на графике, изменение порога в этом случае приводит к плавной кривой, поэтому мы явно не выбираем какой-то неуместный выброс. Это хороший пример того, где вы должны быть осторожны с различием между теорией (не пытайтесь использовать много значений гиперпараметров, иначе вы можете переобучить) и практикой (если связь гладкая, то это нормально). . На этом заканчивается часть этой главы, посвященная классификации с несколькими метками. Далее мы рассмотрим проблему регрессии. . &#1056;&#1077;&#1075;&#1088;&#1077;&#1089;&#1089;&#1080;&#1103; . Легко представить себе, что модели глубокого обучения делятся на такие области, как компьютерное зрение, НЛП и так далее. И действительно, именно так fastai классифицирует свои приложения-в основном потому, что именно так большинство людей привыкли думать о вещах. . Но на самом деле за этим скрывается более интересная и глубокая перспектива. Модель определяется ее независимыми и зависимыми переменными, а также функцией потерь. Это означает, что на самом деле существует гораздо более широкий спектр моделей, чем просто разделение на основе области. Возможно, у нас есть независимая переменная, которая является изображением, и зависимая, которая является текстом (например, генерируя подпись из изображения); или, возможно, у нас есть независимая переменная, которая является текстом, и зависимая, которая является изображением (например, генерируя изображение из подписи—что на самом деле возможно для глубокого обучения!); или, возможно, у нас есть изображения, тексты и табличные данные в качестве независимых переменных, и мы пытаемся предсказать покупку продукта... возможности действительно безграничны. . Возможность выйти за рамки фиксированных приложений, чтобы создавать свои собственные новые решения для новых проблем, помогает понять API блоков данных (и, возможно, также API среднего уровня, который мы увидим позже в этой книге). В качестве примера рассмотрим проблему регрессии изображений. Это относится к обучению на основе набора данных, где независимая переменная представляет собой изображение, а зависимая переменная-одно или несколько чисел типа float. Часто мы видим, что люди относятся к регрессии изображений как к целому отдельному приложению, но, как вы увидите здесь, мы можем рассматривать его как просто еще один CNN поверх API блока данных. . Мы сразу перейдем к довольно сложному варианту регрессии изображений, потому что мы знаем, что вы к этому готовы! Мы собираемся сделать модель ключевой точки. Ключевой момент относится к определенному месту, представленному на изображении—в этом случае мы будем использовать изображения людей и будем искать центр лица человека на каждом изображении. Это означает, что мы фактически будем предсказывать два значения для каждого изображения: строку и столбец центра лица. . Assemble the Data . Мы будем использовать Biwi Kinect Head Pose dataset для этого раздела. Начнем с загрузки набора данных как обычно . path = untar_data(URLs.BIWI_HEAD_POSE) . Давайте посмотрим, что у нас есть! . path.ls().sorted() . (#50) [Path(&#39;01&#39;),Path(&#39;01.obj&#39;),Path(&#39;02&#39;),Path(&#39;02.obj&#39;),Path(&#39;03&#39;),Path(&#39;03.obj&#39;),Path(&#39;04&#39;),Path(&#39;04.obj&#39;),Path(&#39;05&#39;),Path(&#39;05.obj&#39;)...] . Есть 24 каталога, пронумерованные от 01 до 24 (они соответствуют разным сфотографированным людям), и соответствующий файл .obj для каждого (они нам здесь не понадобятся). Давайте заглянем в один из этих каталогов: . (path/&#39;01&#39;).ls().sorted() . (#1000) [Path(&#39;01/depth.cal&#39;),Path(&#39;01/frame_00003_pose.txt&#39;),Path(&#39;01/frame_00003_rgb.jpg&#39;),Path(&#39;01/frame_00004_pose.txt&#39;),Path(&#39;01/frame_00004_rgb.jpg&#39;),Path(&#39;01/frame_00005_pose.txt&#39;),Path(&#39;01/frame_00005_rgb.jpg&#39;),Path(&#39;01/frame_00006_pose.txt&#39;),Path(&#39;01/frame_00006_rgb.jpg&#39;),Path(&#39;01/frame_00007_pose.txt&#39;)...] . Внутри подкаталогов у нас есть разные фреймы, каждый из которых поставляется с изображением (_rgb.jpg) и файлом позы (_pose.txt). Мы можем легко получить все файлы изображений рекурсивно с помощью get_image_files, а затем написать функцию, которая преобразует имя файла изображения в связанный с ним файл позы: . img_files = get_image_files(path) def img2pose(x): return Path(f&#39;{str(x)[:-7]}pose.txt&#39;) img2pose(img_files[0]) . Path(&#39;16/frame_00182_pose.txt&#39;) . Давайте взглянем на наше первое изображение: . im = PILImage.create(img_files[0]) im.shape . (480, 640) . im.to_thumb(160) . Веб-сайт набора данных Biwi используется для объяснения формата связи текстового файла post с каждым изображением, который показывает расположение центра головы. Детали этого не важны для наших целей, поэтому мы просто покажем функцию, которую мы используем для извлечения центральной точки головы: . cal = np.genfromtxt(path/&#39;01&#39;/&#39;rgb.cal&#39;, skip_footer=6) def get_ctr(f): ctr = np.genfromtxt(img2pose(f), skip_header=3) c1 = ctr[0] * cal[0][0]/ctr[2] + cal[0][2] c2 = ctr[1] * cal[1][1]/ctr[2] + cal[1][2] return tensor([c1,c2]) . Мы можем передать эту функцию DataBlock как get_y, так как она отвечает за маркировку каждого элемента. Мы изменим размер изображений до половины их входного размера, просто чтобы немного ускорить обучение. . Один важный момент, который следует отметить, заключается в том, что мы не должны просто использовать случайный сплиттер. Причина этого заключается в том, что одни и те же люди появляются на нескольких изображениях в этом наборе данных, но мы хотим убедиться, что наша модель может обобщать людей, которых она еще не видела. Каждая папка в наборе данных содержит изображения для одного человека. Поэтому мы можем создать функцию splitter, которая возвращает true только для одного человека, в результате чего набор проверки содержит только изображения этого человека. . Единственное другое отличие от предыдущих примеров блоков данных состоит в том, что второй блок является точечным блоком. Это необходимо для того, чтобы fastai знал, что метки представляют координаты; таким образом, он знает, что при увеличении данных он должен делать то же самое увеличение для координат, что и для изображений: . get_ctr(img_files[0]) . tensor([324.0023, 251.5637]) . biwi = DataBlock( blocks=(ImageBlock, PointBlock), get_items=get_image_files, get_y=get_ctr, splitter=FuncSplitter(lambda o: o.parent.name==&#39;13&#39;), batch_tfms=[*aug_transforms(size=(240,320)), Normalize.from_stats(*imagenet_stats)] ) . Прежде чем делать какое-либо моделирование, мы должны посмотреть на наши данные, чтобы убедиться, что все в порядке: . dls = biwi.dataloaders(path) dls.show_batch(max_n=9, figsize=(8,6)) . Это выглядит хорошо! Помимо визуального просмотра пакета, неплохо также посмотреть на лежащие в его основе тензоры (особенно если вы студент; это поможет прояснить ваше понимание того, что на самом деле видит ваша модель): . xb,yb = dls.one_batch() xb.shape,yb.shape . ((64, 3, 240, 320), (64, 1, 2)) . Убедитесь, что вы понимаете, почему именно эти формы используются для наших мини-партий. . Вот пример одной строки из зависимой переменной: . yb[0] . TensorPoint([[-0.2811, -0.0472]], device=&#39;cuda:0&#39;) . Как вы можете видеть, нам не нужно было использовать отдельное приложение регрессии изображений; все, что нам нужно было сделать, это пометить данные и сказать fastai, какие типы данных представляют независимые и зависимые переменные. . То же самое относится и к созданию нашего Learner. Мы будем использовать ту же функцию, что и раньше, с одним новым параметром,и будем готовы обучить нашу модель. . &#1054;&#1073;&#1091;&#1095;&#1077;&#1085;&#1080;&#1077; &#1084;&#1086;&#1076;&#1077;&#1083;&#1080; . Как обычно, мы можем использовать cnn_learner для создания нашего ученика. . learn = cnn_learner(dls, resnet18, y_range=(-1,1)) . y_range реализуется в fastai с помощью sigmoid_range, который определяется как: . def sigmoid_range(x, lo, hi): return torch.sigmoid(x) * (hi-lo) + lo . Он устанавливается в качестве конечного слоя модели, если определен y_range. Подумайте о том, что делает эта функция и почему она заставляет модель выводить активации в диапазоне (lo,hi). . plot_function(partial(sigmoid_range,lo=-1,hi=1), min=-4, max=4) . Мы не указали функцию потерь и это означает fastai выбирает по умолчанию. Давайте посмотрим, что он выбрал для нас: . dls.loss_func . FlattenedLoss of MSELoss() . Это имеет смысл, поскольку, когда координаты используются в качестве зависимой переменной, большую часть времени мы, вероятно, пытаемся предсказать что-то как можно более близкое; это в основном то, что делает MSELoss (mean squared error loss). Если вы хотите использовать другую функцию потерь, вы можете передать ее cnn_learner с помощью параметра loss_func. . Обратите внимание также, что мы не указали никаких метрик. Это потому, что MSE уже является необходимой метрикой для этой задачи (хотя она, вероятно, более интерпретируема после того, как мы возьмем квадратный корень). . Мы можем выбрать лучшую скорость обучения с помощью искателя скорости обучения: . learn.lr_find() . SuggestedLRs(lr_min=0.004786301031708717, lr_steep=0.03981071710586548) . Мы попробуем LR 1e-2: . lr = 1e-2 learn.fine_tune(3, lr) . epoch train_loss valid_loss time . 0 | 0.050240 | 0.016628 | 01:12 | . epoch train_loss valid_loss time . 0 | 0.007083 | 0.002008 | 01:30 | . 1 | 0.002808 | 0.000214 | 01:31 | . 2 | 0.001404 | 0.000119 | 01:31 | . Обычно, когда мы запускаем это, мы получаем потерю около 0,0001, что соответствует средней ошибке предсказания координат: . math.sqrt(0.0001) . 0.01 . Это звучит очень точно! Но очень важно взглянуть на наши результаты с помощью Learner.show_results. Левая сторона-это фактические (истинные) координаты, а правая - предсказания нашей модели: . learn.show_results(ds_idx=1, nrows=3, figsize=(6,8)) . Просто удивительно, что всего за несколько минут вычислений мы создали такую точную модель ключевых точек и без какого-либо специального приложения для конкретной области. Это сила построения гибких API и использования трансфертного обучения! Особенно поразительно, что мы смогли так эффективно использовать трансферное обучение даже между совершенно разными задачами; наша предварительно обученная модель была обучена классификации изображений, и мы точно настроились на регрессию изображений. . &#1047;&#1072;&#1082;&#1083;&#1102;&#1095;&#1077;&#1085;&#1080;&#1077; . В задачах, которые на первый взгляд совершенно различны (классификация с одной меткой, классификация с несколькими метками и регрессия), мы в конечном итоге используем одну и ту же модель с разным количеством выходов. Функция потерь-это единственное, что меняется, поэтому важно дважды проверить, что вы используете правильную функцию потерь для своей проблемы. . fastai автоматически попытается выбрать правильный вариант из построенных вами данных, но если вы используете чистый PyTorch для создания своих загрузчиков данных, убедитесь, что вы хорошо проработали вопрос о том, какую функцию потерь, и помните, что вы, скорее всего, захотите: . nn.CrossEntropyLoss для классификации с одной меткой | nn.BCEWithLogitsLoss для классификации с множесством меток | nn.MSELoss для регрессии | .",
            "url": "https://zmey56.github.io/blog//russian/fast.ai/solution/2021/01/06/06-multicat.html",
            "relUrl": "/russian/fast.ai/solution/2021/01/06/06-multicat.html",
            "date": " • Jan 6, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Russian - Fastbook Chapter 6 questionnaire solutions",
            "content": "Ответы на русском языке на вопросы к шестой части курса Deep Learning 2020 на Fast.ai. Если есть притензии к переводу, как и к осталььным частям прошу писать в коментариях - поправлю. . 1. Как множественная классификация может улучшить медвежий классификатор? . Позволило бы классифицировать отсутствие медведей. В противном случае модель множественной классификации будет предсказывать присутствие медведя, даже если его там нет (если только явно не добавлен отдельный класс). . 2. Как мы кодируем зависимую переменную в задаче классификации с несколькими метками? . Кодируется как one-hot encoded вектор. По сути, это означает, что у нас есть нулевой вектор одинаковой длины числу классов с единицой с индексом соответствующего класса. . 3. Как получить доступ к строкам и столбцам DataFrame, как если бы это была матрица? . Вы можете использовать .iloc. Например, df. iloc[10,10] выберет элемент в 10-й строке и 10-м столбце, как если бы DataFrame был матрицей. . 4. Как получить столбец по имени из DataFrame? . Это очень просто. Вы можете просто использовать указатель. Пример: df[‘column_name’] . **5. В чем разница между Dataset и DataLoader? . Dataset-это набор, который возвращает кортеж независимой и зависимой переменной для одного элемента. DataLoader - это функционально расширеный Dataset. Это итератор, который обеспечивает поток мини-пакетов, где каждый мини-пакет представляет собой пару пакетов из независимых и зависимых переменных. . 6. Что обычно содержиться в Dataset? . Обучающий и проверочный набор. . 7. Что обычно содержит DataLoader? . Тренировочный и проверочный dataloader. . **8. Что обычно лямбда делает в Python? . Лямбды-это сокращенный вариант для написания функций (написание однострочных функций). Он отлично подходит для быстрого прототипирования и итерации, но поскольку он не сериализуем, его нельзя использовать в развертывании и производстве. . 9. Каковы методы настройки того, как независимые и зависимые переменные создаются с помощью API блоков данных? . get_x and get_y . get_x используется для указания способа создания независимых переменных. | get_y используется для указания того, как маркируются точки данных | . 10. Почему softmax не является подходящей функцией активации для вывода при использовании one hot encoded целевого значения? . Softmax нужно, чтобы модель предсказывала только один класс, что может быть неверно в задаче многоклассовой классификации. В задачах классификации с несколькими метками входные данные могут иметь несколько меток или даже не иметь меток. . **11. Почему nll_loss не является подходящей функцией потерь при использовании one hot encoded целевого значения? . Опять же, nll_loss работает только тогда, когда модели нужно предсказать только один класс, чего здесь нет. . 12. В чем разница между nn.BCELoss и nn.BCEWithLogitsLoss? . nn.BCELoss не включает в себя начальную сигмоиду. Предполагается, что соответствующая функция активации (т.е. сигмовидная) уже была применена к предсказаниям. nn.BCEWithLogitsLoss с другой стороны применяет и сигмоиду и кросс-энтропию в одной функции. . 13. Почему мы не можем использовать обычную точность(accurancy) в задаче с несколькими метками? . Обычная точнасть предполагает, что конечным предсказанным моделью классом является класс с наибольшей активацией. Однако в задачах с несколькими метками может быть несколько меток. Поэтому порог для активаций должен быть установлен для выбора конечных прогнозируемых классов на основе активаций по сравнению с целевыми классами. . 14. Когда это нормально, чтобы настроить гипер-параметр в проверочном наборе? . Это нормально, когда отношение между гиперпараметром и наблюдаемой метрикой гладкая, что позволит исключить выбор некорректного выброса. . 15. Как реализован y_range в fastai? (Посмотрите, сможете ли вы реализовать его самостоятельно и протестировать без пика!) . y_range реализован с помощью sigmoid_range в fastai. . def sigmoid_range(x, lo, hi): return x.sigmoid() * (hi-lo) + lo . 16. Что такое проблема регрессии? Какую функцию потерь вы должны использовать для такой проблемы? . В регрессионной задаче зависимая переменная или метки, которые мы пытаемся предсказать, являются непрерывными значениями. Для таких задач используется функция среднеквадратичных потерь ошибок. . 17. Что вам нужно сделать, чтобы убедиться, что библиотека fastai применяет одно и то же увеличение данных к вашим входным изображениям и координатам целевой точки? . Вам нужно использовать правильный DataBlock. В данном случае это PointBlock. Этот DataBlock автоматически применяет увеличение данных к входным изображениям и координатам целевой точки. . 1. Почему мы сначала изменяем размер до большого размера на процессоре, а затем до меньшего размера на графическом процессоре? . Эта концепция известна как проклеивание (presizing). Прирост данных часто применяется к изображениям, и на самом деле это делается на графическом процессоре. Однако увеличение объема данных может привести к ухудшению качества и появлению артефактов, особенно на краях. Поэтому, чтобы свести к минимуму ухудшение качества данных, дополнения выполняются на более крупном изображении, а затем выполняется RandomResizeCrop изменение размера до требуемого размера изображения. . 2. Если вы не знакомы с регулярными выражениями, найдите учебник по регулярным выражениям и задач и выполните их. . Выполняется самостоятельно . 3. Каковы два наиболее распространенных способа предоставления данных для большинства наборов данных глубокого обучения? . Отдельные файлы, представляющие элементы данных, такие как текстовые документы или изображения. | Таблица данных, например в формате CSV, где каждая строка является элементом и может включать имена файлов, обеспечивающие связь между данными в таблице и данными в других форматах, таких как текстовые документы и изображения. | . 4. Посмотрите документацию на L и попробуйте использовать несколько новых методов. . Выполняется самостоятельно . 5. Посмотрите документацию для модуля Python pathlib и попробуйте использовать несколько методов класса Path. . Выполняется самостоятельно . 6. Приведите два примера того, как преобразования изображений могут ухудшить качество данных. . Вращение может являться причиной пустых областей в конечном изображении | Другие операции могут потребовать интерполяции, которая основана на исходных пикселях изображения и в результате более низкое качество изображения | . 7. Какой метод в fastai для просмотра данных в загрузчике данных (DataLoader)? . DataLoader.show_batch . 8. Какой метод в fastai, чтобы помочь вам отладить DataBlock? . DataBlock.summary . 9. Следует ли вам отложить обучение модели до тех пор, пока вы не очистите свои данные полностью? . Нет. Лучше всего первоначально создать базовую модель. . 10. Что за два метода объединены в кросс-энтропию в PyTorch? . Кросс энтропийные потери представляет собой комбинацию функции Softmax и отрицательной логарифмической потери правдоподобия. . 11. Каковы два свойства активаций, которые гарантирует softmax? Почему это так важно? . Выходные данные в сумме дают один и модель может предсказать только один класс. Кроме того, усиливаются небольшие изменения в выходных активациях, что полезно, поскольку это означает, что модель выберет метку с более высокой увереностью (хорошо для проблем с конкретными метками). . 12. Когда вы хотите, чтобы ваши активации не имели этих свойств? . Когда у вас есть проблемы с классификацией нескольких меток (возможно более одной метки). . 13. Вычислите столбцы exp и softmax. . ПРОПУЩЕНО . 14. Почему мы не можем использовать torch.where для создания функции потерь для наборов данных, где наша метка может иметь более двух категорий? . Потому что torch.where может выбирать только между двумя возможностями, в то время как для многоклассовой классификации у нас есть необходимость в выборе нескольких вариантов. . 15. Каково значение log (-2)? Почему? . Значение не определено. Логарифм является обратной экспоненциальной функцией, а экспоненциальная функция всегда положительна, независимо от того, какое значение передается. Таким образом, логарифм не определен для отрицательных значений. . **16. Каковы два хороших эмпирических правила для выбора скорости обучения при использовании искателя скорости обучения? . Любой из этих двух пунктов должен быть использован для скорости обучения: . на порядок меньше, чем там, где была достигнута минимальная потеря (то есть минимум, деленный на 10) | последняя точка, где потеря явно уменьшилась. | . 17. Какие два шага делает метод fine_tune? . Тренирует новую голову (со случайными весами) в течение одной эпохи | Разморозет все слои и тренирует их все для требуемого количества эпох | . 18. Как получить исходный код метода или функции в Jupyter notebook? . Использовать ?? после функции. Пример: DataBlock.summary?? . 19. Что такое дискриминационные показатели обучения? . Дискриминативные скорости обучения относятся к тренировочному трюку использования различных скоростей обучения для разных слоев модели. Это обычно используется в трансфертном обучении. Идея заключается в том, что при обучении предварительно подготовленной модели вы не хотите резко менять более ранние слои, поскольку она содержит информацию о простых объектах, таких как ребра и формы. Но более поздние слои могут быть изменены немного больше, поскольку они могут содержать информацию о чертах лица или других объектах, которые могут не иметь отношения к вашей задаче. Таким образом, более ранние слои имеют более низкую скорость обучения, а более поздние слои имеют более высокую скорость обучения. . 20. Как объект slice на языке Python интерпретируется при передаче в качестве скорости обучения в fastai? . Первое значение объекта среза - это скорость обучения для самого раннего слоя, а второе-скорость обучения для последнего слоя. Промежуточные слои будут иметь скорости обучения, которые мультипликативно равноудалены во всем этом диапазоне. . 21. Почему ранняя остановка является плохим выбором при использовании одного цикла тренировок? . Если используется ранняя остановка, обучение может не успеть достичь более низких значений скорости на графике, что могло бы способствовать совершенствованию модели. Поэтому рекомендуется переучивать модель и выбирать количество эпох исходя из того, где были найдены предыдущие лучшие результаты. . 22. В чем разница между resnet 50 и resnet101? . Числа 50 и 101 относятся к числу слоев в моделях. Таким образом, ResNet101-это более крупная модель с большим количеством слоев по сравнению с ResNet50. Эти варианты моделей обычно используются, поскольку существуют модели с предварительно подготовленными весами ImageNet. . 23. Что делает to_fp16? . Это позволяет проводить обучение со смешанной точностью, в котором для ускорения обучения используются менее точные числа. .",
            "url": "https://zmey56.github.io/blog//markdown/fastai/russian/deep%20learning/2021/01/04/fastai-chapter6-solution.html",
            "relUrl": "/markdown/fastai/russian/deep%20learning/2021/01/04/fastai-chapter6-solution.html",
            "date": " • Jan 4, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Russian - Solution Lesson 5 on Fast.ai",
            "content": "!pip install -Uqq fastbook import fastbook fastbook.setup_book() . &#1050;&#1083;&#1072;&#1089;&#1089;&#1080;&#1092;&#1080;&#1082;&#1072;&#1094;&#1080;&#1103; &#1080;&#1079;&#1086;&#1073;&#1088;&#1072;&#1078;&#1077;&#1085;&#1080;&#1081; . &#1054;&#1090; &#1082;&#1086;&#1096;&#1077;&#1082; &#1080; &#1089;&#1086;&#1073;&#1072;&#1082; &#1082; &#1087;&#1086;&#1088;&#1086;&#1076;&#1072;&#1084; &#1078;&#1080;&#1074;&#1086;&#1090;&#1085;&#1099;&#1093; . Набор данных Pet уже загружен и необходимо получить путь к нему . from fastai.vision.all import * path = untar_data(URLs.PETS) . Чтобы увидеть, что находится в нашем наборе данных, мы можем использовать метод ls: . path.ls() . (#2) [Path(&#39;images&#39;),Path(&#39;annotations&#39;)] . (path/&quot;images&quot;).ls() . (#7393) [Path(&#39;images/american_bulldog_146.jpg&#39;),Path(&#39;images/japanese_chin_12.jpg&#39;),Path(&#39;images/Sphynx_247.jpg&#39;),Path(&#39;images/beagle_158.jpg&#39;),Path(&#39;images/beagle_76.jpg&#39;),Path(&#39;images/shiba_inu_207.jpg&#39;),Path(&#39;images/Siamese_56.jpg&#39;),Path(&#39;images/keeshond_194.jpg&#39;),Path(&#39;images/miniature_pinscher_89.jpg&#39;),Path(&#39;images/leonberger_42.jpg&#39;)...] . Чтобы мы могли протестировать наши регулярные выражения, давайте выберем одно из имен файлов: . fname = (path/&quot;images&quot;).ls()[0] . Давайте используем метод findall, чтобы попробовать регулярное выражение с именем файла объекта fname. Следующее регулярное выражение выбирает все символы до последнего символа подчеркивания если после него идут цифры и расширение файла JPEG.: . re.findall(r&#39;(.+)_ d+.jpg$&#39;, fname.name) . [&#39;american_bulldog&#39;] . Для использования регулярных выражений для всего набора данных мы можем использовать класс RegexLabeller. . pets = DataBlock(blocks = (ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(seed=42), get_y=using_attr(RegexLabeller(r&#39;(.+)_ d+.jpg$&#39;), &#39;name&#39;), item_tfms=Resize(460), batch_tfms=aug_transforms(size=224, min_scale=0.75)) dls = pets.dataloaders(path/&quot;images&quot;) . &#1048;&#1079;&#1084;&#1077;&#1085;&#1077;&#1085;&#1080;&#1077; &#1088;&#1072;&#1079;&#1084;&#1077;&#1088;&#1072; . Для реализации процесса изменения размера фактически используется Resize как преобразование элемента с большим размером, а RandomResizedCrop - как пакетное преобразование с меньшим размером. RandomResizedCrop будет использоваться, если вы включите параметр main_scale в своей функции aug_transforms, как это было сделано в вызове DataBlock в предыдущем разделе. Кроме того, вы можете использовать pad или squish вместо crop (по умолчанию) для первоначального изменения размера. . dblock1 = DataBlock(blocks=(ImageBlock(), CategoryBlock()), get_y=parent_label, item_tfms=Resize(460)) dls1 = dblock1.dataloaders([(Path.cwd()/&#39;images&#39;/&#39;grizzly.jpg&#39;)]*100, bs=8) dls1.train.get_idxs = lambda: Inf.ones x,y = dls1.valid.one_batch() _,axs = subplots(1, 2) x1 = TensorImage(x.clone()) x1 = x1.affine_coord(sz=224) x1 = x1.rotate(draw=30, p=1.) x1 = x1.zoom(draw=1.2, p=1.) x1 = x1.warp(draw_x=-0.2, draw_y=0.2, p=1.) tfms = setup_aug_tfms([Rotate(draw=30, p=1, size=224), Zoom(draw=1.2, p=1., size=224), Warp(draw_x=-0.2, draw_y=0.2, p=1., size=224)]) x = Pipeline(tfms)(x) #x.affine_coord(coord_tfm=coord_tfm, sz=size, mode=mode, pad_mode=pad_mode) TensorImage(x[0]).show(ctx=axs[0]) TensorImage(x1[0]).show(ctx=axs[1]); . &#1055;&#1088;&#1086;&#1074;&#1077;&#1088;&#1082;&#1072; &#1080; &#1086;&#1090;&#1083;&#1072;&#1076;&#1082;&#1072; &#1073;&#1083;&#1086;&#1082;&#1072; &#1076;&#1072;&#1085;&#1085;&#1099;&#1093; . Вы можете вывести данные с помощью метода show_batch для проверки: . dls.show_batch(nrows=1, ncols=3) . Чтобы отладить это,мы рекомендуем вам использовать резюме.Например, одна из распространенных ошибок заключается в том, что вы забываете использовать преобразование размера, поэтому вы получаете изображения разных размеров и не можете их паковать. Вот как будет выглядеть резюме в этом случае (обратите внимание, что точный текст может измениться с момента написания, но это даст вам представление): . pets1 = DataBlock(blocks = (ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(seed=42), get_y=using_attr(RegexLabeller(r&#39;(.+)_ d+.jpg$&#39;), &#39;name&#39;)) pets1.summary(path/&quot;images&quot;) . Setting-up type transforms pipelines Collecting items from /storage/data/oxford-iiit-pet/images Found 7390 items 2 datasets of sizes 5912,1478 Setting up Pipeline: PILBase.create Setting up Pipeline: partial -&gt; Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} Building one sample Pipeline: PILBase.create starting from /storage/data/oxford-iiit-pet/images/shiba_inu_98.jpg applying PILBase.create gives PILImage mode=RGB size=500x374 Pipeline: partial -&gt; Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} starting from /storage/data/oxford-iiit-pet/images/shiba_inu_98.jpg applying partial gives shiba_inu applying Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} gives TensorCategory(33) Final sample: (PILImage mode=RGB size=500x374, TensorCategory(33)) Setting up after_item: Pipeline: ToTensor Setting up before_batch: Pipeline: Setting up after_batch: Pipeline: IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} Building one batch Applying item_tfms to the first sample: Pipeline: ToTensor starting from (PILImage mode=RGB size=500x374, TensorCategory(33)) applying ToTensor gives (TensorImage of size 3x374x500, TensorCategory(33)) Adding the next 3 samples No before_batch transform to apply Collating items in a batch Error! It&#39;s not possible to collate your items in a batch Could not collate the 0-th members of your tuples because got the following shapes torch.Size([3, 374, 500]),torch.Size([3, 375, 500]),torch.Size([3, 500, 424]),torch.Size([3, 351, 500]) . RuntimeError Traceback (most recent call last) &lt;ipython-input-12-ead0dd2a047d&gt; in &lt;module&gt; 3 splitter=RandomSplitter(seed=42), 4 get_y=using_attr(RegexLabeller(r&#39;(.+)_ d+.jpg$&#39;), &#39;name&#39;)) -&gt; 5 pets1.summary(path/&#34;images&#34;) /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/block.py in summary(self, source, bs, show_batch, **kwargs) 188 why = _find_fail_collate(s) 189 print(&#34;Make sure all parts of your samples are tensors of the same size&#34; if why is None else why) --&gt; 190 raise e 191 192 if len([f for f in dls.train.after_batch.fs if f.name != &#39;noop&#39;])!=0: /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/block.py in summary(self, source, bs, show_batch, **kwargs) 182 print(&#34; nCollating items in a batch&#34;) 183 try: --&gt; 184 b = dls.train.create_batch(s) 185 b = retain_types(b, s[0] if is_listy(s) else s) 186 except Exception as e: /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/load.py in create_batch(self, b) 129 def retain(self, res, b): return retain_types(res, b[0] if is_listy(b) else b) 130 def create_item(self, s): return next(self.it) if s is None else self.dataset[s] --&gt; 131 def create_batch(self, b): return (fa_collate,fa_convert)[self.prebatched](b) 132 def do_batch(self, b): return self.retain(self.create_batch(self.before_batch(b)), b) 133 def to(self, device): self.device = device /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/load.py in fa_collate(t) 46 b = t[0] 47 return (default_collate(t) if isinstance(b, _collate_types) &gt; 48 else type(t[0])([fa_collate(s) for s in zip(*t)]) if isinstance(b, Sequence) 49 else default_collate(t)) 50 /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/load.py in &lt;listcomp&gt;(.0) 46 b = t[0] 47 return (default_collate(t) if isinstance(b, _collate_types) &gt; 48 else type(t[0])([fa_collate(s) for s in zip(*t)]) if isinstance(b, Sequence) 49 else default_collate(t)) 50 /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/load.py in fa_collate(t) 45 &#34;A replacement for PyTorch `default_collate` which maintains types and handles `Sequence`s&#34; 46 b = t[0] &gt; 47 return (default_collate(t) if isinstance(b, _collate_types) 48 else type(t[0])([fa_collate(s) for s in zip(*t)]) if isinstance(b, Sequence) 49 else default_collate(t)) /opt/conda/envs/fastai/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py in default_collate(batch) 53 storage = elem.storage()._new_shared(numel) 54 out = elem.new(storage) &gt; 55 return torch.stack(batch, 0, out=out) 56 elif elem_type.__module__ == &#39;numpy&#39; and elem_type.__name__ != &#39;str_&#39; 57 and elem_type.__name__ != &#39;string_&#39;: /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/torch_core.py in __torch_function__(self, func, types, args, kwargs) 315 316 def __torch_function__(self, func, types, args=(), kwargs=None): --&gt; 317 with torch._C.DisableTorchFunction(): ret = _convert(func(*args, **(kwargs or {})), self.__class__) 318 if isinstance(ret, TensorBase): ret.set_meta(self, as_copy=True) 319 return ret RuntimeError: stack expects each tensor to be equal size, but got [3, 374, 500] at entry 0 and [3, 375, 500] at entry 1 . Для первоначального теста мы будем использовать простую модель: . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fine_tune(2) . epoch train_loss valid_loss error_rate time . 0 | 1.527914 | 0.350461 | 0.105548 | 11:05 | . epoch train_loss valid_loss error_rate time . 0 | 0.513429 | 0.363308 | 0.108931 | 14:55 | . 1 | 0.307440 | 0.248480 | 0.075778 | 15:00 | . &#1050;&#1088;&#1086;&#1089;&#1089;-&#1069;&#1085;&#1090;&#1088;&#1086;&#1087;&#1080;&#1081;&#1085;&#1099;&#1077; &#1055;&#1086;&#1090;&#1077;&#1088;&#1080; (Cross-Entropy Loss) . &#1040;&#1082;&#1090;&#1080;&#1074;&#1072;&#1094;&#1080;&#1103; &#1080; &#1084;&#1077;&#1090;&#1082;&#1080; . Чтобы получить массив реальных данных из нашего загрузчика данных, мы можем использовать метод one_batch: . x,y = dls.one_batch() . Давайте посмотрим, что на самом деле содержится в нашей зависимой переменной: . y . TensorCategory([25, 30, 1, 17, 30, 18, 29, 9, 19, 14, 20, 14, 24, 6, 19, 17, 24, 20, 13, 4, 3, 1, 19, 1, 23, 2, 28, 32, 20, 12, 11, 1, 32, 6, 8, 35, 11, 34, 14, 33, 23, 27, 3, 11, 24, 2, 22, 7, 20, 26, 29, 28, 12, 1, 27, 27, 30, 0, 2, 13, 22, 29, 9, 13]) . Наш размер пакета равен 64, поэтому у нас есть 64 строки в этом Тензоре. Каждая строка представляет собой одно целое число от 0 до 36, представляющее 37 возможных пород домашних животных. Мы можем просматривать предсказания (то есть активации конечного слоя нашей нейронной сети) с помощью Learner.get_preds. Она возвращает прогнозы и цели по умолчанию, но поскольку у нас уже есть цели, мы можем игнорировать их, вставив специальную переменную _: . preds,_ = learn.get_preds(dl=[(x,y)]) preds[0] . TensorImage([1.9830e-07, 1.8078e-07, 1.0011e-06, 2.7075e-08, 9.1111e-08, 1.0051e-08, 1.6212e-07, 8.9683e-08, 3.2831e-07, 1.4720e-07, 9.0234e-08, 1.2954e-08, 9.1324e-08, 1.3131e-07, 1.6930e-07, 5.0692e-08, 1.9956e-06, 1.9521e-08, 1.4544e-08, 4.4335e-07, 5.2613e-07, 4.8888e-06, 4.8523e-08, 2.5678e-08, 1.1946e-05, 9.9994e-01, 1.1523e-07, 3.8850e-06, 4.4177e-07, 2.3358e-07, 3.1694e-05, 1.0225e-07, 3.7125e-09, 9.5777e-07, 6.3361e-07, 1.7584e-06, 2.7162e-08]) . Фактические предсказания - это 37 вероятностей между 0 и 1, которые в сумме равняются 1: . len(preds[0]),preds[0].sum() . (37, TensorImage(1.)) . Softmax . В нашей классификационной модели мы используем функцию активации softmax в последнем слое, что гарантирует, что все значения активации находятся между 0 и 1 и что они в сумме дают 1. . Softmax аналогичен сигмовидной функции, которую мы использовали ранее. Как напоминание сигмоид выглядит так: . plot_function(torch.sigmoid, min=-4,max=4) . Теперь подумайте о том, что произойдет, если мы захотим поставить цель получить больше категорий чем две (например, наши 37 пород домашних животных). Это означает, что нам понадобится активация для каждой категории. Мы можем создать, например, нейронную сеть, которая предсказывает тройки и семерки используя для этого две активации, по одной для каждого класса-это будет хорошим первым шагом к созданию более общего подхода. Давайте просто используем некоторые случайные числа со стандартным отклонением 2 (по этому мы умножаем randn на 2) для этого примера, предполагая, что у нас есть 6 изображений и 2 возможные категории (где первый столбец представляет тройки, а второй-семерки): . acts = torch.randn((6,2))*2 acts . tensor([[ 0.6734, 0.2576], [ 0.4689, 0.4607], [-2.2457, -0.3727], [ 4.4164, -1.2760], [ 0.9233, 0.5347], [ 1.0698, 1.6187]]) . Мы не можем просто взять сигмоиду этого непосредственно, так как мы не получаем что сумма значений в строке вероятности того, что это тройка плюс вероятность того, что это семерка равняется одному: . acts.sigmoid() . tensor([[0.6623, 0.5641], [0.6151, 0.6132], [0.0957, 0.4079], [0.9881, 0.2182], [0.7157, 0.6306], [0.7446, 0.8346]]) . Итак, что же на самом деле означают эти активации в бинарном случае? Одна пара активаций просто указывает на относительную вероятность того, входное изображение является тройкой по сравнению с семеркой. Общая сумма, являются ли оба значения высокими или низкими не имеют значения. Все, что имеет значение, это то, что оно выше другого и на сколько. . В связи с тем, что у нас интерес немного другой - рассмотреть двухактивационную версию нашей нейроной сети, то эту проблему можно рассмотреть с другой стороны. Мы можем просто взять разницу между активациями нейронной сети, потому что это отражает, насколько мы более уверены в том, что на вход подается 3, а не 7, а затем взять сигмоиду этого: . (acts[:,0]-acts[:,1]).sigmoid() . tensor([0.6025, 0.5021, 0.1332, 0.9966, 0.5959, 0.3661]) . Второй столбец (вероятность того, что это будет 7) будет тогда просто тем значением, которое вычитается из 1. . Теперь нам нужен способ сделать все это, который будет также работать для более чем двух столбцов. Оказывается он есть и эта функция называемая softmax: . def softmax(x): return exp(x) / exp(x).sum(dim=1, keepdim=True) . Экспоненциальная функция (exp):буквально определяется как e**x, где e-специальное число, приблизительно равное 2,718. Это обратная функция натурального логарифма. Обратите внимание, что exp всегда положительный, и он очень быстро увеличивается! . Давайте проверим, что softmax возвращает те же значения, что и sigmoid для первого столбца, и эти значения вычитаются из 1 для второго столбца: . sm_acts = torch.softmax(acts, dim=1) sm_acts . tensor([[0.6025, 0.3975], [0.5021, 0.4979], [0.1332, 0.8668], [0.9966, 0.0034], [0.5959, 0.4041], [0.3661, 0.6339]]) . &#1051;&#1086;&#1075;&#1072;&#1088;&#1080;&#1092;&#1084;&#1080;&#1095;&#1077;&#1089;&#1082;&#1072;&#1103; &#1042;&#1077;&#1088;&#1086;&#1103;&#1090;&#1085;&#1086;&#1089;&#1090;&#1100; . Когда мы вычисляли потери для нашего MNIST примера в последней главе, то мы использовали функцию: . def mnist_loss(inputs, targets): inputs = inputs.sigmoid() return torch.where(targets==1, 1-inputs, inputs).mean() . Точно так же, как мы перешли от sigmoid к softmax, нам нужно перейти и для функции потерь, чтобы работать не только с двоичной классификацией. Она должна быть способна классифицировать любое количество категорий (в данном случае у нас есть 37 категорий). Наши активации, после softmax, находятся между 0 и 1 и суммируются до 1 для каждой строки в пакете предсказаний. Наши цели-целые числа от 0 до 36. . В двоичном случае мы использовали torch.where для выбора между inputs и (1-inputs). Когда мы рассматриваем двоичную классификацию как общую классификационную задачу с двумя категориями, это на самом деле становится еще проще, потому что (как мы видели в предыдущем разделе) у нас теперь есть два столбца, содержащие эквивалент inputs и (1-inputs). Итак, все, что нам нужно сделать, это выбрать из соответствующего столбца. Давайте попробуем реализовать это в PyTorch. Для нашего воображаемого примера троек и семерок предположим, что это наши метки: . targ = tensor([0,1,0,1,1,0]) . и следующие активации softmax . sm_acts . tensor([[0.6025, 0.3975], [0.5021, 0.4979], [0.1332, 0.8668], [0.9966, 0.0034], [0.5959, 0.4041], [0.3661, 0.6339]]) . Затем для каждого элемента targ мы можем использовать для выбора соответствующего столбца sm_acts с помощью тензорной индексации, например: . idx = range(6) sm_acts[idx, targ] . tensor([0.6025, 0.4979, 0.1332, 0.0034, 0.4041, 0.3661]) . Чтобы точно увидеть, что здесь происходит, давайте сложим все столбцы вместе в таблицу. Здесь первые два столбца - это наши активации, затем у нас есть цели, индекс строки и, наконец, результат, показанный непосредственно выше: . from IPython.display import HTML df = pd.DataFrame(sm_acts, columns=[&quot;3&quot;,&quot;7&quot;]) df[&#39;targ&#39;] = targ df[&#39;idx&#39;] = idx df[&#39;loss&#39;] = sm_acts[range(6), targ] t = df.style.hide_index() #To have html code compatible with our script html = t._repr_html_().split(&#39;&lt;/style&gt;&#39;)[1] html = re.sub(r&#39;&lt;table id=&quot;([^&quot;]+)&quot; s*&gt;&#39;, r&#39;&lt;table &gt;&#39;, html) display(HTML(html)) . 3 7 targ idx loss . 0.602469 | 0.397531 | 0 | 0 | 0.602469 | . 0.502065 | 0.497935 | 1 | 1 | 0.497935 | . 0.133188 | 0.866811 | 0 | 2 | 0.133188 | . 0.996640 | 0.003360 | 1 | 3 | 0.003360 | . 0.595949 | 0.404051 | 1 | 4 | 0.404051 | . 0.366118 | 0.633882 | 0 | 5 | 0.366118 | . Глядя на эту таблицу, вы можете видеть, что последний столбец может быть вычислен, взяв столбцы targ и idx в качестве индексов в двухколоночной матрице, содержащей столбцы 3 и 7. Вот что на самом деле делает sm_acts[idx, targ]. . Действительно интересно то, что это на самом деле работает так же хорошо с более чем двумя колонками. Чтобы увидеть это, рассмотрим, что произойдет, если мы добавим столбец активации для каждой цифры (от 0 до 9), а targ будет содержать число от 0 до 9. Пока столбцы активации суммируются до 1 (а это так и будет, если мы используем softmax), у нас будет функция потерь, которая показывает, насколько хорошо мы предсказываем каждую цифру. . Мы только выбираем потери из столбца, содержащего правильную метку. Нам не нужно рассматривать другие столбцы, потому что при использовании softmax они складываются до 1 минус активация, соответствующая правильной метке. Поэтому, получая активацию для правильной метки как можно выше, мы также уменьшаем активацию остальных столбцов. . В PyTorch предоставлена функция, которая делает точно то же самое, что и sm_acts[range(n), targ] (за исключением того, что она принимает отрицательное значение), называемую nll_loss (NLL означает отрицательное логарифмическое правдоподобие): . -sm_acts[idx, targ] . tensor([-0.6025, -0.4979, -0.1332, -0.0034, -0.4041, -0.3661]) . F.nll_loss(sm_acts, targ, reduction=&#39;none&#39;) . tensor([-0.6025, -0.4979, -0.1332, -0.0034, -0.4041, -0.3661]) . &#1042;&#1086;&#1079;&#1100;&#1084;&#1077;&#1084; &#1083;&#1086;&#1075;&#1072;&#1088;&#1080;&#1092;&#1084; . Функция, которую мы видели в предыдущем разделе, довольно хорошо работает как функция потерь, но мы можем сделать ее немного лучше. Проблема в том, что мы используем вероятности, а вероятности не могут быть меньше 0 или больше 1. Это означает, что для нашей модели нет разницы между числом 0,99 и 0,999. Действительно, эти цифры очень близки друг к другу, но с другой стороны 0,999 в 10 раз более точное, чем 0,99. Итак, мы хотим преобразовать наши числа от 0 до 1, чтобы они лежали между отрицательной бесконечностью и положительной бесконечностью. Существует математическая функция, которая делает это: логарифм (доступен как torch.log). Он не определен для чисел меньше 0 и выглядит следующим образом: . plot_function(torch.log, min=0,max=4) . Когда мы сначала берем softmax, а затем логарифмическую вероятность этого, эта комбинация называется кросс-энтропийной потерей. В PyTorch она доступна как nn.CrossEntropyLoss(что на практике фактически делает log_softmax и nll_loss): . loss_func = nn.CrossEntropyLoss() . Как видите, это класс. Его создание дает вам объект, который ведет себя как функция: . loss_func(acts, targ) . tensor(1.8045) . Все функции потерь PyTorch предоставляются в двух формах: класс, только что показанный выше, а также простая функциональная форма, доступная в пространстве имен F: . F.cross_entropy(acts, targ) . tensor(1.8045) . Любой из них прекрасно работает и может быть использован в любой ситуации. Мы заметили, что большинство людей склонны использовать версию класса, и она чаще используется в официальных документах и примерах PyTorch, поэтому мы тоже будем использовать ее. . По умолчанию функции потерь PyTorch принимают среднее значение потерь всех элементов. Вы можете использовать reduction= &#39;none&#39;, чтобы отключить это: . nn.CrossEntropyLoss(reduction=&#39;none&#39;)(acts, targ) . tensor([0.5067, 0.6973, 2.0160, 5.6958, 0.9062, 1.0048]) . &#1048;&#1085;&#1090;&#1077;&#1088;&#1087;&#1088;&#1077;&#1090;&#1072;&#1094;&#1080;&#1103; &#1084;&#1086;&#1076;&#1077;&#1083;&#1080; . Очень трудно интерпретировать функции потерь напрямую, потому что они предназначены для того, чтобы быть вещами, которые компьютеры могут дифференцировать и оптимизировать, а не вещами, которые люди могут понять. Вот почему у нас есть метрики. Они не используются в процессе оптимизации, а просто помогают нам, бедным людям, понять, что происходит. В этом случае наша точность уже выглядит довольно хорошо! Так где же мы совершаем ошибки? . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix(figsize=(12,12), dpi=60) . О боже—в этом случае матрицу ошибок очень трудно прочитать. У нас есть 37 различных пород домашних животных, а это значит, что у нас есть 37×37 записей в этой гигантской матрице! Вместо этого мы можем использовать метод most_confused, который просто показывает нам ячейки матрицы ошибок с наиболее неверными предсказаниями (здесь, по крайней мере, с 5 или более): . interp.most_confused(min_val=5) . [(&#39;Ragdoll&#39;, &#39;Birman&#39;, 9), (&#39;Bengal&#39;, &#39;Abyssinian&#39;, 5), (&#39;american_pit_bull_terrier&#39;, &#39;american_bulldog&#39;, 5), (&#39;american_pit_bull_terrier&#39;, &#39;staffordshire_bull_terrier&#39;, 5)] . &#1059;&#1083;&#1091;&#1076;&#1096;&#1077;&#1085;&#1080;&#1077; &#1085;&#1072;&#1096;&#1077;&#1081; &#1084;&#1086;&#1076;&#1077;&#1083;&#1080; . &#1048;&#1089;&#1082;&#1072;&#1090;&#1077;&#1083;&#1100; &#1089;&#1082;&#1086;&#1088;&#1086;&#1089;&#1090;&#1080; &#1086;&#1073;&#1091;&#1095;&#1077;&#1085;&#1080;&#1103; (The Learning Rate Finder) . Одна из самых важных вещей, которую мы можем сделать при обучении модели, - это убедиться, что у нас есть правильная скорость обучения. Если наша скорость обучения слишком низка, для обучения нашей модели может потребоваться много-много эпох. Это не только отнимает время, но и означает, что у нас могут возникнуть проблемы с переобучением, потому что каждый раз, когда мы полностью проходим через данные, мы даем нашей модели шанс запомнить их. . Так что давайте просто сделаем нашу скорость обучения действительно высокой, не так ли? Конечно, давайте попробуем и посмотрим, что получится: . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fine_tune(1, base_lr=0.1) . epoch train_loss valid_loss error_rate time . 0 | 2.560477 | 3.031554 | 0.379567 | 11:09 | . epoch train_loss valid_loss error_rate time . 0 | 3.068019 | 1.584792 | 0.429635 | 15:03 | . Это выглядит не очень хорошо. Вот что произошло. Оптимизатор шагнул в правильном направлении, но шагнул так далеко, что полностью перешагнул минимальную потерю. Повторяя это несколько раз, он становится все дальше и дальше, а не ближе и ближе! . Что мы делаем, чтобы найти идеальную скорость обучения-не слишком высокую и не слишком низкую? В 2015 году исследователю Лесли Смиту пришла в голову блестящая идея, получившая название learning rate finder. Его идея состояла в том, чтобы начать с очень, очень маленькой скорости обучения, чего-то настолько маленького, что мы никогда не ожидали бы, что это будет слишком большим, чтобы справиться. Мы используем это для одной мини-партии, находим, каковы потери после этого, а затем увеличиваем скорость обучения на некоторый процент (например, удваивая ее каждый раз). Затем мы делаем еще одну мини-партию, отслеживаем потери и снова удваиваем скорость обучения. Мы продолжаем делать это до тех пор, пока потеря не станет хуже, а не лучше. Это тот момент, когда мы знаем, что зашли слишком далеко. Затем мы выбираем скорость обучения немного ниже этой точки. Наш совет-выбрать либо то, либо другое: . На порядок меньше, чем там, где была достигнута минимальная ошибка (то есть минимум, деленный на 10) | Последняя точка, где ошибки явно уменьшались | . Искатель скорости обучения вычисляет эти точки на кривой, чтобы помочь вам. Оба эти правила обычно дают примерно одинаковое значение. В первой главе мы не указывали скорость обучения, используя значение по умолчанию из библиотеки fastai (которое равно 1e-3): . learn = cnn_learner(dls, resnet34, metrics=error_rate) lr_min,lr_steep = learn.lr_find() . print(f&quot;Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}&quot;) . Minimum/10: 1.20e-02, steepest point: 4.37e-03 . На этом графике мы видим, что в диапазоне от 1е-6 до 1е-3 на самом деле ничего не происходит, и модель не обучается. Затем ошибки начинают уменьшаться, пока не достигнут минимума, а затем снова увеличиваются. Мы не хотим, чтобы скорость обучения превышала 1е-1. Но 1е-1 уже то же высоко: на этом этапе мы вышли из периода, когда ошибки неуклонно снижались. . На этом графике скорости обучения кажется, что скорость обучения около 3e-3 была бы подходящей, поэтому давайте выберем ее: . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fine_tune(2, base_lr=3e-3) . epoch train_loss valid_loss error_rate time . 0 | 1.305556 | 0.348068 | 0.110284 | 11:09 | . epoch train_loss valid_loss error_rate time . 0 | 0.561989 | 0.377429 | 0.108254 | 14:55 | . 1 | 0.334126 | 0.248589 | 0.073748 | 14:57 | . &#1056;&#1072;&#1079;&#1084;&#1086;&#1088;&#1072;&#1078;&#1080;&#1074;&#1072;&#1085;&#1080;&#1077; &#1080; Transfer Learning (&#1090;&#1088;&#1072;&#1085;&#1089;&#1092;&#1077;&#1088;&#1085;&#1086;&#1077; &#1086;&#1073;&#1091;&#1095;&#1077;&#1085;&#1080;&#1077;) . Когда мы создаем модель из предварительно подготовленной сети, fastai автоматически замораживает все предварительно подготовленные слои для нас. Когда мы вызываем метод fine_tune fastai делает две вещи: . Обучает случайно добавленные слои для одной эпохи, а все остальные слои оставляет заморожеными | Размораживает все слои и тренирует их все на требуемое количество эпох | . Так что давайте попробуем сделать это вручную сами. Сначала мы будем обучать случайно добавленные слои для трех эпох, используя fit_one_cycle. Как уже упоминалось в . learn.fine_tune?? . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fit_one_cycle(3, 3e-3) . epoch train_loss valid_loss error_rate time . 0 | 1.195682 | 0.359648 | 0.116373 | 11:01 | . 1 | 0.536354 | 0.268985 | 0.083897 | 10:54 | . 2 | 0.337108 | 0.244635 | 0.077808 | 10:59 | . Затем мы разморозим модель: . learn.unfreeze() . и снова запустите lr_find, потому что наличие большего количества слоев для обучения и весов, которые уже были обучены в течение трех эпох, означает, что наша ранее найденная скорость обучения больше не подходит: . learn.lr_find() . SuggestedLRs(lr_min=1.3182566908653825e-05, lr_steep=6.309573450380412e-07) . Обратите внимание, что график немного отличается от того, когда у нас были случайные веса: у нас нет того резкого спуска, который указывает на то, что модель обучается. Это потому, что наша модель уже прошла обучение. Здесь мы имеем несколько плоскую область перед резким увеличением, и мы должны взять точку задолго до этого резкого увеличения—например, 1е-5. Точка с максимальным градиентом-это не то, что мы ищем здесь, и ее следует игнорировать. . Давайте тренироваться с подходящей скоростью обучения: . learn.fit_one_cycle(6, lr_max=1e-5) . epoch train_loss valid_loss error_rate time . 0 | 0.261118 | 0.245165 | 0.073072 | 15:25 | . 1 | 0.244202 | 0.230939 | 0.068336 | 14:58 | . 2 | 0.222367 | 0.231852 | 0.069012 | 14:53 | . 3 | 0.216706 | 0.226638 | 0.066306 | 14:52 | . 4 | 0.193296 | 0.225428 | 0.066982 | 13:08 | . 5 | 0.184676 | 0.225443 | 0.067659 | 14:22 | . Discriminative Learning Rates . fasta позволяет передавать объект slice Python в любом месте, где предполагается скорость обучения. Первое переданное значение будет скоростью обучения в самом раннем слое нейронной сети, а второе-скоростью обучения в последнем слое. Промежуточные слои будут иметь скорости обучения, которые мультипликативно равноудалены во всем этом диапазоне. Давайте воспользуемся этим подходом, чтобы повторить предыдущее обучение, но на этот раз мы установим только самый низкий уровень нашей сети на скорость обучения 1e-6; другие слои будут масштабироваться до 1e-4. Давайте немного потренируемся и посмотрим что получится: . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fit_one_cycle(3, 3e-3) learn.unfreeze() learn.fit_one_cycle(12, lr_max=slice(1e-6,1e-4)) . epoch train_loss valid_loss error_rate time . 0 | 1.173580 | 0.367213 | 0.116373 | 00:36 | . 1 | 0.539504 | 0.270600 | 0.089986 | 00:35 | . 2 | 0.346232 | 0.240070 | 0.079161 | 00:35 | . epoch train_loss valid_loss error_rate time . 0 | 0.268828 | 0.231327 | 0.075101 | 00:44 | . 1 | 0.260505 | 0.225987 | 0.073748 | 00:44 | . 2 | 0.246831 | 0.228189 | 0.074425 | 00:44 | . 3 | 0.220918 | 0.224612 | 0.075101 | 00:43 | . 4 | 0.195331 | 0.215086 | 0.066982 | 00:44 | . 5 | 0.171444 | 0.211952 | 0.071719 | 00:43 | . 6 | 0.148516 | 0.216797 | 0.069689 | 00:44 | . 7 | 0.140547 | 0.210381 | 0.066306 | 00:44 | . 8 | 0.147587 | 0.211248 | 0.063599 | 00:44 | . 9 | 0.136450 | 0.208178 | 0.064276 | 00:43 | . 10 | 0.117142 | 0.208999 | 0.064953 | 00:43 | . 11 | 0.114411 | 0.209443 | 0.060893 | 00:44 | . Теперь тонкая настройка работает отлично! . fastai может показать нам график ошибок при обучении и валидации: . learn.recorder.plot_loss() . Как вы можете видеть, потеря тренировок становится все лучше и лучше. Но обратите внимание, что в конечном итоге улучшение потери валидации замедляется, а иногда даже ухудшается! Это точка, в которой модель начинает перестраиваться. В частности, модель становится слишком самоуверенной в своих предсказаниях. Но это не значит, что она становится обязательно менее точной. Взгляните на таблицу результатов обучения за каждую эпоху, и вы часто увидите, что точность продолжает улучшаться, даже когда потеря валидации становится хуже. В конце концов, важна ваша точность или, в более общем смысле, выбранные вами показатели, а не потери. Потеря-это просто функция, которую мы дали компьютеру, чтобы помочь нам оптимизировать. . Еще одно решение, которое вы должны принять при обучении модели, - это как долго тренироваться. Мы рассмотрим это в следующий раз. . Deeper Architectures . Недостаток более глубоких архитектур заключается в том, что их обучение занимает гораздо больше времени. Одна из техник, которая может значительно ускорить процесс, - это тренировка смешанной точности. Это относится к использованию менее точных чисел (Число́ полови́нной то́чности (half-precision floating point) также называемое fp16) там, где это возможно во время обучения. Когда мы пишем эти слова в начале 2020 года, почти все современные графические процессоры NVIDIA поддерживают специальную функцию, называемую тензорными ядрами, которая может значительно ускорить обучение нейронных сетей в 2-3 раза. Они также требуют гораздо меньше памяти GPU. Чтобы включить эту функцию в fastai, просто добавьте to_fp16() после создания вашего Learner (вам также нужно импортировать модуль). . Вы не можете заранее знать, какая архитектура лучше всего подходит для вашей конкретной проблемы—вам нужно попробовать потренироваться. Так что давайте теперь попробуем ResNet-50 со смешанной точностью: . from fastai.callback.fp16 import * learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16() learn.fine_tune(6, freeze_epochs=3) . epoch train_loss valid_loss error_rate time . 0 | 1.418004 | 0.275086 | 0.090663 | 00:58 | . 1 | 0.594283 | 0.286878 | 0.095399 | 00:59 | . 2 | 0.433570 | 0.260211 | 0.084574 | 00:58 | . epoch train_loss valid_loss error_rate time . 0 | 0.283216 | 0.237705 | 0.075778 | 01:11 | . 1 | 0.300372 | 0.374852 | 0.104871 | 01:11 | . 2 | 0.263926 | 0.244888 | 0.069689 | 01:11 | . 3 | 0.150826 | 0.218107 | 0.062246 | 01:12 | . 4 | 0.082293 | 0.197206 | 0.059540 | 01:12 | . 5 | 0.052833 | 0.192704 | 0.058187 | 01:12 | . В этом случае мы не видим явного выигрыша от более глубокой модели. Это полезно помнить—большие модели не обязательно являются лучшими моделями для вашего конкретного случая! Обязательно попробуйте небольшие модели, прежде чем приступать к масштабированию. .",
            "url": "https://zmey56.github.io/blog//russian/fast.ai/solution/2020/12/21/05-pet-breeds.html",
            "relUrl": "/russian/fast.ai/solution/2020/12/21/05-pet-breeds.html",
            "date": " • Dec 21, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Russian - Fastbook Chapter 5 questionnaire solutions",
            "content": "Ответы на русском языке на вопросы к пятой части курса Deep Learning 2020 на Fast.ai. Если есть притензии к переводу, как и к осталььным частям прошу писать в коментариях - поправлю. . 1. Почему мы сначала изменяем размер до большого размера на процессоре, а затем до меньшего размера на графическом процессоре? . Эта концепция известна как проклеивание (presizing). Прирост данных часто применяется к изображениям, и на самом деле это делается на графическом процессоре. Однако увеличение объема данных может привести к ухудшению качества и появлению артефактов, особенно на краях. Поэтому, чтобы свести к минимуму ухудшение качества данных, дополнения выполняются на более крупном изображении, а затем выполняется RandomResizeCrop изменение размера до требуемого размера изображения. . 2. Если вы не знакомы с регулярными выражениями, найдите учебник по регулярным выражениям и задач и выполните их. . Выполняется самостоятельно . 3. Каковы два наиболее распространенных способа предоставления данных для большинства наборов данных глубокого обучения? . Отдельные файлы, представляющие элементы данных, такие как текстовые документы или изображения. | Таблица данных, например в формате CSV, где каждая строка является элементом и может включать имена файлов, обеспечивающие связь между данными в таблице и данными в других форматах, таких как текстовые документы и изображения. | . 4. Посмотрите документацию на L и попробуйте использовать несколько новых методов. . Выполняется самостоятельно . 5. Посмотрите документацию для модуля Python pathlib и попробуйте использовать несколько методов класса Path. . Выполняется самостоятельно . 6. Приведите два примера того, как преобразования изображений могут ухудшить качество данных. . Вращение может являться причиной пустых областей в конечном изображении | Другие операции могут потребовать интерполяции, которая основана на исходных пикселях изображения и в результате более низкое качество изображения | . 7. Какой метод в fastai для просмотра данных в загрузчике данных (DataLoader)? . DataLoader.show_batch . 8. Какой метод в fastai, чтобы помочь вам отладить DataBlock? . DataBlock.summary . 9. Следует ли вам отложить обучение модели до тех пор, пока вы не очистите свои данные полностью? . Нет. Лучше всего первоначально создать базовую модель. . 10. Что за два метода объединены в кросс-энтропию в PyTorch? . Кросс энтропийные потери представляет собой комбинацию функции Softmax и отрицательной логарифмической потери правдоподобия. . 11. Каковы два свойства активаций, которые гарантирует softmax? Почему это так важно? . Выходные данные в сумме дают один и модель может предсказать только один класс. Кроме того, усиливаются небольшие изменения в выходных активациях, что полезно, поскольку это означает, что модель выберет метку с более высокой увереностью (хорошо для проблем с конкретными метками). . 12. Когда вы хотите, чтобы ваши активации не имели этих свойств? . Когда у вас есть проблемы с классификацией нескольких меток (возможно более одной метки). . 13. Вычислите столбцы exp и softmax. . ПРОПУЩЕНО . 14. Почему мы не можем использовать torch.where для создания функции потерь для наборов данных, где наша метка может иметь более двух категорий? . Потому что torch.where может выбирать только между двумя возможностями, в то время как для многоклассовой классификации у нас есть необходимость в выборе нескольких вариантов. . 15. Каково значение log (-2)? Почему? . Значение не определено. Логарифм является обратной экспоненциальной функцией, а экспоненциальная функция всегда положительна, независимо от того, какое значение передается. Таким образом, логарифм не определен для отрицательных значений. . **16. Каковы два хороших эмпирических правила для выбора скорости обучения при использовании искателя скорости обучения? . Любой из этих двух пунктов должен быть использован для скорости обучения: . на порядок меньше, чем там, где была достигнута минимальная потеря (то есть минимум, деленный на 10) | последняя точка, где потеря явно уменьшилась. | . 17. Какие два шага делает метод fine_tune? . Тренирует новую голову (со случайными весами) в течение одной эпохи | Разморозет все слои и тренирует их все для требуемого количества эпох | . 18. Как получить исходный код метода или функции в Jupyter notebook? . Использовать ?? после функции. Пример: DataBlock.summary?? . 19. Что такое дискриминационные показатели обучения? . Дискриминативные скорости обучения относятся к тренировочному трюку использования различных скоростей обучения для разных слоев модели. Это обычно используется в трансфертном обучении. Идея заключается в том, что при обучении предварительно подготовленной модели вы не хотите резко менять более ранние слои, поскольку она содержит информацию о простых объектах, таких как ребра и формы. Но более поздние слои могут быть изменены немного больше, поскольку они могут содержать информацию о чертах лица или других объектах, которые могут не иметь отношения к вашей задаче. Таким образом, более ранние слои имеют более низкую скорость обучения, а более поздние слои имеют более высокую скорость обучения. . 20. Как объект slice на языке Python интерпретируется при передаче в качестве скорости обучения в fastai? . Первое значение объекта среза - это скорость обучения для самого раннего слоя, а второе-скорость обучения для последнего слоя. Промежуточные слои будут иметь скорости обучения, которые мультипликативно равноудалены во всем этом диапазоне. . 21. Почему ранняя остановка является плохим выбором при использовании одного цикла тренировок? . Если используется ранняя остановка, обучение может не успеть достичь более низких значений скорости на графике, что могло бы способствовать совершенствованию модели. Поэтому рекомендуется переучивать модель и выбирать количество эпох исходя из того, где были найдены предыдущие лучшие результаты. . 22. В чем разница между resnet 50 и resnet101? . Числа 50 и 101 относятся к числу слоев в моделях. Таким образом, ResNet101-это более крупная модель с большим количеством слоев по сравнению с ResNet50. Эти варианты моделей обычно используются, поскольку существуют модели с предварительно подготовленными весами ImageNet. . 23. Что делает to_fp16? . Это позволяет проводить обучение со смешанной точностью, в котором для ускорения обучения используются менее точные числа. .",
            "url": "https://zmey56.github.io/blog//markdown/fastai/russian/deep%20learning/2020/12/20/fastai-chapter5-solution.html",
            "relUrl": "/markdown/fastai/russian/deep%20learning/2020/12/20/fastai-chapter5-solution.html",
            "date": " • Dec 20, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Russian - Solution Lesson 4 on Fast.ai",
            "content": "Следующий блокнот с решением к третьему или четвертому уроку. Честно сказать, то это не я не определился, а просто у составителей третий урок называется &quot;этика&quot; и я ему не придал должного значения. Там только почитать. У данный блокнот относиться ко второй части третьего урока. . В этом уроке будет создаваться модель, которая может классифицировать изображение как 3 или 7. Для это загрузим образцы MNIST содержащие изображения только этих цифр: . MNIST содержит изображения рукописных цифр, собранные Национальным институтом стандартов и технологий и сведенные в набор данных машинного обучения Янном Лекуном и его коллегами. Лекун использовал MNIST в 1998 году в Lenet-5, первой компьютерной системе, продемонстрировавшей практически полезное распознавание рукописных цифр. Это был один из самых важных прорывов в истории искусственного интеллекта. . path = untar_data(URLs.MNIST_SAMPLE) . Посмотреть, что находится в каталоге можно при помощи метода ls, добавленного в fastai. Этот метод возвращает объект специального класса fastai под названием L, который помимо функциональных возможностей списков Python, также может многое другое. Одна из его удобных особенностей заключается в том, что при выводе на печать он отображает количество элементов перед их перечислением (если их больше 10, он просто показывает первые несколько): . path.ls() . (#3) [Path(&#39;labels.csv&#39;),Path(&#39;valid&#39;),Path(&#39;train&#39;)] . Набор значений MNIST имеет стандартную компоновку данных для машинного обучения: отдельные папки для обучающего набора и проверки (и/или тестового множества). Дальше посмотрим, что находится внутри тренировочного набора: . (path/&#39;train&#39;).ls() . (#2) [Path(&#39;train/7&#39;),Path(&#39;train/3&#39;)] . В нем есть папки, содержащие цифры 3 и 7. Благодаря тому, что изображения раскиданы по папкам - на языке машинного обучения они получили метки &quot;3&quot; и &quot;7&quot;. Давайте заглянем в одну из этих папок (сортировку использована для того, чтобы мы получили один и тот же порядок файлов): . threes = (path/&#39;train&#39;/&#39;3&#39;).ls().sorted() sevens = (path/&#39;train&#39;/&#39;7&#39;).ls().sorted() threes . (#6131) [Path(&#39;train/3/10.png&#39;),Path(&#39;train/3/10000.png&#39;),Path(&#39;train/3/10011.png&#39;),Path(&#39;train/3/10031.png&#39;),Path(&#39;train/3/10034.png&#39;),Path(&#39;train/3/10042.png&#39;),Path(&#39;train/3/10052.png&#39;),Path(&#39;train/3/1007.png&#39;),Path(&#39;train/3/10074.png&#39;),Path(&#39;train/3/10091.png&#39;)...] . Как и следовало ожидать в ней полно изображений. Дальше можно вывести одно из них: . im3_path = threes[1] im3 = Image.open(im3_path) im3 . Здесь мы используем класс Image из библиотеки Python Imaging Library (PIL), которая является наиболее широко используемым пакетом Python для работы с растровым изображением. Jupyter так же приспособлен к работе с PIL. . В компьютере все представлено в виде чисел. Чтобы просмотреть числа, составляющие это изображение, мы должны преобразовать его в массив NumPy или Тензор PyTorch. Например, вот как выглядит часть изображения, преобразованная в массив NumPy: . array(im3)[4:10,4:10] . array([[ 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 29], [ 0, 0, 0, 48, 166, 224], [ 0, 93, 244, 249, 253, 187], [ 0, 107, 253, 253, 230, 48], [ 0, 3, 20, 20, 15, 0]], dtype=uint8) . 4:10 указывает на то, что нам необходимы строки с индексом 4 (включено) до 10 (не включено) и то же самое для столбцов. NumPy индексирует сверху вниз и слева направо. Вот то же самое для Тензора PyTorch: . tensor(im3)[4:10,4:10] . tensor([[ 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 29], [ 0, 0, 0, 48, 166, 224], [ 0, 93, 244, 249, 253, 187], [ 0, 107, 253, 253, 230, 48], [ 0, 3, 20, 20, 15, 0]], dtype=torch.uint8) . Можно взять только ту часть массива, в которой находятся часть цифр, отличных от нуля, а затем использовать Pandas DataFrame для использования заполнения градиентом оттенков серого ячеек, которое ясно покажет как создается изображение из значений пикселей: . im3_t = tensor(im3) df = pd.DataFrame(im3_t[4:15,4:22]) df.style.set_properties(**{&#39;font-size&#39;:&#39;6pt&#39;}).background_gradient(&#39;Greys&#39;) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . 0 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 0 | 0 | 0 | 0 | 0 | 29 | 150 | 195 | 254 | 255 | 254 | 176 | 193 | 150 | 96 | 0 | 0 | 0 | . 2 0 | 0 | 0 | 48 | 166 | 224 | 253 | 253 | 234 | 196 | 253 | 253 | 253 | 253 | 233 | 0 | 0 | 0 | . 3 0 | 93 | 244 | 249 | 253 | 187 | 46 | 10 | 8 | 4 | 10 | 194 | 253 | 253 | 233 | 0 | 0 | 0 | . 4 0 | 107 | 253 | 253 | 230 | 48 | 0 | 0 | 0 | 0 | 0 | 192 | 253 | 253 | 156 | 0 | 0 | 0 | . 5 0 | 3 | 20 | 20 | 15 | 0 | 0 | 0 | 0 | 0 | 43 | 224 | 253 | 245 | 74 | 0 | 0 | 0 | . 6 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 249 | 253 | 245 | 126 | 0 | 0 | 0 | 0 | . 7 0 | 0 | 0 | 0 | 0 | 0 | 0 | 14 | 101 | 223 | 253 | 248 | 124 | 0 | 0 | 0 | 0 | 0 | . 8 0 | 0 | 0 | 0 | 0 | 11 | 166 | 239 | 253 | 253 | 253 | 187 | 30 | 0 | 0 | 0 | 0 | 0 | . 9 0 | 0 | 0 | 0 | 0 | 16 | 248 | 250 | 253 | 253 | 253 | 253 | 232 | 213 | 111 | 2 | 0 | 0 | . 10 0 | 0 | 0 | 0 | 0 | 0 | 0 | 43 | 98 | 98 | 208 | 253 | 253 | 253 | 253 | 187 | 22 | 0 | . &#1055;&#1077;&#1088;&#1074;&#1072;&#1103; &#1087;&#1086;&#1087;&#1099;&#1090;&#1082;&#1072;: &#1057;&#1093;&#1086;&#1076;&#1089;&#1090;&#1074;&#1086; &#1087;&#1080;&#1082;&#1089;&#1077;&#1083;&#1077;&#1081; . Создадим списки, содержащий все наши тензоры 3 и отдельно 7 вместе. После этого проверим их размеры. . seven_tensors = [tensor(Image.open(o)) for o in sevens] three_tensors = [tensor(Image.open(o)) for o in threes] len(three_tensors),len(seven_tensors) . (6131, 6265) . Дальше проверим на одном из изображений, что оно выглядит нормально. Так значения переведены в тензоры, которые Jupyter , будет распечатывать как матрицы, а не изображения, то нужно использовать функцию show_image из fastai. . show_image(three_tensors[1]); . При помощи функции stack из PyTorch объединим все тензоры в один. Так как ряд операции в PyTorch, такие как например взятие среднего значения, требуют использование чисел с плавающей точкой, то приведем их дальше к типу float. Если полученные значения изображения с плавающей точкой, то обычно используют их в диапазоне от 0 до 1 для чего делим на 255. . Функция shape позволяет узнать размеры тензора. В результате получим 6131 изображений 28 на 28 пикселей. . stacked_sevens = torch.stack(seven_tensors).float()/255 stacked_threes = torch.stack(three_tensors).float()/255 stacked_threes.shape . torch.Size([6131, 28, 28]) . Используя len можно получить размерность тензора (rank - количество осей) . len(stacked_threes.shape) . 3 . Также можно получить rank тензора с помощью ndim: . stacked_threes.ndim . 3 . Дальше находим &quot;идеальную&quot; 3. Для этого вычисляем среднее всех тензоров по оси 0 и выведемм его на печать . mean3 = stacked_threes.mean(0) show_image(mean3); . Сделаем то же самое для 7 . mean7 = stacked_sevens.mean(0) show_image(mean7); . Возьмем тройку . a_3 = stacked_threes[1] show_image(a_3); . Дальше измерим растояние двумя методами: . при помощи среднего значения суммы абсолютного значения разностей (абсолютное значение-это модуль числа). Называется средней абсолютной разницей или нормой L1 | при помощи среднего значения квадрата разностей и квадратного корня. Называется среднеквадратичной ошибкой (RMSE) или нормой L2. | . dist_3_abs = (a_3 - mean3).abs().mean() dist_3_sqr = ((a_3 - mean3)**2).mean().sqrt() dist_3_abs,dist_3_sqr . (tensor(0.1114), tensor(0.2021)) . dist_7_abs = (a_3 - mean7).abs().mean() dist_7_sqr = ((a_3 - mean7)**2).mean().sqrt() dist_7_abs,dist_7_sqr . (tensor(0.1586), tensor(0.3021)) . В обоих случаях расстояние между исследуемым 3 и &quot;идеальным&quot; 3 меньше, чем расстояние до идеального 7. Таким образом простая модель даст точный прогноз. . В PyTorch предоставлены обе эти функции как функции потерь (loss functions): . F.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt() . (tensor(0.1586), tensor(0.3021)) . NumPy &#1084;&#1072;&#1089;&#1089;&#1080;&#1074; &#1080; PyTorch &#1090;&#1077;&#1085;&#1079;&#1086;&#1088; . Чтобы создать массив или тензор, передайте список (или список списков, или список списков списков и т. д.) в array() или tensor(): . data = [[1,2,3],[4,5,6]] arr = array (data) tns = tensor(data) . arr # numpy . array([[1, 2, 3], [4, 5, 6]]) . tns # pytorch . tensor([[1, 2, 3], [4, 5, 6]]) . Все последующие операции показаны на тензорах, но синтаксис и результаты для массивов NumPy идентичны. . Выбрать вторую строку (индексация с 0): . tns[1] . tensor([4, 5, 6]) . или столбец, используя : для обозначения всех строк: . tns[:,1] . tensor([2, 5]) . Так же можно использовать питоновские срезы Python ([start:end]), чтобы выбрать часть строки или столбца: . tns[1,1:3] . tensor([5, 6]) . Можно использовать стандартные операторы, такие как +, -, *, /: . tns+1 . tensor([[2, 3, 4], [5, 6, 7]]) . Так же у тензора есть тип . tns.type() . &#39;torch.LongTensor&#39; . Тип будет автоматически меняться по мере необходимости, например, с int на float: . tns*1.5 . tensor([[1.5000, 3.0000, 4.5000], [6.0000, 7.5000, 9.0000]]) . &#1042;&#1099;&#1095;&#1080;&#1089;&#1083;&#1077;&#1085;&#1080;&#1077; &#1084;&#1077;&#1090;&#1088;&#1080;&#1082; . Первым шагом создаем тензоры для 3 и 7 из валиадационного каталога для последующей оценки полученной модели . valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;valid&#39;/&#39;3&#39;).ls()]) valid_3_tens = valid_3_tens.float()/255 valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;valid&#39;/&#39;7&#39;).ls()]) valid_7_tens = valid_7_tens.float()/255 valid_3_tens.shape,valid_7_tens.shape . (torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28])) . Дальше напишем функцию, которая вычисляет среднюю абсолютную ошибку, используя выражение, очень похожее на то, которое было в прошлом разделе: . def mnist_distance(a,b): return (a-b).abs().mean((-1,-2)) mnist_distance(a_3, mean3) . tensor(0.1114) . После вычислим растояние валиадационного набора до идеальной 3 и на выходе получим вектор . valid_3_dist = mnist_distance(valid_3_tens, mean3) valid_3_dist, valid_3_dist.shape . (tensor([0.1290, 0.1223, 0.1380, ..., 0.1337, 0.1132, 0.1097]), torch.Size([1010])) . Как видно ошибка несоответствия размеров не возникает, так как в этот раз используется broadcasting - автоматическое расширение тензора с меньшим размером (rank). . Пример операции для тензоров с одинаковым количеством измеренийа после с разным: . tensor([1,2,3]) + tensor([1,1,1]) . tensor([2, 3, 4]) . (valid_3_tens-mean3).shape . torch.Size([1010, 28, 28]) . Дальше создадим функцию mnist_distance, которая будет выяснять является ли изображение 3 или нет используя следующую логику: если расстояние между рассматриваемой цифрой и идеальным 3 меньше расстояния до идеального 7, то это 3: . def is_3(x): return mnist_distance(x,mean3) &lt; mnist_distance(x,mean7) . Проверим на нашем примере: . is_3(a_3), is_3(a_3).float() . (tensor(True), tensor(1.)) . Дальше протестируем на всем наборе . is_3(valid_3_tens) . tensor([True, True, True, ..., True, True, True]) . Теперь мы можем вычислить точность для каждого числа из троек и семерок, взяв среднее значение этой функции для всех троек и обратную функцию для всех семерок: . accuracy_3s = is_3(valid_3_tens).float() .mean() accuracy_7s = (1 - is_3(valid_7_tens).float()).mean() accuracy_3s,accuracy_7s,(accuracy_3s+accuracy_7s)/2 . (tensor(0.9168), tensor(0.9854), tensor(0.9511)) . &#1057;&#1090;&#1086;&#1093;&#1072;&#1089;&#1090;&#1080;&#1095;&#1077;&#1089;&#1082;&#1080;&#1081; &#1075;&#1088;&#1072;&#1076;&#1080;&#1077;&#1085;&#1090;&#1085;&#1099;&#1081; &#1089;&#1087;&#1091;&#1089;&#1082; (Stochastic Gradient Descent) (SGD) . Шаги, которые потребуются, чтобы превратить функцию по определению троек и семерек в классификатор машинного обучения: . Инициализируйте веса. | Для каждого изображения использовать эти веса, чтобы предсказать, будет ли оно 3 или 7. | Исходя из полученных прогнозов, рассчитайте, насколько качественная полученная модель (расчитать ее потерю). | Вычислите градиент, который измеряется для каждого веса и как изменение этого веса изменяет потерю | Изменение всех весов, основанное на прошлом вычислении. | Вернитесь к Шагу 2 и повторите процесс. | Повторяйте до тех пор, пока не решите остановить тренировочный процесс (например, потому что получили качественную модель или вы не хотите больше ждать). | gv(&#39;&#39;&#39; init-&gt;predict-&gt;loss-&gt;gradient-&gt;step-&gt;stop step-&gt;predict[label=repeat] &#39;&#39;&#39;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G init init predict predict init&#45;&gt;predict loss loss predict&#45;&gt;loss gradient gradient loss&#45;&gt;gradient step step gradient&#45;&gt;step step&#45;&gt;predict repeat stop stop step&#45;&gt;stop Прежде чем применить эти шаги к нашей задаче классификации изображений, давайте проиллюстрируем, как они выглядят в более простом случае. Сначала мы определим очень простую функцию, квадратичную-давайте представим, что это наша функция потерь, а x-весовой параметр функции: . def f(x): return x**2 . Вот график этой функции: . plot_function(f, &#39;x&#39;, &#39;x**2&#39;) . /opt/conda/envs/fastai/lib/python3.8/site-packages/fastbook/__init__.py:73: UserWarning: Not providing a value for linspace&#39;s steps is deprecated and will throw a runtime error in a future release. This warning will appear only once per process. (Triggered internally at /pytorch/aten/src/ATen/native/RangeFactories.cpp:23.) x = torch.linspace(min,max) . Последовательность шагов, описанных ранее, начинается с выбора некоторого случайного значения параметра и вычисления величины потери: . plot_function(f, &#39;x&#39;, &#39;x**2&#39;) plt.scatter(-1.5, f(-1.5), color=&#39;red&#39;); . &#1042;&#1099;&#1095;&#1080;&#1089;&#1083;&#1077;&#1085;&#1080;&#1077; &#1075;&#1088;&#1072;&#1076;&#1080;&#1077;&#1085;&#1090;&#1072; . Во-первых, давайте выберем тензорное значение, для которого нам нужен градиент. requiresgrad - показывает, что мы хотим вычислить градиенты относительно этой переменной при этом значении: . xt = tensor(3.).requires_grad_() . Теперь мы вычисляем нашу функцию с этим значением. Обратите внимание, как PyTorch печатает не только вычисленное значение, но и примечание, что у него есть градиентная функция, которую он будет использовать для вычисления наших градиентов, когда это необходимо: . yt = f(xt) yt . tensor(9., grad_fn=&lt;PowBackward0&gt;) . Дальше мы говорим PyTorch вычислить градиенты для нас: . yt.backward() . backward - здесь относится к метод обратного распространения ошибки (англ. backpropagation) — метод вычисления градиента, который используется при обновлении весов многослойного перцептрона. . xt.grad . tensor(6.) . Если вы помните свои школьные годы и правила вычисления производной от x 2, то знаете что производная равна 2*x, а у нас x=3, поэтому градиент равен 2*3=6, что и рассчитал для нас PyTorch! . Теперь мы повторим предыдущие шаги, но с аргументом в виде вектора для нашей функции: . xt = tensor([3.,4.,10.]).requires_grad_() xt . tensor([ 3., 4., 10.], requires_grad=True) . И мы добавим сумму к нашей функции, чтобы она могла взять вектор (т. е. тензор ранга 1) и вернуть скаляр (т. е. тензор ранга 0): . def f(x): return (x**2).sum() yt = f(xt) yt . tensor(125., grad_fn=&lt;SumBackward0&gt;) . yt.backward() xt.grad . tensor([ 6., 8., 20.]) . &#1054;&#1090; &#1085;&#1072;&#1095;&#1072;&#1083;&#1072; &#1076;&#1086; &#1082;&#1086;&#1085;&#1094;&#1072; &#1087;&#1088;&#1080;&#1084;&#1077;&#1088; &#1089;&#1090;&#1086;&#1093;&#1072;&#1089;&#1090;&#1080;&#1095;&#1077;&#1089;&#1082;&#1086;&#1075;&#1086; &#1075;&#1088;&#1072;&#1076;&#1080;&#1077;&#1085;&#1090;&#1085;&#1086;&#1075;&#1086; &#1089;&#1087;&#1091;&#1089;&#1082;&#1072; . Рассматриваться будет простая модель на примере американских горок. Измеряется скорость: когда тележка залазит на вершину, то скорость падает, а когда спускается, то возрастает. Задача - построить модель изменения скорости со временем. Если бы скорость измерялась каждую секунду в течении 20 секунд, это это могли быть следующие величины: . time = torch.arange(0,20).float(); time . tensor([ 0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.]) . speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1 plt.scatter(time,speed); . Определим функцию, которая будет принимать параметры и время и выполнять их разделение внутри и вычесление . def f(t, params): a,b,c = params return a*(t**2) + (b*t) + c . Сначала нам нужно определить, что подразумевается под &quot;лучшим&quot; результатом. Это определяетя точно при помощи функции потерь, которая будет возвращать значение на основе прогноза и целевызх значений, где более низкие значения функции соответствуют &quot;лучшим&quot; прогнозам. Для непрерывных данных обычно используется среднеквадратичная ошибка: . def mse(preds, targets): return ((preds-targets)**2).mean() . Step 1: &#1048;&#1085;&#1080;&#1094;&#1080;&#1083;&#1080;&#1079;&#1072;&#1094;&#1080;&#1103; &#1087;&#1072;&#1088;&#1072;&#1084;&#1077;&#1090;&#1088;&#1086;&#1074; . Сначала инициализируем параметры случайными значениями и сообщаем PyTorch, что хотим отслеживать их градиенты, используя requiresgrad: . params = torch.randn(3).requires_grad_() . Step 2: &#1042;&#1099;&#1095;&#1080;&#1089;&#1083;&#1077;&#1085;&#1080;&#1077; &#1087;&#1088;&#1077;&#1076;&#1089;&#1082;&#1072;&#1079;&#1072;&#1085;&#1080;&#1103; . preds = f(time, params) . def show_preds(preds, ax=None): if ax is None: ax=plt.subplots()[1] ax.scatter(time, speed) ax.scatter(time, to_np(preds), color=&#39;red&#39;) ax.set_ylim(-300,100) . show_preds(preds) . Step 3: &#1042;&#1099;&#1095;&#1080;&#1089;&#1083;&#1077;&#1085;&#1080;&#1077; &#1087;&#1086;&#1090;&#1077;&#1088;&#1080; . loss = mse(preds, speed) loss . tensor(25823.8086, grad_fn=&lt;MeanBackward0&gt;) . Step 4: &#1042;&#1099;&#1095;&#1080;&#1089;&#1083;&#1077;&#1085;&#1080;&#1077; &#1075;&#1088;&#1072;&#1076;&#1080;&#1077;&#1085;&#1090;&#1072; . loss.backward() params.grad . tensor([-53195.8633, -3419.7148, -253.8908]) . params.grad * 1e-5 . tensor([-0.5320, -0.0342, -0.0025]) . Можно использовать эти градиенты для улучшения параметров. В качестве скорости обучения используется значение 1e-5 или 0.00001 . params . tensor([-0.7658, -0.7506, 1.3525], requires_grad=True) . Step 5: &#1069;&#1090;&#1072;&#1087; &#1089; &#1074;&#1077;&#1089;&#1072;&#1084;&#1080; . Теперь нужно обновить параметры на основе градиентов, которые только что рассчитали: . lr = 1e-5 params.data -= lr * params.grad.data params.grad = None . Посмотрим как изменилась потеря . preds = f(time,params) mse(preds, speed) . tensor(5435.5356, grad_fn=&lt;MeanBackward0&gt;) . Построим график . show_preds(preds) . Так как необходимо повторить это несколько раз, поэтому логично создадать функцию которое будет это все включать в свое тело . def apply_step(params, prn=True): preds = f(time, params) loss = mse(preds, speed) loss.backward() params.data -= lr * params.grad.data params.grad = None if prn: print(loss.item()) return preds . Step 6: &#1055;&#1086;&#1074;&#1090;&#1086;&#1088;&#1080;&#1090;&#1100; &#1087;&#1088;&#1086;&#1094;&#1077;&#1089;&#1089; . for i in range(10): apply_step(params) . 5435.53564453125 1577.44921875 847.3778076171875 709.2225341796875 683.0758056640625 678.1243896484375 677.1838989257812 677.0023803710938 676.9645385742188 676.9537353515625 . Построим график для гаждого шага, чтоб увидеть как приблежается функция к идеальной . _,axs = plt.subplots(1,4,figsize=(12,3)) for ax in axs: show_preds(apply_step(params, False), ax) plt.tight_layout() . Step 7: &#1057;&#1058;&#1054;&#1055; . Решение остановиться после 10 эпох произвольно. На практике необходимо наблюдать за метриками, чтобы решить, когда остановиться. . MNIST &#1092;&#1091;&#1085;&#1082;&#1094;&#1080;&#1103; &#1087;&#1086;&#1090;&#1077;&#1088;&#1080; . В исследуемой модели зависимыми переменными яляются сам изображения. Необходимо объединить все их в один тензор и изменить rank 2(матрица) на rank 3(вектор).Это можно сделать при помощи команды view из PyTorch. Происходит изменение формы тензора без изменения его содержимого. -1-параметр когда не известно сколько строк необходимо, но точно известно количество столбцов. Другими словами сделайть ось настолько большой, насколько это необходимо для размещения всех данных: . train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28) . Так как необходима метка для каждого изображения, то испольуется 1 для 3 и 0 для 7-ки: . train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1) train_x.shape,train_y.shape . (torch.Size([12396, 784]), torch.Size([12396, 1])) . Dataset в PyTorch должен возвращать кортеж (x, y) при индексации. Python предоставляет функцию zip, которая в сочетании с фунцией list обеспечивает простой способ получить эту функциональность: . dset = list(zip(train_x,train_y)) x,y = dset[0] x.shape,y . (torch.Size([784]), tensor([1])) . valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28) valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1) valid_dset = list(zip(valid_x,valid_y)) . Теперь необходимы веса для каждого пикселя (это шаг инициализации в семиступенчатом процессе): . def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_() . weights = init_params((28*28,1)) . Функция weights/pixels не будет достаточно гибкой, так как она всегда равна 0, когда пиксели равны 0. Так как функция для прямой линии выглядит следующим образом Y=w x+b, то необходимо еще случайным образом иницилизировать b: . bias = init_params(1) . Вычислим прогноз для одного изображения: . (train_x[0]*weights.T).sum() + bias . tensor([20.2336], grad_fn=&lt;AddBackward0&gt;) . В Python умножение матриц, представленных с помощью оператора @. . def linear1(xb): return xb@weights + bias preds = linear1(train_x) preds . tensor([[20.2336], [17.0644], [15.2384], ..., [18.3804], [23.8567], [28.6816]], grad_fn=&lt;AddBackward0&gt;) . Чтобы решить, представляет ли прогноз 3 или 7, можно просто проверить, больше ли он 0: . corrects = (preds&gt;0.0).float() == train_y corrects . tensor([[ True], [ True], [ True], ..., [False], [False], [False]]) . corrects.float().mean().item() . 0.4912068545818329 . Теперь проверим каково изменение точности для одного небольшого изменения веса: . weights[0] *= 1.0001 . preds = linear1(train_x) ((preds&gt;0.0).float() == train_y).float().mean().item() . 0.4912068545818329 . Для рассмотрения предположим, что есть три изображения, которые, как известно являются 3, 7 и 3 с вероятностью, что первое число 3 - 0.9, второе число 7 - 0.4 и третье число 3 с верояятностью 0.2. . trgts = tensor([1,0,1]) prds = tensor([0.9, 0.4, 0.2]) . Далее создадим первую функцию потерь, которая измеряет расстояние между прогнозом и целевым значением. В нем torch.where(a,b,c) то же самое, что [b[i] if a[i] else c[i] for i in range(len(a))], но работает с тензорами с большей скоростью . def mnist_loss(predictions, targets): return torch.where(targets==1, 1-predictions, predictions).mean() . Испытание для prds и trgts: . torch.where(trgts==1, 1-prds, prds) . tensor([0.1000, 0.4000, 0.8000]) . Поскольку необходимо скалярное значение, то при помощи mnist_loss получаемт среднее значение предыдущего тензора: . mnist_loss(prds,trgts) . tensor(0.4333) . Для примера изменим наш прогноз для одного значения с 0.2 на 0.8и в результате потери уменьшаться, что говорит о том, что это лучший прогноз: . mnist_loss(tensor([0.9, 0.4, 0.8]),trgts) . tensor(0.2333) . Sigmoid . Сигмоидная функция всегда выводит число от 0 до 1. Он определяется следующим образом . def sigmoid(x): return 1/(1+torch.exp(-x)) . В Pytorch она определена и нет необходимости создавать свою собственную. Она определена от 0 до 1 и вот как это выглядит: . plot_function(torch.sigmoid, title=&#39;Sigmoid&#39;, min=-4, max=4) . Обновим функцию mnist_loss, чтобы применить сигмоиду к входным данным: . def mnist_loss(predictions, targets): predictions = predictions.sigmoid() return torch.where(targets==1, 1-predictions, predictions).mean() . SGD &#1080; Mini-Batches . DataLoader может взять любой набор Python и превратить ее в итератор для многих пакетов, например: . coll = range(15) dl = DataLoader(coll, batch_size=5, shuffle=True) list(dl) . [tensor([ 3, 12, 8, 10, 2]), tensor([ 9, 4, 7, 14, 5]), tensor([ 1, 13, 0, 6, 11])] . Для обучения модели нам нужна не просто коллекция Python, а коллекция, содержащая независимые и зависимые переменные (то есть входные значения и результаты). Коллекция, содержащая кортежи независимых и зависимых переменных, известна в PyTorch как Dataset. Один из примеров . ds = L(enumerate(string.ascii_lowercase)) ds . (#26) [(0, &#39;a&#39;),(1, &#39;b&#39;),(2, &#39;c&#39;),(3, &#39;d&#39;),(4, &#39;e&#39;),(5, &#39;f&#39;),(6, &#39;g&#39;),(7, &#39;h&#39;),(8, &#39;i&#39;),(9, &#39;j&#39;)...] . Когда передается Dataset в DataLoader, получается много пакетов, которые сами являются кортежами тензоров, представляющих независимые и зависимые переменные: . dl = DataLoader(ds, batch_size=6, shuffle=True) list(dl) . [(tensor([17, 18, 10, 22, 8, 14]), (&#39;r&#39;, &#39;s&#39;, &#39;k&#39;, &#39;w&#39;, &#39;i&#39;, &#39;o&#39;)), (tensor([20, 15, 9, 13, 21, 12]), (&#39;u&#39;, &#39;p&#39;, &#39;j&#39;, &#39;n&#39;, &#39;v&#39;, &#39;m&#39;)), (tensor([ 7, 25, 6, 5, 11, 23]), (&#39;h&#39;, &#39;z&#39;, &#39;g&#39;, &#39;f&#39;, &#39;l&#39;, &#39;x&#39;)), (tensor([ 1, 3, 0, 24, 19, 16]), (&#39;b&#39;, &#39;d&#39;, &#39;a&#39;, &#39;y&#39;, &#39;t&#39;, &#39;q&#39;)), (tensor([2, 4]), (&#39;c&#39;, &#39;e&#39;))] . &#1057;&#1086;&#1077;&#1076;&#1080;&#1085;&#1080;&#1090;&#1100; &#1074;&#1089;&#1077; &#1074;&#1086;&#1077;&#1076;&#1080;&#1085;&#1086; . Повторно инициализируем параметры: . weights = init_params((28*28,1)) bias = init_params(1) . DataLoader создать из Dataset: . dl = DataLoader(dset, batch_size=256) xb,yb = first(dl) xb.shape,yb.shape . (torch.Size([256, 784]), torch.Size([256, 1])) . Сделаем то же самое для проверочного набора: . valid_dl = DataLoader(valid_dset, batch_size=256) . Создадим мини-пакеты размером в четыре для тестирования: . batch = train_x[:4] batch.shape . torch.Size([4, 784]) . preds = linear1(batch) preds . tensor([[-2.1876], [-8.3973], [ 2.5000], [-4.9473]], grad_fn=&lt;AddBackward0&gt;) . loss = mnist_loss(preds, train_y[:4]) loss . tensor(0.7419, grad_fn=&lt;MeanBackward0&gt;) . Теперь можем вычислить градиенты: . loss.backward() weights.grad.shape,weights.grad.mean(),bias.grad . (torch.Size([784, 1]), tensor(-0.0061), tensor([-0.0420])) . Поместим все это в функцию: . def calc_grad(xb, yb, model): preds = model(xb) loss = mnist_loss(preds, yb) loss.backward() . и протестируем: . calc_grad(batch, train_y[:4], linear1) weights.grad.mean(),bias.grad . (tensor(-0.0121), tensor([-0.0840])) . Теперь посмотрим, что произойдет, если вызвать функцию дважды . calc_grad(batch, train_y[:4], linear1) weights.grad.mean(),bias.grad . (tensor(-0.0182), tensor([-0.1260])) . Градиенты изменились! Причина этого заключается в том, что loss.backward фактически добавляет градиенты потерь к градиентам, которые в данный момент хранятся. Итак, сначала необходимо установить текущие градиенты на 0: . weights.grad.zero_() bias.grad.zero_(); . Создадим функцию базового цикла обучения для эпохи: . def train_epoch(model, lr, params): for xb,yb in dl: calc_grad(xb, yb, model) for p in params: p.data -= p.grad*lr p.grad.zero_() . Также проверим, как работает. Чтобы решить, представляет ли прогноз 3 или 7, можно просто проверить, больше ли он 0: . (preds&gt;0.0).float() == train_y[:4] . tensor([[False], [False], [ True], [False]]) . Получается функция для вычисления точности сверки: . def batch_accuracy(xb, yb): preds = xb.sigmoid() correct = (preds&gt;0.5) == yb return correct.float().mean() . Можно проверить как это работает: . batch_accuracy(linear1(batch), train_y[:4]) . tensor(0.2500) . а затем сложить пакеты вместе . def validate_epoch(model): accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl] return round(torch.stack(accs).mean().item(), 4) . validate_epoch(linear1) . 0.5263 . Далее потренируемся на одной эпохе и проверим измениться ли точность: . lr = 1. params = weights,bias train_epoch(linear1, lr, params) validate_epoch(linear1) . 0.6663 . Затем еще несколько: . for i in range(20): train_epoch(linear1, lr, params) print(validate_epoch(linear1), end=&#39; &#39;) . 0.8265 0.8899 0.9182 0.9275 0.9397 0.9466 0.9505 0.9525 0.9559 0.9578 0.9598 0.9608 0.9613 0.9618 0.9632 0.9637 0.9647 0.9657 0.9672 0.9677 . Получен неплохой результат. Далее оптимизация. . &#1057;&#1086;&#1079;&#1076;&#1072;&#1085;&#1080;&#1077; &#1086;&#1087;&#1090;&#1080;&#1084;&#1080;&#1079;&#1072;&#1090;&#1086;&#1088;&#1072; . nn.Linear делает то же самое, что и init_params и linear вместе. Он содержит как веса, так и смещения в одном классе. Копируем модель из предыдущего раздела: . linear_model = nn.Linear(28*28,1) . Получить доступ к параметрам в модуле PyTorch, которые будут обучены, можно через метод parameters: . w,b = linear_model.parameters() w.shape,b.shape . (torch.Size([1, 784]), torch.Size([1])) . Можно использовать эту информацию для создания оптимизатора . class BasicOptim: def __init__(self,params,lr): self.params,self.lr = list(params),lr def step(self, *args, **kwargs): for p in self.params: p.data -= p.grad.data * self.lr def zero_grad(self, *args, **kwargs): for p in self.params: p.grad = None . Создается оптимизатор путем передачи параметров модели: . opt = BasicOptim(linear_model.parameters(), lr) . Теперь можно упростить цикл . def train_epoch(model): for xb,yb in dl: calc_grad(xb, yb, model) opt.step() opt.zero_grad() . Функцию проверки вообще менять не надо . validate_epoch(linear_model) . 0.4608 . Поместим тренировочнуюый цикл в функцию, чтобы упростить: . def train_model(model, epochs): for i in range(epochs): train_epoch(model) print(validate_epoch(model), end=&#39; &#39;) . Получим тот же результат, что и в прошлом разделе . train_model(linear_model, 20) . 0.4932 0.7685 0.8554 0.9135 0.9345 0.9482 0.957 0.9633 0.9658 0.9677 0.9697 0.9716 0.9736 0.9746 0.976 0.977 0.9775 0.9775 0.978 0.9785 . В fastai имеется класс SGD, который делает то же самое, что и BasicOptim: . linear_model = nn.Linear(28*28,1) opt = SGD(linear_model.parameters(), lr) train_model(linear_model, 20) . 0.4932 0.8179 0.8496 0.914 0.9345 0.9482 0.957 0.9619 0.9658 0.9672 0.9692 0.9712 0.9741 0.9751 0.976 0.9775 0.9775 0.978 0.9785 0.979 . В fastai также есть Learner.fit, который используется вместо train_model. Чтобы создать Learner, необходимо сначала создать DataLoaders, передав обучающие и проверочные данные: . dls = DataLoaders(dl, valid_dl) . Чтобы создать Learner без использования приложений (например, cnn_learner), нужно передать все элементы, которые были созданы в этой главе: DataLoaders, модель, функцию оптимизации (которой будут переданы параметры), функцию потерь и, возможно, метрики для вывода: . learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy) . Теперь можно тренировать . learn.fit(10, lr=lr) . epoch train_loss valid_loss batch_accuracy time . 0 | 0.636709 | 0.503144 | 0.495584 | 00:00 | . 1 | 0.429828 | 0.248517 | 0.777233 | 00:00 | . 2 | 0.161680 | 0.155361 | 0.861629 | 00:00 | . 3 | 0.072948 | 0.097722 | 0.917566 | 00:00 | . 4 | 0.040128 | 0.073205 | 0.936212 | 00:00 | . 5 | 0.027210 | 0.059466 | 0.950442 | 00:00 | . 6 | 0.021837 | 0.050799 | 0.957802 | 00:00 | . 7 | 0.019398 | 0.044980 | 0.964181 | 00:00 | . 8 | 0.018122 | 0.040853 | 0.966143 | 00:00 | . 9 | 0.017330 | 0.037788 | 0.968106 | 00:00 | . &#1044;&#1086;&#1073;&#1072;&#1074;&#1083;&#1077;&#1085;&#1080;&#1077; &#1085;&#1077;&#1083;&#1080;&#1085;&#1077;&#1081;&#1085;&#1086;&#1089;&#1090;&#1080; . Полное описание базовой нейроной сети выглядит следующим образом: . def simple_net(xb): res = xb@w1 + b1 res = res.max(tensor(0.0)) res = res@w2 + b2 return res . w1 и w2-тензоры с весами, а b1 и b2-тензоры со смещениями. Параметры изначально инициализируются случайным образом, как и в предыдущем разделе: . w1 = init_params((28*28,30)) b1 = init_params(30) w2 = init_params((30,1)) b2 = init_params(1) . res.max(tensor(0.0)) - заменить каждое отрицательное число нулем и данная функция представлена в PyTorch - F.relu (rectified linear unit.). . plot_function(F.relu) . Три строки кода, которые представлены ниже - слои. Первый и третий - линейные слои, а вторая строка кода - нелинейность или функция активации. Скорость дальше немного повысим, а количество эпох увеличим: . simple_net = nn.Sequential( nn.Linear(28*28,30), nn.ReLU(), nn.Linear(30,1) ) . learn = Learner(dls, simple_net, opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy) . learn.fit(40, 0.1) . epoch train_loss valid_loss batch_accuracy time . 0 | 0.333021 | 0.396112 | 0.512267 | 00:00 | . 1 | 0.152461 | 0.235238 | 0.797350 | 00:00 | . 2 | 0.083573 | 0.117471 | 0.911678 | 00:00 | . 3 | 0.054309 | 0.078720 | 0.940628 | 00:00 | . 4 | 0.040829 | 0.061228 | 0.956330 | 00:00 | . 5 | 0.034006 | 0.051490 | 0.963690 | 00:00 | . 6 | 0.030123 | 0.045381 | 0.966634 | 00:00 | . 7 | 0.027619 | 0.041218 | 0.968106 | 00:00 | . 8 | 0.025825 | 0.038200 | 0.969087 | 00:00 | . 9 | 0.024441 | 0.035901 | 0.969578 | 00:00 | . 10 | 0.023321 | 0.034082 | 0.971541 | 00:00 | . 11 | 0.022387 | 0.032598 | 0.972031 | 00:00 | . 12 | 0.021592 | 0.031353 | 0.974485 | 00:00 | . 13 | 0.020904 | 0.030284 | 0.975466 | 00:00 | . 14 | 0.020300 | 0.029352 | 0.975466 | 00:00 | . 15 | 0.019766 | 0.028526 | 0.975466 | 00:00 | . 16 | 0.019288 | 0.027788 | 0.976448 | 00:00 | . 17 | 0.018857 | 0.027124 | 0.977429 | 00:00 | . 18 | 0.018465 | 0.026523 | 0.978410 | 00:00 | . 19 | 0.018107 | 0.025977 | 0.978901 | 00:00 | . 20 | 0.017777 | 0.025479 | 0.978901 | 00:00 | . 21 | 0.017473 | 0.025022 | 0.979392 | 00:00 | . 22 | 0.017191 | 0.024601 | 0.980373 | 00:00 | . 23 | 0.016927 | 0.024213 | 0.980373 | 00:00 | . 24 | 0.016680 | 0.023855 | 0.981354 | 00:00 | . 25 | 0.016449 | 0.023521 | 0.981354 | 00:00 | . 26 | 0.016230 | 0.023211 | 0.981354 | 00:00 | . 27 | 0.016023 | 0.022922 | 0.981354 | 00:00 | . 28 | 0.015827 | 0.022653 | 0.981845 | 00:00 | . 29 | 0.015641 | 0.022401 | 0.981845 | 00:00 | . 30 | 0.015463 | 0.022165 | 0.981845 | 00:00 | . 31 | 0.015294 | 0.021944 | 0.983317 | 00:00 | . 32 | 0.015132 | 0.021736 | 0.982826 | 00:00 | . 33 | 0.014977 | 0.021541 | 0.982826 | 00:00 | . 34 | 0.014828 | 0.021357 | 0.982336 | 00:00 | . 35 | 0.014686 | 0.021184 | 0.982336 | 00:00 | . 36 | 0.014549 | 0.021019 | 0.982336 | 00:00 | . 37 | 0.014417 | 0.020864 | 0.982336 | 00:00 | . 38 | 0.014290 | 0.020716 | 0.982336 | 00:00 | . 39 | 0.014168 | 0.020576 | 0.982336 | 00:00 | . Процесс обучения записывается в learn.recorder, а таблица с результатамиа хранится в values.В связи с чем построить график точности можно следующим образом:: . plt.plot(L(learn.recorder.values).itemgot(2)); . И теперь можно посмотреть окончательную точность: . learn.recorder.values[-1][2] . 0.98233562707901 . &#1048;&#1076;&#1077;&#1084; &#1075;&#1083;&#1091;&#1073;&#1078;&#1077; . Вот что происходит, когда обучаем при помощи 18-слойной модели используя тот же самый подход, что и в предыдущем разделе. . dls = ImageDataLoaders.from_folder(path) learn = cnn_learner(dls, resnet18, pretrained=False, loss_func=F.cross_entropy, metrics=accuracy) learn.fit_one_cycle(1, 0.1) . epoch train_loss valid_loss accuracy time . 0 | 0.089869 | 0.028326 | 0.990186 | 00:09 | . &#1057;&#1086;&#1079;&#1076;&#1072;&#1085;&#1080;&#1077; &#1089;&#1086;&#1073;&#1089;&#1090;&#1074;&#1077;&#1085;&#1085;&#1086;&#1081; &#1084;&#1086;&#1076;&#1077;&#1083;&#1080; &#1076;&#1083;&#1103; &#1074;&#1089;&#1077;&#1093; &#1095;&#1080;&#1089;&#1077;&#1083; . datapath = untar_data(URLs.MNIST) . data = ImageDataLoaders.from_folder(path=datapath, train=&#39;training&#39;, test=&#39;testing&#39;, valid_pct=0.2) . learn = cnn_learner(data, resnet18, pretrained=False, loss_func=F.cross_entropy, metrics=accuracy) learn.fit_one_cycle(1, 0.1) . epoch train_loss valid_loss accuracy time . 0 | 0.097839 | 0.118689 | 0.984071 | 00:45 | .",
            "url": "https://zmey56.github.io/blog//russian/fast.ai/solution/2020/12/13/04-mnist-basics.html",
            "relUrl": "/russian/fast.ai/solution/2020/12/13/04-mnist-basics.html",
            "date": " • Dec 13, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Russian - Fastbook Chapter 4 questionnaire solutions",
            "content": "Ответы на русском языке на вопросы к четвертой части курса Deep Learning 2020 на Fast.ai. Напоминаю, что третья часть отдана этики. . 1. Как представлено на компьютере изображение в градиентах серого? Как цветное изображение? . Изображения представлены массивами со значениями пикселей, представляющими содержимое изображения. Для изображений в оттенках серого используется 2-мерный массив с пикселями, представляющими значения в оттенках серого, в диапазоне от 0 до 256. Значение 0 - белый цвет, а значение 255 - черный, а между ними различные оттенки серого. Для цветных изображений обычно используются три цветовых канала (красный, зеленый, синий), причем для каждого канала используется отдельный 256-диапазонный 2D-массив. Значение пикселя 0 снова представляет белый цвет, а 255 - сплошной красный, зеленый или синий. Три 2-D массива образуют окончательный 3-D массив (тензор ранга 3), представляющий цветное изображение. . 2. Как структурированы файлы и папки в наборе данных MNIST_SAMPLE? Почему? . Есть две подпапки, train и valid, первая содержит данные для обучения модели, вторая содержит данные для проверки подтверждения модели после каждого шага обучения. Оценка модели на валидационном наборе служит двум целям: а) сообщить о такой интерпретируемой человеком метрике, как точность (в отличие от часто абстрактных функций потерь, используемых для обучения), б) облегчить обнаружение переобучения путем оценки модели на наборе данных, на котором она не была обучена (короче говоря, модель переобучения работает все лучше на обучающем наборе, но все меньше на валидационном наборе). Конечно, каждый практик мог генерировать свои собственные тренировочные / валидационые разделения данных. Общедоступные наборы данных обычно предварительно разделяются для упрощения сравнения результатов между реализациями/публикациями. . Каждая подпапка имеет две подпапки 3 и 7, которые содержат файлы ф формате jpg для соответствующего класса изображений. Это распространенный способ организации наборов данных, состоящих из изображений. Для полного набора данных MNIST существует 10 подпапок, по одной для изображений каждой цифры. . 3. Объясните, как работает подход ”пиксельного сходства (pixel similarity)” к классификации цифр. . В подходе “сходства пикселей” мы генерируем образец для каждого класса, который хотим идентифицировать. В нашем случае мы хотим отличить изображения трех от изображений семи. Мы определяем образец трех как среднее значение по пикселям всех трех в обучающем наборе. Аналогично для семерки. Вы можете визуализировать два образца и увидеть, что они на самом деле являются размытыми версиями чисел, которые они представляют. Чтобы определить, является ли ранее нерассматриваемое изображение 3 или 7, мы вычисляем его расстояние до двух образцов (здесь: средняя абсолютная разница в пикселях). Мы говорим, что новый образ-это 3, если его расстояние до образца трех меньше, чем ддля образца семи. . 4. Что такое представление списков (list comprehension)? Теперь создайте тот, который выбирает нечетные числа из списка и удваивает их. . Списки (массивы на других языках программирования) часто генерируются с помощью цикла for. Представление списков (list comprehension) - это Питонический способ конденсирования создания списка с помощью цикла for в одно выражение. редставление списков (list comprehension) также часто будет включать условия для фильтрации. . lst_in = range(10) lst_out = [2*el for el in lst_in if el%2==1] # is equivalent to: lst_out = [] for el in lst_in: if el%2==1: lst_out.append(2*el) . 5. Что такое “тензор ранга 3”? . Ранг тензора-это число измерений, которые он имеет. Простой способ определить ранг - это количество индексов, которые вам понадобятся для ссылки на число внутри тензора. Скаляр может быть представлен как тензор ранга 0 (без индекса), вектор может быть представлен как тензор ранга 1 (один индекс, например, v[i]), матрица может быть представлена как тензор ранга 2 (два индекса, например,a[i, j]), а тензор ранга 3-это кубоид или “стек матриц” (три индекса, например,b[i,j, k]). В частности, ранг тензора не зависит от его формы или размерности, например, тензор формы 2x2x2 и тензор формы 3x5x7 имеют ранг 3. Обратите внимание, что термин “ранг” имеет различные значения в контексте тензоров и матриц (где он относится к числу линейно независимых векторов столбцов). . 6. В чем разница между тензорным рангом и формой (shape)? . Ранг - это число осей или измерений в Тензоре; форма (shape)-размер каждой оси тензора. . Как вы получаете ранг от формы? . Длина формы тензора - это его ранг. . Итак, если у нас есть изображения папки 3 из набора данных MINST_SAMPLE в Тензоре под названием stacked_threes, и мы находим его форму вот так. . In [ ]: stacked_threes.shape Out[ ]: torch.Size([6131, 28, 28]) . Нам просто нужно найти его длину, чтобы узнать его ранг. Это делается следующим образом. . In [ ]: len(stacked_threes.shape) Out[ ]: 3 . Вы также можете получить ранг тензора непосредственно с помощью ndim. . In [ ]: stacked_threes.ndim Out[ ]: 3 . 7. Что такое норма RMSE и L1? . Среднеквадратичная ошибка (RMSE), также называемая нормой L2, и средняя абсолютная разность (MAE), также называемая нормой L1, являются двумя широко используемыми методами измерения “расстояния”. Простые вычитания не работают, потому что некоторые различия положительны, а другие отрицательны и в результате они отменяют друг друга. Поэтому для правильного измерения расстояний необходима функция, которая фокусируется на величинах разностей. Проще всего было бы сложить абсолютные значения разностей, что и есть MAE. RMSE берет среднее значение квадрата (делает все положительным), а затем берет квадратный корень (отменяет возведение в квадрат). . 8. Как вы можете выполнить вычисление на тысячах чисел одновременно, во много тысяч раз быстрее, чем цикл на Python? . Поскольку циклы в Python очень медленные, лучше всего представлять операции как операции массива, а не циклически перебирать отдельные элементы. Если это можно сделать, то использование NumPy или PyTorch будет в тысячи раз быстрее, так как они используют базовый код C, который намного быстрее, чем чистый Python. Еще лучше то, что PyTorch позволяет запускать операции на GPU, которые будут иметь значительное ускорение, если есть параллельные операции, которые можно выполнить. . 9. Создайте тензор 3x3 или массив, содержащий числа от 1 до 9. Удвоьте его. Выберите в правом нижнем углу 4 цифры. . In [ ]: a = torch.Tensor(list(range(1,10))).view(3,3); print(a) Out [ ]: tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]]) In [ ]: b = 2*a; print(b) Out [ ]: tensor([[ 2., 4., 6.], [ 8., 10., 12.], [14., 16., 18.]]) In [ ]: b[1:,1:] Out []: tensor([[10., 12.], [16., 18.]]) . 10. Что такое бродкастинг? . Бродкастинг (broadcasting) - Научные / числовые пакеты Python, такие как NumPy и PyTorch, часто реализуют бродкастинг, который часто облегчает написание кода. В случае PyTorch тензоры с меньшим рангом расширяются, чтобы иметь тот же размер, что и тензор большего ранга. Таким образом, операции могут выполняться между тензорами с различным рангом. . 11. Обычно метрики рассчитываются с использованием обучающего набора или набора проверки? Почему? . Метрики обычно рассчитываются на основе набора валидации. Поскольку набор валидации является данными, которые не использовались для обучения модели, оценка метрик в наборе валидации лучше для того, чтобы определить, есть ли какое-либо переобучение и насколько хорошо модель могла бы обобщить, если бы ей были даны аналогичные данные. . 12. Что такое SGD? . SGD, или стохастический градиентный спуск, - это алгоритм оптимизации. В частности, SGD-это алгоритм, который будет обновлять параметры модели для того, чтобы минимизировать заданную функцию потерь, которая была оценена по прогнозам и цели. Ключевая идея SGD (и многих алгоритмов оптимизации, если на то пошло) заключается в том, что градиент функции потерь дает представление о том, как эта функция потерь изменяется в пространстве параметров, которое мы можем использовать, чтобы определить, как лучше всего обновить параметры, чтобы минимизировать функцию потерь. Это то, что делает SGD. . 13. Почему SGD использует мини-пакеты? . Нам нужно вычислить нашу функцию потерь (и наш градиент) на одной или нескольких точках данных. Мы не можем рассчитывать на всех наборах данных из-за компьютерных ограничений и ограничений по времени. Однако если мы будем перебирать каждую точку данных, градиент будет неустойчивым и неточным и не пригодным для обучения. В качестве компромисса мы рассчитываем средние потери для небольшого подмножества набора данных за один раз. Это подмножество называется мини-пакетом. Использование мини-пакетов также более эффективно с вычислительной точки зрения, чем отдельные элементы на графическом процессоре. . 14. Какие 7 шагов в SGD машинного обучения? . Инициализируйте параметры-случайные значения часто работают лучше всего. | Рассчитать прогнозы-это делается на тренировочном наборе, по одному мини-пакету за раз. | Вычислить потери – вычисляется средняя потеря по минипакету** | Вычисление градиентов-это аппроксимация того, как должны изменяться параметры, чтобы минимизировать функцию потерь | Шаг Весов-обновление параметров на основе вычисленных Весов | Повторить процесс | Остановка-на практике это либо основано на временных ограничениях, либо обычно основано на том, когда потери в обучении/валидации и показатели перестают улучшаться. | 15. Как мы инициализируем веса в модели? . Случайные веса работают довольно хорошо. . 16. Что такое “потеря”? . Функция потерь будет возвращать значение, основанное на заданных прогнозах и целевых показателях, где более низкие значения соответствуют лучшим прогнозам модели. . 17. Почему мы не можем всегда использовать высокую скорость обучения? . Потери могут “отскакивать” вокруг (колебаться) или даже расходиться, так как оптимизатор делает слишком большие шаги и обновляет параметры быстрее, чем это должно быть. . 18. Что такое “градиент”? . Градиенты говорят нам, насколько мы должны изменить каждый вес, чтобы сделать нашу модель лучше. По сути, это мера того, как изменяется функция потерь при изменении Весов модели (производной). . 19. Вам нужно знать, как самостоятельно вычислять градиенты? . Ручной расчет градиентов не требуется, так как библиотеки глубокого обучения автоматически рассчитают градиенты для вас. Эта функция известна как автоматическая дифференциация. В PyTorch, если requires_grad=True, градиенты могут быть возвращены методом обратного вызова: a.backward() . 20. Почему мы не можем использовать точность как функцию потерь? . Функция потерь должна изменяться по мере корректировки Весов. Точность меняется только в том случае, если меняются предсказания модели. Таким образом, если в модели есть небольшие изменения, которые, скажем, повышают уверенность в предсказании, но не изменяют предсказание, точность все равно не изменится. Таким образом, градиенты будут равны нулю везде, кроме тех случаев, когда фактические прогнозы изменяются. Таким образом, модель не может учиться на градиентах, равных нулю, и веса модели не будут обновляться и не будут обучаться. Хорошая функция потерь дает немного лучшие потери, когда модель дает немного лучшие прогнозы. Немного лучшие предсказания означают, что модель более уверена в правильности предсказания. Например, предсказание 0,9 против 0,7 для вероятности того, что изображение MNIST является 3, было бы немного лучшим предсказанием. Функция потерь должна отражать это. . 21. Нарисуйте сигмовидную функцию. Что особенного в ее форме? . . Сигмоидная функция-это гладкая кривая у которой все значения лежат между 0 и 1. У функций потерь значения вероятности или доверительного уровня лежат между 0 и 1, поэтому на конце модели используется сигмоидная функция. . 22. В чем разница между потерями и метриками? . Ключевое различие заключается в том, что метрики служат для человеческого понимания, а потери - автоматизированного обучения. Чтобы потеря была полезна для обучения, она должна иметь значимую производную. Многие показатели, такие как например точность, не подходят. Метрики в свою очередь это цифры которые волнуют людей и отражают производительность модели. . 23. Что является функцией для вычисления новых весов с использованием скорости обучения? . Функция оптимизации шага . 24. Что класс DataLoader делает? . Класс DataLoader может взять любую коллекцию Python и превратить ее в итератор для пакетов. . 25. Напишите псевдокод, показывающий основные шаги, предпринятые каждой эпохой для SGD. . for x,y in dl: pred = model(x) loss = loss_func(pred, y) loss.backward() parameters -= parameters.grad * lr . 26. Создайте функцию, которая при передаче двух аргументов [1,2,3,4] и ‘abcd’ возвращает [(1, ‘a’), (2, ‘b’), (3, ‘c’), (4, ‘d’)] . Что особенного в этой структуре выходных данных? . def func(a,b): return list(zip(a,b)) . Эта структура данных полезна для моделей машинного обучения, когда вам нужны списки кортежей, где каждый кортеж будет содержать входные данные и метку. . 27. Что делает view в PyTorch? . Он изменяет форму тензора, не изменяя его содержания. . **28. Какая функция у параметра “смещения(bias)” в нейронной сети? Зачем он нам нужен? . Без параметров смещения, если на вход подается нуль, выход всегда будет равен нулю. Поэтому использование параметров смещения добавляет модели дополнительную гибкость. . 29. Что оператор @ делает в python? . Это оператор умножения матриц. . 30. Что делает метод backward делает? . Этот метод возвращает текущие градиенты. . 31. Почему мы должны обнулять градиенты? . PyTorch будет добавлять градиенты переменных в любые из ранее сохраненных градиентов. Если функция цикла обучения вызывается несколько раз, не обнуляя градиенты, градиент текущих потерь будет добавлен к ранее сохраненному значению градиента. . 32. Какую информацию мы должны передать Learner? . Нам нужно передать DataLoader, модель, функцию оптимизации, функцию потерь и, возможно, метрики для вывода. . 33. Покажите python или псевдокод для основных шагов обучающего цикла. . def train_epoch(model, lr, params): for xb,yb in dl: calc_grad(xb, yb, model) for p in params: p.data -= p.grad*lr p.grad.zero_() for i in range(20): train_epoch(model, lr, params) . 34. Что такое “ReLU”? Нарисуйте график для значений от -2 до +2. . ReLU просто означает “заменить любые отрицательные числа нулем”. Это обычно используемая функция активации. . . 35. Что такое “функция активации”? . Функция активации-это еще одна функция, входящая в состав нейронной сети, цель которой-обеспечить нелинейность модели. Идея состоит в том, что без функции активации есть несколько линейных функций вида y=mx+b. Однако ряд линейных слоев эквивалентен одному линейному слою, поэтому наша модель может подогнать только линию к данным. Вводя нелинейность между линейными слоями,это уже не так. Каждый слой несколько отделен от остальных слоев, и теперь модель может соответствовать гораздо более сложным функциям. На самом деле можно математически доказать, что такая модель может решить любую вычислимую задачу с произвольно высокой точностью, если модель достаточно велика с соответствующими весами. Это известно как универсальная аппроксимационная теорема. . *36. В чем разница между *F.relu и nn.ReLU? . F.relu - это функция Python для активации relu. С другой стороны, nn.ReLU-это модуль PyTorch. Это означает, что класс Python может быть вызван как функция таким же образом, как и F.relu. . **37. Универсальная аппроксимационная теорема показывает, что любая функция может быть аппроксимирована настолько близко, насколько это необходимо, используя только одну нелинейность. Так почему же мы обычно используем больше? . Использование более чем одной нелинейности дает практические преимущества. Мы можем использовать более глубокую модель с меньшим количеством параметров, лучшей производительностью, более быстрым обучением и меньшими требованиями к вычислениям и памяти. .",
            "url": "https://zmey56.github.io/blog//markdown/fastai/russian/deep%20learning/2020/12/09/fastai-chapter4-solution.html",
            "relUrl": "/markdown/fastai/russian/deep%20learning/2020/12/09/fastai-chapter4-solution.html",
            "date": " • Dec 9, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Russian - Fastbook Chapter 2 questionnaire solutions",
            "content": "Ответы на русском языке на вопросы ко второй части курса Deep Learning 2020 на Fast.ai. Если есть притензии к переводу, как и в первой части прошу писать в коментариях - поправлю. . 1. Приведите пример где модель классификации медведя может работать плохо из-за отличий в структуре или стиле обучающей выборки. . Существует много случаев, когда модель классификации медведей может ошибаться, причинной чего так же может являться отсутсвия экземпляров в обучающих данных: . изображение частично закрыто | ночные фото | низкое разрешение | объект далеко от камеры | приоритет характеритик (например цвета) | . 2. Где у языковой модели в настоящее время наблюдаются сложности? . Языковые модели могут генерировать тексты, которые например имитируют ответы или стили различных авторов. Но при этом их не интерисует коректность полученного результатав человеческом смысле. То есть используя фактическую базу данных трудно получитьправильные ответы, но при этом он будет казаться убедительным. Это может быть очень опасно, так как обыватель может принять все за “чистую” монету. . 3. Каких негативных социальных последствий может быть причина модель генерации текстов? . Способность моделей генерации текста генерировать очень убедительные ответы может быть использовано в массовом масштабе для распространения дезинформации (“фейковых новостей”) и подогрева конфликтов. . При обучении модели усиливают некоторые характеристики (например, гендерную и расовую предвзятость) и в результате выдвет цепочку необъективных результатов. . 4. В ситуациях, когда модель может ошибаться, и это может принести значительный вред, что является хорошей альтернативой автоматизации процесса? . Прогнозы контролируются экспертами, которые оценивают результат и принимают решение о следующем шаге. Особенно это актуально для применения машинного обучения при постановке медицинских диагнозов. Например, модель машинного обучения для идентификации инсультов при компьютерной томографии может выявлять высокоприоритетные случаи, которые должны быть расмотрены незамедлительно, в то время как другие случаи расмотраваются врачами в порядке общей очереди. За счет этого повышвется эффективность работы. . 5. В какого типа табличных данных глубокое обучение эффективно? . Глубокое обучение хорошо подходит для анализа табличных данных, включающих естественный язык, или категориальные столбцы (содержащих большее количество дискретных величин, таких как почтовый индекс). . 6. Что является ключевым недостатком использования модели глубокого обучения для рекомендательных систем? . Машинное обучение для рекомендательных систем часто говорит только о том, какие продукты могут быть интересны пользователю, и мпри этом фактически не являться рекомендацией. Например, пользователю рекомендуются книги которые он уже прочел на основании того, что он уже купил книги этого автора или другие товары которые уже приобретены. . 7 Что такое трансмиссионный (Drivetrain) подход? . . 8. Как этапы подхода Drivetrain соотносятся с системой рекомендаций . Цель механизма рекомендаций состоит в том, чтобы стимулировать дополнительные продажи за счет удовлетворения потребностей клиента в их предпочтениях. Рычагом является ранжирование рекомендаций. Данные необходимо для создания новых рекомендаций и стимулирования новых продаж. Потребуется провести множество рандомизированных экспериментов, чтобы собрать данные из большого объема рекомендаций для широкого круга клиентов. Этот шаг, который делают немногие организации; но без этого него нет информации, необходимой для реальной оптимизации рекомендаций, основанных на вашей истинной цели (больше продаж!). . 9. Создайте модель распознавания образа, используя данные, которые вам интересны, и разверните ее в интернете. . Ввыполнить просто второй ноутбук. Можно взять свою выборку, но я остановился на варианте медведей как в работе. . 10. Что такое DataLoaders(загрузчик данных)? . Класс Dataloader-это класс, который передает данные в fastai модель. По сути, это класс, который хранит необходимые объекты Dataloader (обычно наборs train и validation). . 11. Какие четыре вещи нам нужны для fastai? чтоб создать DataLoaders? . с какими типами данных мы работаем | как получить список элементов | какие метки для этих элементы | как создать validation набор | . 12. Что делает параметр split в DataBlock? . Используется для разделения данных на подмножества (как правило обучающие и проверочные). Например, для случайного разбиения данных можно использовать предопределенный класс RandomSplitter из fastai, передавая в данный класс значение доли данных, используемых для проверки. . 13. Как мы можно получить при случайном разделении один и тот же набор для проверки? . Оказывается, наши компьютеры не могут действительно генерировать случайные числа. Вместо этого они используют процесс, известный как псевдослучайный генератор. Однако этот процесс можно контролировать с помощью случайного seed. Если установить его начальное значение, то генератор псевдослучайных чисел будет генерировать “случайные” числа одним и тем же образом и они будут совпадать для каждого запуска. Определяя seed мы можем генерировать случайное разбиеник, которое всегда дает один и тот же набор для проверки. . 14. Какие буквы чаще всего используются для обозначения независимых и зависимых переменных? . х для независимых и y для зависимых. . 15. В чем разница между crop, pad и squish Resize ()? Когда и какой из них использовать? . crop изображения гризли: crop(обрезка) - это метод Resize() по умолчанию. В результате обрезается изображение так, чтобы оно соответствовало квадратной форме требуемого размера заполняя всю ширину и высоту. Это может привести к потере некоторых важных деталей. Например, если мы пытаемся распознать породу собаки или кошки, мы можем в конечном итоге обрезать ключевую часть тела или лица, необходимую для различения похожих пород. . | pad изображения гризли: pad-это альтернативный метод Resize (), который заполняет недостающие участки изображения нулями (которые отображаются черным цветом при просмотре изображений). Если мы заполняем изображения, то у нас есть много пустого пространства, которое тратиться впустую при вычислении для нашей модели и приводит к более низкому эффективному разрешению для той части изображения, которую мы фактически используем. . | squish изображения гризли: squish-это еще один альтернативный метод изменения размера, который либо сжимает, либо растягивает изображение. Это приводит к тому, что изображение принимает нереалистичную форму, что приведет к модели, которая запоминает вещи иначе, чем они есть на самом деле, и как следствие приводит к снижению точности. . | . Выбор метода изменения размера зависит от задачи и набора данных. Например, если объекты в изображениях набора данных занимают все изображение целиком и обрезка может привести к потере ценной информации, то более правильным будет использование методов сжатие и заполнения. . Другим хорошим методом является RandomResizedCrop, в котором обрезка изображения происходит случайным образом. В каждую эпоху модель будет видеть различную часть одного и того же изображения, что будет учтено при обучении. . 16. Что такое приращение данных? Зачем это нужно? . Приращение данных - создание случайных вариаций входных данных таким образом, что они кажутся разными, но при этом не изменяется их значение. Примеры включают в себя переворачивание, поворот, деформацию перспективы, изменение яркости и т. д. Приращение данных полезно для модели, чтобы лучше понять основную концепцию того, какие есть объекты и как интерисующие объекты представлены в изображениях. Таким образом, увеличение объема данных позволяет моделям машинного обучения проыодить обобщение . Это особенно важно, когда маркировка данных может быть медленной и дорогостоящей. . 17. В чем разница между item_tfms и batch_tfms? . item_tfms — используется для определения типа преобразований, применяемых к каждому изображению на процессоре. | batch_tfms — используется для определения типа преобразований, применяемых к каждому пакету на графическом процессоре. | . 18. ЧТо такое матрица ошибок(confusion matrix)? . Матрица ошибок - это сравнения сделанных предсказаний относительно истинных значений. Строки матрицы представляют собой истинные значения, а столбцы-предсказаные. Таким образом, количество изображений в диагональных элементах представляет собой количество правильно классифицированных изображений, в то время как вне диагональные элементы являются неправильно классифицированными изображениями. Матрицы ошибок предоставляют полезную информацию о том, насколько хорошо работает модель и для каких значений она склонна делать ошибки. . 19. Что export делает? . export сохраняет как архитектуру, так и обученные параметры архитектуры нейронной сети. Он также сохраняет то, как определен DataLoaders. . 20. Как это называется, когда мы используем модель для получения прогнозов вместо обучения? . Inference(вывод) . **21. Что такое виджеты IPython? . Виджеты IPython - это совместные функции JavaScript и Python, которые позволяют нам создавать и взаимодействовать с компонентами GUI (графи́ческий интерфе́йс по́льзователя) непосредственно в ноутбуке Jupyter. Примером этого может служить кнопка загрузки, которая может быть создана с помощью питоновской функции widgets.FileUpload(). . 22. Когда можно использовать процессор для развертывания? Когда лучше GPU? . Графические процессоры лучше всего подходят для выполнения идентичной работы параллельно. Если вы будете анализировать отдельные фрагменты данных за один раз (например, одно изображение или одно предложение), то процессоры могут быть более экономичными, особенно при том, что рыночной конкуренции за процессорные серверы больше по сравнению с конкуренцией за графические сервера. Графические процессоры можно использовать, если вы собираете ответы пользователей в пакеты за один раз и выполняете вывод на основании этого пакета. В связи с чем это будет вызывать задержку по времени в ожиданиях прогнозов модели. Кроме того, существует много других задач, когда ощущаются преимущества использования графического процессора, такие как управление памятью и работа с очередями из пакетов. . 23. Каковы недостатки развертывания приложения на сервере, а не на клиентском устройстве, таком как телефон или ПК? . Приложение для работы потребует подключения к сети, и у него будет дополнительная по времени задержки из-за сети при отправке входных данных и возврате результатов. Кроме того, отправка личных данных на сетевой сервер может привести к проблемам персональной безопасности. . 24. Три проблемы, которые могут возникнуть при внедрении системы предупреждения о медведях на практике? . Модель, которую мы обучили, скорее всего, будет работать плохо в следующих случаях: . Обработка ночных изображений | Работа с изображениями с низким разрешением (например, некоторые изображения смартфонов) | Запаздывание получение результатов что приводит к их бесполезности | **25. Что такое “данные вне домена”(“out of domain data”)? . Данные, которые принципиально отличаются в каком-то аспекте по сравнению с обучающими данными модели. Например, детектор объектов, который был обучен исключительно с помощью дневных фотографий, получает фотографию, сделанную ночью. . **26. Что такое “сдвиг домена”(“domain shift”)? . Это происходит, когда тип данных постепенно меняется с течением времени. Например, страховая компания использует модель глубокого обучения как часть своего алгоритма ценообразования, но со временем ее клиенты будут отличаться, причем исходные данные обучения не будут репрезентативны текущим данным. . 27. Каковы 3 шага в процессе развертывания? . Ручной процесс (Manual process) – модель запускается параллельно и непосредственно не управляет никакими действиями. Люди проверяют выходные данные модели. | Развертывание с ограниченным охватом (Limited scope deployment) – Область применения модели ограничена и тщательно контролируется. Например, ограничение выполнено по географическому и временному принципу, и в свою очередь это строго контролируется. | Постепенное расширение (Gradual expansion) – охват модели постепенно увеличивается и в то же время системы отчетности внедряются для проверки любых существенных изменений в предпринимаемых действиях по сравнению с процессом, если бы он выполнялся вручную (т. е. модели должны работать аналогично людям, если только уже не ожидается, что они будут выполнять лучше). | 28. Для своего проекта проведите мысленный эксперимент “что произойдет, если он пройдет очень, очень хорошо?” . Выполняется самостоятельно. . **29. Заведите блог и напишите свой первый пост в блоге. Например напишите о том, что, по вашему мнению, может быть полезно глубокое обучение в интересующей вас области. . Выполняется самостоятельно. .",
            "url": "https://zmey56.github.io/blog//markdown/fastai/russian/deep%20learning/2020/11/20/fastai-chapter2-solution.html",
            "relUrl": "/markdown/fastai/russian/deep%20learning/2020/11/20/fastai-chapter2-solution.html",
            "date": " • Nov 20, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Russian - Solution Lesson 2 on Fast.ai",
            "content": "В этом блокоте рассмотрено решение по второму и началу третьего урока на fast.ai. Сначало как обычно устанавливаются и подключаются необходиые библиотеки. . Первоначально загружаются изображения с помощью Bing Image Search. Для этого регистрируюсь в Microsoft (так как у меня уже есть учетка, то этого не потребовалось) для получения бесплатной учетной записи. Предоставляется ключ, который вставляю в место XXX . key = os.environ.get(&#39;AZURE_SEARCH_KEY&#39;, &#39;XXX&#39;) . search_images_bing . &lt;function fastbook.search_images_bing(key, term, min_sz=128)&gt; . Но в связи с изменениями формата запросов и поиска изображений при помощи Bing со стороны Microsoft запрос, который использовался в ферале 2020 года часто выдает ошибку. Из-за чего развернулась большая дискуссия на форуме fast.ai. Я предложил свое решение, но оно выглядело достаточно коряво. На основании его один из пользователей сделал новую функцию search_images_bing. . Успешно загрузжены URL-адреса 150 медведей гризли (или, по крайней мере, изображения, которые Bing Image Search находит для данного поискового запроса). Можно посмотреть на один из них: . dest = &#39;images/grizzly.jpg&#39; download_url(ims[0], dest) . im = Image.open(dest) im.to_thumb(128,128) . Для того, чтобы скачать все фото согласно поисковому запросу и поместить их в отдельные папки используется функция download_images из пакета fastai: . bear_types = &#39;grizzly&#39;,&#39;black&#39;,&#39;teddy&#39; path = Path(&#39;bears&#39;) . if not path.exists(): path.mkdir() for o in bear_types: dest = (path/o) dest.mkdir(exist_ok=True) results = search_images_bing(key, f&#39;{o} bear&#39;) download_images(dest, urls=results.attrgot(&#39;contentUrl&#39;)) . В результате в папках по 150 изображений . fns = get_image_files(path) fns . (#441) [Path(&#39;bears/grizzly/00000006.jpg&#39;),Path(&#39;bears/grizzly/00000005.jpg&#39;),Path(&#39;bears/grizzly/00000008.jpg&#39;),Path(&#39;bears/grizzly/00000009.jpg&#39;),Path(&#39;bears/grizzly/00000002.jpg&#39;),Path(&#39;bears/grizzly/00000003.jpg&#39;),Path(&#39;bears/grizzly/00000010.jpg&#39;),Path(&#39;bears/grizzly/00000000.jpg&#39;),Path(&#39;bears/grizzly/00000012.jpg&#39;),Path(&#39;bears/grizzly/00000007.jpg&#39;)...] . После этого проверяю загруженные файлы на наличие поврежденных . failed = verify_images(fns) failed . (#14) [Path(&#39;bears/black/00000026.jpg&#39;),Path(&#39;bears/black/00000032.jpg&#39;),Path(&#39;bears/black/00000039.jpg&#39;),Path(&#39;bears/black/00000122.jpg&#39;),Path(&#39;bears/black/00000119.jpg&#39;),Path(&#39;bears/teddy/00000010.jpg&#39;),Path(&#39;bears/teddy/00000004.jpg&#39;),Path(&#39;bears/teddy/00000055.jpg&#39;),Path(&#39;bears/teddy/00000047.jpg&#39;),Path(&#39;bears/teddy/00000065.jpg&#39;)...] . Чтобы удалить все &quot;бракованные&quot; изображения использую функцию unlink для каждого из них. В связи с тем, что verify_images возвращает объект типа L и в нем есть метод map, то переданная функция исполниться для каждого элемента коллекции: . failed.map(Path.unlink); . Все объекты хранятся в классе DataLoader, которые ему передаются. В результате они будут доступны как train и valid.С помощью DataBlock можно настроить каждый этап создания загрузчиков данных. В него передаются следующие параметры: . blocks=(ImageBlock, CategoryBlock) - кортеж, где содержится информация какие тип использовать для независимых и зависимых переменных. Независимая переменная-это то, что используется для предсказания, а зависимая переменная - результат. В этом случае независимыми переменными являются фото, а зависимыми переменными - категории (тип медведя) для каждого фото; | get_items=get_image_files - говорим, что для DataLoader данными будут являться пути к файлам. Функция get_image_files получает расположение и возвращает список всех изображений расположенных по этому пути (по умолчанию рекурсивно); | splitter=RandomSplitter(valid_pct=0.2, seed=42) - разделить train и valid случайным образом. Но для того, чтоб каждый раз разбивка не менялась, то фиксируется seed; | get_y=parent_label - функция, которая должна создать метки (зависимые переменные). parent_label-это функция, которая просто получает имя папки, в которой находится файл; | item_tfms=Resize(128) - преобразовать размер всех изображений к одному. | . bears = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . Дальше передаю путь, по которому можно найти изображения: . dls = bears.dataloaders(path) . Показать некоторые из элементов при помощи метода show_batch: . dls.valid.show_batch(max_n=4, nrows=1) . Примеры двух вариантов использования метода Resize: заполнить пустые мест изображения нулями (черными полями) или растянуть/сжать их: . bears = bears.new(item_tfms=Resize(128, ResizeMethod.Squish)) dls = bears.dataloaders(path) dls.valid.show_batch(max_n=4, nrows=1) . bears = bears.new(item_tfms=Resize(128, ResizeMethod.Pad, pad_mode=&#39;zeros&#39;)) dls = bears.dataloaders(path) dls.valid.show_batch(max_n=4, nrows=1) . Пример использования RandomResizedCrop вместо Resize - выбирается часть изображения, а остальная обрезается. Параметр min_scale определяет размер минимальной части изображения которую нужно выбирать каждый раз, а unique=True в функции show_batch - использование одного и то же изображения. . bears = bears.new(item_tfms=RandomResizedCrop(128, min_scale=0.3)) dls = bears.dataloaders(path) dls.train.show_batch(max_n=4, nrows=1, unique=True) . Трансформация изображений (поворот, переворачивание, деформация перспективы, изменение яркости и контрастности) функцией aug_transforms и двойное увеличение . bears = bears.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2)) dls = bears.dataloaders(path) dls.train.show_batch(max_n=8, nrows=2, unique=True) . Обучение модели с RandomResizedCrop в 224 px и aug_transforms: . bears = bears.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = bears.dataloaders(path) . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 1.084715 | 0.166342 | 0.047059 | 00:10 | . epoch train_loss valid_loss error_rate time . 0 | 0.171819 | 0.092201 | 0.047059 | 00:10 | . 1 | 0.129211 | 0.048695 | 0.035294 | 00:10 | . 2 | 0.095478 | 0.040643 | 0.023529 | 00:10 | . 3 | 0.075971 | 0.046714 | 0.023529 | 00:10 | . Проверка при помощи матрицы ошибок - confusion matrix: . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . Следующим шагом показываются изображения с максимальными потерями (loss) при помощи функции plot_top_losses. В заголовке каждого фото по порядку приведено следующее: предсказание, фактическая (целевая метка), потеря и вероятность. Вероятность - это уровень достоверности, от нуля до единицы, который модель присвоила своему прогнозу: . interp.plot_top_losses(5, nrows=1) . fastai включает в себя удобный графический интерфейс для очистки данных под названием ImageClassifierCleaner, который позволяет выбрать категорию и набор обучения по сравнению с проверкой и просмотреть изображения с наибольшей потерей (по порядку), а также меню, позволяющие выбирать изображения для удаления или повторной маркировки: . cleaner = ImageClassifierCleaner(learn) cleaner . После выполнения ручной разметки будут возращены индексы элементов для изменения. Чтобы удалить (разорвать связь) все изображения, выбранные для удаления, и переместить изображения, для которых мы выбрали другую категорию, запускается следующий код . После необходимо запустить повторное обучение и в результате можно добиться очень неплохих результатов. . &#1057;&#1086;&#1079;&#1076;&#1072;&#1085;&#1080;&#1077; &#1086;&#1085;&#1083;&#1072;&#1081;&#1085; &#1087;&#1088;&#1080;&#1083;&#1086;&#1078;&#1077;&#1085;&#1080;&#1103; . Вызвать функцию export, чтоб fastai сохранил модель в файл под названием export.pkl: . learn.export() . Далее проверка, что файл существует, используя метод ls, который у fastai добавлен в класс Path . path = Path() path.ls(file_exts=&#39;.pkl&#39;) . (#1) [Path(&#39;export.pkl&#39;)] . Чтобы создать вывод из экспортированного файла используется load_learner . learn_inf = load_learner(path/&#39;export.pkl&#39;) . Проводится проверка на одном из изображений, которое уже использовалось ранее . learn_inf.predict(&#39;images/grizzly.jpg&#39;) . (&#39;grizzly&#39;, TensorImage(1), TensorImage([3.8019e-06, 1.0000e+00, 1.0876e-07])) . В результате получили три значения: предсказанную категорию, индекс предсказанной категории и вероятности каждой категории. . Последние два основаны на порядке категорий в vocab DataLoaders: . learn_inf.dls.vocab . [&#39;black&#39;, &#39;grizzly&#39;, &#39;teddy&#39;] . &#1057;&#1086;&#1079;&#1076;&#1072;&#1085;&#1080;&#1077; Notebook App &#1087;&#1088;&#1080;&#1083;&#1086;&#1078;&#1077;&#1085;&#1080;&#1103; &#1085;&#1072; &#1086;&#1089;&#1085;&#1086;&#1074;&#1077; &#1084;&#1086;&#1076;&#1077;&#1083;&#1080; . Создать виджет загрузки файлов: . btn_upload = widgets.FileUpload() btn_upload . Теперь мы можем передать изображение, но по факту для упрощения загружаем файл: . img = PILImage.create(btn_upload.data[-1]) . Для показа изображениия используется виджет Output: . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . Тогда получаем прогнозы и используем Label чтобы их показать: . pred,pred_idx,probs = learn_inf.predict(img) . lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . Создаем кнопку, чтобы сделать классификацию: . btn_run = widgets.Button(description=&#39;Classify&#39;) btn_run . Создаем обработчик событий click . def on_click_classify(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; btn_run.on_click(on_click_classify) . Поместим все в коробку (VBox) для завершения GUI: . VBox([widgets.Label(&#39;Select your bear!&#39;), btn_upload, btn_run, out_pl, lbl_pred]) . &#1056;&#1072;&#1079;&#1074;&#1086;&#1088;&#1086;&#1090; Notebook &#1074; &#1088;&#1077;&#1072;&#1083;&#1100;&#1085;&#1086;&#1077; &#1087;&#1088;&#1080;&#1083;&#1086;&#1078;&#1077;&#1085;&#1080;&#1080; . Перед тем, как развернуть приложение, надо установить дополнительный пакет и сделать настройку. Но при настройке у меня выскакивала ошибка. На форуме нашел подсказку и привожу ниже уже исправленный вариант. . После этого я сделал сокращенный вариант своего блокнота и разместил все в репрозитории на github. Первые мои настройки приложения через Binder оканчивались неудачей. После пойска на форумах и на самом сайте попытался настройть через Heroku. Но и там не все так гладко - надо пересобирать с устаревшими библиотеками. Но как говориться - лень - двигатель прогресса: . Я взял в одном из репрозиториев файл requirements.txt (точнее скопировал из него четыре строчки с версиями библиотек). | Прочитал внимательно учебник и заметил ошибку, которую я допускал: помимо ссылки на github репрозиторий ОБЯЗАТЕЛЬНО в Path to notebook file необходимо File сменить на URL и прописать там следующий путь: /voila/render/bear_classifier.ipynb. Может можно как и по другому, но я не испытывал. | В результате у вас получается следующее. Если вдруг не запуститься, значит опять что-то перенастроили. Но в результате должен открываться пустой сайт с кнопкой для загрузке изображения. После загрузки появляется фото, ответ и его вероятность. .",
            "url": "https://zmey56.github.io/blog//russian/fast.ai/solution/2020/11/20/02-production.html",
            "relUrl": "/russian/fast.ai/solution/2020/11/20/02-production.html",
            "date": " • Nov 20, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "English - Using machine learning to predict gold mining stock prices",
            "content": "As a basis, I took a notebook published on colab for oil. This notebook examines the analysis of gold prices and shares of gold mining companies using machine analysis methods: linear regression, cluster analysis, and random forest. I immediately warn you that this post does not attempt to show the current situation and predict the future direction. Just like the author for oil, this article does not aim to raise or refute the possibilities of machine learning for analyzing stock prices or other tools. I upgraded the code for gold research in order to encourage those who are interested in further reflection and listen to constructive criticism in their address. . pip install yfinance --upgrade --no-cache-dir . Collecting yfinance Downloading https://files.pythonhosted.org/packages/7a/e8/b9d7104d3a4bf39924799067592d9e59119fcfc900a425a12e80a3123ec8/yfinance-0.1.55.tar.gz Requirement already satisfied, skipping upgrade: pandas&gt;=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.1.4) Requirement already satisfied, skipping upgrade: numpy&gt;=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.18.5) Requirement already satisfied, skipping upgrade: requests&gt;=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.23.0) Requirement already satisfied, skipping upgrade: multitasking&gt;=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9) Collecting lxml&gt;=4.5.1 Downloading https://files.pythonhosted.org/packages/64/28/0b761b64ecbd63d272ed0e7a6ae6e4402fc37886b59181bfdf274424d693/lxml-4.6.1-cp36-cp36m-manylinux1_x86_64.whl (5.5MB) |████████████████████████████████| 5.5MB 6.9MB/s Requirement already satisfied, skipping upgrade: pytz&gt;=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas&gt;=0.24-&gt;yfinance) (2018.9) Requirement already satisfied, skipping upgrade: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas&gt;=0.24-&gt;yfinance) (2.8.1) Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.20-&gt;yfinance) (1.24.3) Requirement already satisfied, skipping upgrade: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.20-&gt;yfinance) (2020.6.20) Requirement already satisfied, skipping upgrade: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.20-&gt;yfinance) (2.10) Requirement already satisfied, skipping upgrade: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.20-&gt;yfinance) (3.0.4) Requirement already satisfied, skipping upgrade: six&gt;=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.24-&gt;yfinance) (1.15.0) Building wheels for collected packages: yfinance Building wheel for yfinance (setup.py) ... done Created wheel for yfinance: filename=yfinance-0.1.55-py2.py3-none-any.whl size=22618 sha256=2b1a24b9e8937bf5603faead14841f6f3e045d79bd13bf0e76bc189db75a8640 Stored in directory: /tmp/pip-ephem-wheel-cache-5al_gsvn/wheels/04/98/cc/2702a4242d60bdc14f48b4557c427ded1fe92aedf257d4565c Successfully built yfinance Installing collected packages: lxml, yfinance Found existing installation: lxml 4.2.6 Uninstalling lxml-4.2.6: Successfully uninstalled lxml-4.2.6 Successfully installed lxml-4.6.1 yfinance-0.1.55 . import yfinance as yf import pandas as pd import numpy as np import seaborn as sns from sklearn import metrics import matplotlib.pyplot as plt from sklearn.preprocessing import MinMaxScaler from sklearn.linear_model import LinearRegression . 1. Loading data . For the price of gold, take the value of the exchange-traded investment Fund SPDR Gold Trust, whose shares are 100% backed by precious metal. The quotes will be compared with the prices of gold mining companies &#39; shares: . Newmont Goldcorp (NMM) | Barrick Gold (GOLD) | AngloGold Ashanti (AU) | Kinross Gold (KGC) | Newcrest Mining (ENC) | Polyus (PLZL) | Polymetal (POLY) | Seligdar (SELG) | . gold = pd.DataFrame(yf.download(&quot;GLD&quot;, start=&quot;2010-01-01&quot;, end=&quot;2019-12-31&quot;)[&#39;Adj Close&#39;]) . [*********************100%***********************] 1 of 1 completed . gold = gold.reset_index() gold.columns = [&quot;Date&quot;,&quot;gold_price&quot;] gold[&#39;Date&#39;] = pd.to_datetime(gold[&#39;Date&#39;]) gold.head() . Date gold_price . 0 2010-01-04 | 109.800003 | . 1 2010-01-05 | 109.699997 | . 2 2010-01-06 | 111.510002 | . 3 2010-01-07 | 110.820000 | . 4 2010-01-08 | 111.370003 | . It is necessary to move the price of gold, as we will be interested in how yesterday&#39;s price affected today&#39;s stock price. . gold[&quot;gold_price&quot;] = gold[&quot;gold_price&quot;].shift(1) . shares=[&quot;NMM.SG&quot;,&quot;GOLD&quot;,&quot;AU&quot;,&quot;KGC&quot;,&quot;NCM.AX&quot;,&quot;PLZL.ME&quot;,&quot;POLY.ME&quot;,&quot;SELG.ME&quot;] data= yf.download(shares, start=&quot;2010-01-01&quot;, end=&quot;2019-12-31&quot;)[&#39;Adj Close&#39;] . [*********************100%***********************] 8 of 8 completed . data = data.reset_index() data.head() . Date AU GOLD KGC NCM.AX NMM.SG PLZL.ME POLY.ME SELG.ME . 0 2010-01-04 | 39.698944 | 34.561649 | 18.105721 | 33.237167 | 26.924570 | NaN | NaN | NaN | . 1 2010-01-05 | 40.320408 | 34.989510 | 18.594805 | 33.901924 | 27.116940 | NaN | NaN | NaN | . 2 2010-01-06 | 41.601028 | 35.733963 | 19.256504 | 33.901924 | 27.289278 | NaN | NaN | NaN | . 3 2010-01-07 | 41.130215 | 35.229092 | 19.352404 | 34.298923 | NaN | NaN | NaN | NaN | . 4 2010-01-08 | 41.601028 | 35.451572 | 19.601744 | 33.421829 | 27.702093 | NaN | NaN | NaN | . data[&#39;Date&#39;] = pd.to_datetime(data[&#39;Date&#39;]) . all_data=pd.DataFrame() . for index in range(len(shares)): stock=pd.DataFrame() # transform the data stock=data.loc[:, (&quot;Date&quot;,shares[index])] stock[&quot;Date&quot;]=stock[&quot;Date&quot;].astype(&#39;datetime64[ns]&#39;) stock.columns=[&quot;Date&quot;,&quot;share_price&quot;] test=pd.DataFrame(gold) output=stock.merge(test,on=&quot;Date&quot;,how=&quot;left&quot;) #combining two data sets stock[&quot;gold_price&quot;]=output[&quot;gold_price&quot;] stock[&#39;share_price&#39;]=pd.to_numeric(stock[&#39;share_price&#39;], errors=&#39;coerce&#39;).dropna(0) stock[&#39;gold_price&#39;]=pd.to_numeric(stock[&#39;gold_price&#39;], errors=&#39;coerce&#39;).dropna(0) stock[&quot;year&quot;]=pd.to_datetime(stock[&quot;Date&quot;]).dt.year #Create a column with years for subsequent filtering stock[&quot;name&quot;]=shares[index] stock = stock.dropna() #delete all NAN lines #creating a column with a scaled share price scaler=MinMaxScaler() stock[&quot;share_price_scaled&quot;]=scaler.fit_transform(stock[&quot;share_price&quot;].to_frame()) #add data to the main dataframe all_data=all_data.append(stock) #add the data . all_data_15 = all_data[(all_data[&#39;year&#39;]&gt;2014)&amp;(all_data[&#39;year&#39;]&lt;2020)] all_data_15.head() . Date share_price gold_price year name share_price_scaled . 1301 2015-01-02 | 14.269927 | 113.580002 | 2015 | NMM.SG | 0.052072 | . 1302 2015-01-05 | 14.845476 | 114.080002 | 2015 | NMM.SG | 0.071190 | . 1303 2015-01-06 | 15.601913 | 115.800003 | 2015 | NMM.SG | 0.096317 | . 1304 2015-01-07 | 15.645762 | 117.120003 | 2015 | NMM.SG | 0.097773 | . 1305 2015-01-08 | 15.517859 | 116.430000 | 2015 | NMM.SG | 0.093525 | . 2. Data analysis . It is best to start analyzing data by presenting it visually, which will help you understand it better. . 2.1 Chart of gold price changes . gold[[&#39;Date&#39;,&#39;gold_price&#39;]].set_index(&#39;Date&#39;).plot(color=&quot;green&quot;, linewidth=1.0) plt.show() . 2.2. Plotting the pairplot chart for the price of Polyus and Barrick Gold shares over the past five years . palette=sns.cubehelix_palette(18, start=2, rot=0, dark=0, light=.95, reverse=False) g = sns.pairplot(all_data[(all_data[&#39;name&#39;]==&quot;POLY.ME&quot;)&amp;(all_data[&#39;year&#39;]&gt;2014)&amp;(all_data[&#39;year&#39;]&lt;2020)]. drop([&quot;share_price_scaled&quot;],axis=1), hue=&quot;year&quot;,height=4) g.fig.suptitle(&quot;Polyuse&quot;, y=1.08) palette=sns.cubehelix_palette(18, start=2, rot=0, dark=0, light=.95, reverse=False) f = sns.pairplot(all_data[(all_data[&#39;name&#39;]==&quot;GOLD&quot;)&amp;(all_data[&#39;year&#39;]&gt;2014)&amp;(all_data[&#39;year&#39;]&lt;2020)]. drop([&quot;share_price_scaled&quot;],axis=1), hue=&quot;year&quot;,height=4) f.fig.suptitle(&#39;Barrick Gold&#39;, y=1.08) plt.show() . A paired graph allows you to see the distribution of data by showing the paired relationships in the data set and the univariate distribution of data for each variable. You can also use the palette to see how this data changed in different years. . The chart is particularly interesting for 2016 and 2019, as it looks like the price of the Pole stock, Barrick Gold and the price of gold are lined up along the same line. We can also conclude from the distribution charts that the price of gold and stocks moved gradually towards higher values. . 2.3 Violinplot for the gold price . plt.figure(figsize=(10,10)) sns.set_style(&quot;whitegrid&quot;) palette=sns.cubehelix_palette(5, start=2.8, rot=0, dark=0.2, light=0.8, reverse=False) sns.violinplot(x=&quot;year&quot;, y=&quot;gold_price&quot;, data=all_data_15[[&quot;gold_price&quot;,&quot;year&quot;]], inner=&quot;quart&quot;, palette=palette, trim=True) plt.xlabel(&quot;Year&quot;) plt.ylabel(&quot;Price gold&quot;) plt.show() . 2.4 Violinplot for multiple shares . sns.catplot(x=&quot;year&quot;, y=&quot;share_price_scaled&quot;, col=&#39;name&#39;, col_wrap=3,kind=&quot;violin&quot;, split=True, data=all_data_15,inner=&quot;quart&quot;, palette=palette, trim=True, height=4, aspect=1.2) sns.despine(left=True) . A large fluctuation in gold prices was noted according to the charts in 2016 and 2019. As you can see from the graphs in the following figure, some companies such as Newmont Mining, Barrick Gold, AngloGold Ashanti, Newcrest Mining and Polymetal were also affected. It should also be noted that all prices are marked in the range from 0 to 1 and this may lead to inaccuracies in the interpretation. . Next, we will build distribution charts for one Russian company - Polymetal and one foreign company - Barrick Gold . sns.jointplot(&quot;gold_price&quot;, &quot;share_price&quot;,data=all_data_15[all_data_15[&#39;name&#39;]==&quot;POLY.ME&quot;],kind=&quot;kde&quot;, height=6,ratio=2,color=&quot;red&quot;).plot_joint(sns.kdeplot, zorder=0, n_levels=20) sns.jointplot(&quot;gold_price&quot;, &quot;share_price&quot;,data=all_data_15[all_data_15[&#39;name&#39;]==&quot;GOLD&quot;],kind=&quot;kde&quot;, height=6,ratio=2,color=&quot;red&quot;).plot_joint(sns.kdeplot, zorder=0, n_levels=20) plt.show() . /usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. FutureWarning /usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. FutureWarning . It is necessary to pay attention to the distribution of the share price for the two companies and it will become clear that the shape of the density graph is the same for them. . 2.5 Charts of the dependence of the share price of various companies on the price of gold . sns.lmplot(x=&quot;gold_price&quot;, y=&quot;share_price_scaled&quot;, col=&quot;name&quot;,ci=None, col_wrap=3, data=all_data_15, order=1,line_kws={&#39;color&#39;: &#39;blue&#39;},scatter_kws={&#39;color&#39;: &#39;grey&#39;}).set(ylim=(0, 1)) plt.show() . In fact, you won&#39;t be able to see much on these charts, although some stocks seem to have a relationship. . The next step is to try to color the charts depending on the years. . palette=sns.cubehelix_palette(5, start=2, rot=0, dark=0, light=.95, reverse=False) sns.lmplot(x=&quot;gold_price&quot;, y=&quot;share_price_scaled&quot;,hue=&quot;year&quot;, col=&quot;name&quot;,ci=None, col_wrap=3, data=all_data_15, order=1,palette=palette,height=4).set(ylim=(0, 1)) plt.show() . Here the picture is a little better in the sense that some companies have a data cloud stretching along a straight line in some years, which may indicate the existence of a dependency. . 3 Machine learning and prediction . I will give a definition for machine learning from Wikipedia: Machine learning is a class of artificial intelligence methods that are characterized not by direct problem solving, but by learning in the process of applying solutions to many similar problems. To build such methods, we use mathematical statistics, numerical methods, optimization methods, probability theory, graph theory, and various techniques for working with data in digital form. . Usually, machine learning algorithms can be classified into the following categories: learning with a teacher and learning without a teacher. Here is their definition from one of the sites: . Supervised learning is one of the sections of machine learning dedicated to solving the following problem. There is a set of objects (situations) and the set of possible answers (responses, reactions). There is some relationship between responses and objects, but it is unknown. Only a finite set of use cases is known — the &quot;object, response&quot; pairs, called the training sample. Based on this data, you need to restore the dependency, that is, build an algorithm that can give a fairly accurate answer for any object. To measure the accuracy of responses, a quality functional is introduced in a certain way. see the Links) . Unsupervised learning is one of the sections of machine learning. Studies a wide class of data processing problems in which only descriptions of a set of objects (training sample) are known, and it is required to detect internal relationships, dependencies, and patterns that exist between objects. Learning without a teacher is often contrasted with learning with a teacher, when each training object is given a &quot;correct answer&quot;, and you need to find the relationship between the objects and the answers. see links) . The following machine learning methods will be discussed later: . Cluster analysis | Linear regression | Random forest | . Using these algorithms, you can evaluate overvalued or undervalued stocks relative to the price of gold and possible movement on the next day. I remind you that you must be very careful and use the conclusions from this post at your own risk. I also remind you that my main goal is to show the potential of machine learning for stock valuation. . 3.1. Cluster analysis for Barrick Gold stock . Clustering is the task of dividing a set of objects into groups called clusters. Each group should contain &quot;similar&quot; objects, and objects from different groups should be as different as possible. . from sklearn.cluster import KMeans poly=all_data_15[all_data_15[&#39;name&#39;]==&quot;GOLD&quot;] # We need to scale also gold price, so clustering is not influenced by the relative size of one axis. poly=pd.DataFrame(poly) poly[&#39;gold_price_scaled&#39;] = scaler.fit_transform(poly[&quot;gold_price&quot;].to_frame()) poly[&quot;cluster&quot;] = KMeans(n_clusters=5, random_state=1).fit_predict(poly[[&quot;share_price_scaled&quot;,&quot;gold_price_scaled&quot;]]) # The 954 most common RGB monitor colors https://xkcd.com/color/rgb/ colors = [&quot;baby blue&quot;, &quot;amber&quot;, &quot;scarlet&quot;, &quot;grey&quot;,&quot;milk chocolate&quot;, &quot;windows blue&quot;] palette=sns.xkcd_palette(colors) sns.lmplot(x=&quot;gold_price&quot;, y=&quot;share_price_scaled&quot;,ci=None,palette=palette, hue=&quot;cluster&quot;,fit_reg=0 ,data=poly) plt.show() . Cluster analysis is used in a large number of machine learning tasks. But I have given it only for informational purposes, since in this form it does not bring much benefit to our analysis. . 3.2. Linear regression between Barrick Gold shares and the gold price . Next, we will build a regular linear regression using training with a teacher. The goal is to estimate the forecast of data for the last 100 days of 2019 based on data from 2018/2019 (excluding estimated ones). Training data is the data used to build the model, and test data is the data that we will try to predict. . for sh in shares: print(sh) #Data Preparation share_18=pd.DataFrame() share_18=all_data_15[(all_data_15[&#39;name&#39;]==sh)] # Get data 2018/19 share_18=share_18[[&quot;share_price&quot;,&quot;gold_price&quot;]].reset_index() # Just using 1 variable for linear regression. Split the data into training/testing sets train = share_18[:-100] test = share_18[-100:] x_train=train[&quot;gold_price&quot;].to_frame() y_train=train[&#39;share_price&#39;].to_frame() x_test=test[&quot;gold_price&quot;].to_frame() y_test=test[&#39;share_price&#39;].to_frame() regr = LinearRegression() #Create linear regression object regr.fit(x_train,y_train) #Train the model using the training sets print(&quot;Coefficients: &quot;, float(regr.coef_)) print(np.corrcoef(x_train,y_train, rowvar=False)) y_pred = regr.predict(x_test) print(&#39;Mean Absolute Error:&#39;, metrics.mean_absolute_error(y_test, y_pred)) print(&#39;Mean Squared Error:&#39;, metrics.mean_squared_error(y_test, y_pred)) print(&#39;Root Mean Squared Error:&#39;, np.sqrt(metrics.mean_squared_error(y_test, y_pred))) # Plot outputs using matplotlib plt_train=plt.scatter(x_train[&quot;gold_price&quot;],y_train, color=&#39;grey&#39;) plt_test=plt.scatter(x_test[&quot;gold_price&quot;],y_test, color=&#39;green&#39;) plt_pred=plt.scatter(x_test[&quot;gold_price&quot;], y_pred, color=&#39;black&#39;) plt.xlabel(&quot;gold_price&quot;) plt.ylabel(&quot;share_price&quot;) plt.legend((plt_train, plt_test,plt_pred),(&quot;train data&quot;, &quot;test data&quot;,&quot;prediction&quot;)) plt.show() . NMM.SG Coefficients: 0.6629423053739908 [[1. 0.790953] [0.790953 1. ]] Mean Absolute Error: 6.063058573972694 Mean Squared Error: 39.21188296210148 Root Mean Squared Error: 6.261939233344689 . GOLD Coefficients: 0.3355465472461071 [[1. 0.67139243] [0.67139243 1. ]] Mean Absolute Error: 3.3769293704374657 Mean Squared Error: 11.756813554455096 Root Mean Squared Error: 3.4288210152259473 . AU Coefficients: 0.31252669952857776 [[1. 0.67830589] [0.67830589 1. ]] Mean Absolute Error: 2.2471377544809683 Mean Squared Error: 5.789211153877581 Root Mean Squared Error: 2.4060779608893768 . KGC Coefficients: 0.10461302060876282 [[1. 0.78266367] [0.78266367 1. ]] Mean Absolute Error: 1.0583009847297946 Mean Squared Error: 1.1523726951635975 Root Mean Squared Error: 1.073486234268329 . NCM.AX Coefficients: 0.5623005799590818 [[1. 0.79891272] [0.79891272 1. ]] Mean Absolute Error: 2.0335289996635937 Mean Squared Error: 5.836462091267656 Root Mean Squared Error: 2.415877085297937 . PLZL.ME Coefficients: 103.84435014609612 [[1. 0.60373084] [0.60373084 1. ]] Mean Absolute Error: 1315.093426667142 Mean Squared Error: 1776892.2964767825 Root Mean Squared Error: 1333.0012364873419 . POLY.ME Coefficients: 10.772023429299809 [[1. 0.63694034] [0.63694034 1. ]] Mean Absolute Error: 69.33753863275061 Mean Squared Error: 6800.525447108329 Root Mean Squared Error: 82.46529844187995 . SELG.ME Coefficients: 0.15570348678870732 [[1. 0.51630147] [0.51630147 1. ]] Mean Absolute Error: 1.8096071903165585 Mean Squared Error: 4.039450515732427 Root Mean Squared Error: 2.009838430255633 . From the above charts, we can conclude that the price of gold predicts the price of shares of foreign companies on the next day quite well. In Russian companies, this picture looks much worse. Of course, there may be a false impression about Seligdar shares. But visual analysis of the chart allows you to discard this assumption. . 3.3 Random forest on Newmont Goldcorp shares against the price of gold and shares of gold companies . Random forest is a machine learning algorithm that uses a Committee (ensemble) of decision trees. The main idea is to use a large ensemble of decision trees, each of which in itself gives a very low quality of classification, but due to their large number, the result is good. . The random forest algorithm accepts more than one variable in the input data to predict the output data. It works very efficiently on large amounts of data, can handle many input variables, has efficient methods for estimating missing data, and many other advantages. The main disadvantages are: . Random forests is slow to generate forecasts because it has many decision trees. Whenever it makes a forecast, all the trees in the forest must make a forecast for the same given input and then vote on it. This whole process takes a long time. | the Model is difficult to interpret compared to the decision tree, where you can easily make a decision by following the path in the tree. | One of the great advantages of a random forest is that it can be used for both classification and regression problems, which make up most of today&#39;s machine learning systems. I will talk about random forests in classification, since classification is sometimes considered a building block of machine learning. Below you can see what a random forest with two trees looks like: . In addition to the gold price, we will use other variables to forecast the Newmont Goldcorp share price. This will be the share prices of other foreign gold mining companies. I know it doesn&#39;t make a lot of sense, but we just want to see how to build this type of model. This will allow us to see the impact of each of them on the final forecast.Random forest is a machine learning algorithm that uses a Committee (ensemble) of decision trees. The main idea is to use a large ensemble of decision trees, each of which in itself gives a very low quality of classification, but due to their large number, the result is good. . from sklearn.ensemble import RandomForestRegressor # 1.- Data Preparation nmm15=pd.DataFrame() nmm15=all_data_15[(all_data_15[&#39;name&#39;]==&quot;NMM.SG&quot;) &amp; (all_data_15[&#39;year&#39;]&gt;2016 )] nmm15=nmm15[[&quot;share_price&quot;,&quot;gold_price&quot;]].reset_index() # Load share price of other variables nmm15[&#39;GOLD&#39;]=all_data_15[(all_data_15[&#39;name&#39;]==&quot;GOLD&quot;)][-980:].reset_index()[&#39;share_price&#39;] nmm15[&#39;GOLD&#39;] = nmm15[&#39;GOLD&#39;].shift(1) nmm15[&#39;AU&#39;]=all_data_15[(all_data_15[&#39;name&#39;]==&quot;AU&quot;)][-980:].reset_index()[&#39;share_price&#39;] nmm15[&#39;AU&#39;] = nmm15[&#39;AU&#39;].shift(1) nmm15[&#39;KGC&#39;]=all_data_15[(all_data_15[&#39;name&#39;]==&quot;KGC&quot;)][-980:].reset_index()[&#39;share_price&#39;] nmm15[&#39;KGC&#39;] = nmm15[&#39;KGC&#39;].shift(1) nmm15[&#39;NCM.AX&#39;]=all_data_15[(all_data_15[&#39;name&#39;]==&quot;NCM.AX&quot;)][-980:].reset_index()[&#39;share_price&#39;] nmm15[&#39;NCM.AX&#39;] = nmm15[&#39;NCM.AX&#39;].shift(1) nmm15 = nmm15.drop(nmm15.index[0]) train = nmm15[:-100] test = nmm15[-100:] x_train=train[[&quot;gold_price&quot;,&quot;GOLD&quot;,&quot;AU&quot;,&quot;KGC&quot;,&quot;NCM.AX&quot;]] y_train=train[&#39;share_price&#39;] x_test=test[[&quot;gold_price&quot;,&quot;GOLD&quot;,&quot;AU&quot;,&quot;KGC&quot;,&quot;NCM.AX&quot;,]] y_test=test[&#39;share_price&#39;].to_frame() # 2.- Create Randomforest object usinig a max depth=5 regressor = RandomForestRegressor(n_estimators=200, max_depth=5 ) # 3.- Train data clf=regressor.fit(x_train, y_train) # 4.- Predict! y_pred=regressor.predict(x_test) y_pred_list = list(y_pred) y_pred=pd.DataFrame(y_pred) . plt_train=plt.scatter(x_train[&quot;gold_price&quot;],y_train, color=&#39;grey&#39;) plt_pred=plt.scatter(nmm15[&quot;gold_price&quot;], regressor.predict(nmm15[[&quot;gold_price&quot;,&quot;GOLD&quot;,&quot;AU&quot;,&quot;KGC&quot;,&quot;NCM.AX&quot;]]), color=&#39;black&#39;) plt.xlabel(&quot;gold_price&quot;) plt.ylabel(&quot;share_price&quot;) plt.legend((plt_train,plt_pred),(&quot;train data&quot;,&quot;prediction&quot;)) plt.show() . The resulting model looks really good in addition, we must remember that Random Forest has many more parameters to configure, but the key one is the maximum depth, which is unlimited by default. Next, we&#39;ll check how this model predicts or tests data. . plt_train=plt.scatter(x_train[&quot;gold_price&quot;],y_train, color=&#39;grey&#39;) plt_test=plt.scatter(x_test[&quot;gold_price&quot;],y_test, color=&#39;green&#39;) plt_pred=plt.scatter(x_test[&quot;gold_price&quot;], y_pred, color=&#39;black&#39;) plt.xlabel(&quot;gold_price&quot;) plt.ylabel(&quot;share_price&quot;) plt.legend((plt_train, plt_test,plt_pred),(&quot;train data&quot;, &quot;test data&quot;,&quot;prediction&quot;)) plt.show() . y_pred = clf.predict(x_test) print(&#39;Mean Absolute Error:&#39;, metrics.mean_absolute_error(y_test, y_pred)) print(&#39;Mean Squared Error:&#39;, metrics.mean_squared_error(y_test, y_pred)) print(&#39;Root Mean Squared Error:&#39;, np.sqrt(metrics.mean_squared_error(y_test, y_pred))) . Mean Absolute Error: 1.410409517520304 Mean Squared Error: 3.0995744019029483 Root Mean Squared Error: 1.7605608202794212 . importances=regressor.feature_importances_ indices=list(x_train) print(&quot;Feature ranking:&quot;) for f in range(x_train.shape[1]): print(&quot;Feature %s (%f)&quot; % (indices[f], importances[f])) f, (ax1) = plt.subplots(1, 1, figsize=(8, 6), sharex=True) sns.barplot(indices, importances, palette=&quot;BrBG&quot;, ax=ax1) ax1.set_ylabel(&quot;Importance&quot;) . Feature ranking: Feature gold_price (0.627703) Feature GOLD (0.045197) Feature AU (0.040957) Feature KGC (0.038973) Feature NCM.AX (0.247171) . /usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. FutureWarning . Text(0, 0.5, &#39;Importance&#39;) . By the importance of the signs, it immediately becomes clear how strong the value of gold is. . In short, I hope I was able to reveal to you the beginnings of a project on using machine learning to study stock prices, and I hope to hear your comments. .",
            "url": "https://zmey56.github.io/blog//english/machine%20learning/algotrading/2020/11/17/ml-prediction-gold-shares.html",
            "relUrl": "/english/machine%20learning/algotrading/2020/11/17/ml-prediction-gold-shares.html",
            "date": " • Nov 17, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Russian - Fastbook Chapter 1 questionnaire solutions",
            "content": "Решил собрать ответы на русском языке на вопросы к первой части курса Deep Learning 2020 на Fast.ai. Если есть притензии к переводу, то пешите в коментариях - поправлю. . 1. Что Вам нужно для изучения глубокого обучения: . Много математики - неправда | Много данных - неправда | Дорогой компьютер - неправда | Докторская Степень - неправда | . 2. Назовите пять областей, где глубокое обучение лучше всего представлено сейчас: . Любые пять из следующих: . Обработка естественного языка (NLP) – ответы на вопросы, обобщение и классификация документов и т. д . Компьютерное зрение – интерпретация съемок спутников и беспилотных аппаратов, распознавание и определение лиц, субтитры к изображениям и т. д. . Медицина – обнаружение аномалий в медицинских изображениях (например, КТ, рентген, МРТ), обнаружение особенностей на съемках тканей (патология), диагностика диабетической ретинопатии и т. д. . Биология – сворачиваемость белков, классификация, задачи геномики, классификация клеток и т. д. . Генерация изображения/улучшение – раскрашивание изображений, повышая разрешение изображения (супер-разрешение), удаление шума с изображения (шумоподавление), преобразование изображения в стиле известных художников (перемешывание стилей) и т. д. . Рекомендательные системы – веб-поиск, рекомендации по продуктам и т. д. . Игра – шахматы, го и т. д . Робототехника – управление объектами в зависимости от их местоположения . Другие приложения – финансовое и логистическое прогнозирование; преобразование текста в речь; многое, многое другое. . 3. Как называлось первое устройство, которое было основано на принципе искусственного нейрона? . Персептрон Mark I построенный Фрэнком Розенблаттом . 4. Какие существуют требования к “параллельной распределенной обработке” согласно книге? . Набор процессорных блоков | Состояние активации | Выходная функция для каждого блока | Закономерность связи между блоками | Правило распространения для распространения схем активации через сеть связей | Правило активации для объединения входов, воздействующих на блок, в текущем состоянии этого блока для получения нового уровня активации для блока | Правило обучения, в соответствии с которым схема связности модифицируется опытом | Среда, в которой должна работать система | . 5. Каковы были два теоретических постулата, которые сдерживали развитие нейронных сетей? . В 1969 году Марвин Мински и Сеймур Паперт продемонстрировали в своей книге “Персептроны”, что один слой искусственных нейронов не может выучить простые, критические математические функции, такие как логический элемент XOR. Хотя впоследствии они продемонстрировали в той же книге, что дополнительные слои могут решить эту проблему, было принято во внимание только первое утверждение, что явилось первой “зимой” для ИИ. . В 1980-х годах изучались модели с двумя слоями. Теоретически можно аппроксимировать любую математическую функцию, используя два слоя искусственных нейронов. Однако на практике эти сети были слишком большими и слишком медленными. Хотя было продемонстрировано, что добавление дополнительных слоев повышает производительность, это понимание не было признано, и началась вторая зима искусственного интеллекта. В последнее десятилетие, с увеличением доступности данных и улучшением компьютерного оборудования (как в производительности процессора, так и, что более важно, в производительности графического процессора), нейронные сети наконец-то оправдали свой потенциал. . 6. Что такое графический процессор (GPU)? . GPU расшифровывается как графический процессор (также известный как видеокарта). Стандартные компьютеры имеют различные компоненты, такие как процессоры, оперативная память и т. д. Процессоры, или центральные процессоры, являются основными блоками всех стандартных компьютеров, и они выполняют инструкции, которые составляют компьютерные программы. Графические процессоры, с другой стороны, являются специализированными устройствами, предназначенными для отображения графики, особенно 3D - графики в современных компьютерных играх. Аппаратная оптимизация, используемая в графических процессорах, позволяет ему обрабатывать тысячи задач одновременно. Кстати, эти оптимизации позволяют нам запускать и обучать нейронные сети в сотни раз быстрее, чем на обычных процессорах. . 7. Откройте блокнот и выполните ячейку, содержащую: 1+1 . Что же произойдет? . В блокноте Jupyter мы можем создавать ячейки кода и запускать код в интерактивном режиме. Когда мы выполняем ячейку, содержащую некоторый код (в данном случае: 1+1), код запускает Python, а выходные данные отображаются под ячейкой кода (в данном случае: 2). . 8. Проследите за каждой ячейкой урезанной версии записной книжки для этой главы. Прежде чем выполнить каждую ячейку, угадайте, что произойдет. . Это необходимо сделать самому. . 9. Заполните онлайн-приложение Jupyter Notebook. . Это необходимо сделать самому. . 10. Почему трудно использовать традиционные компьютерные программы для распознавания изображений на фотографии? . Для нас, людей, легко идентифицировать изображения на фотографиях, например, идентифицировать кошек и собак. Это происходит потому, что подсознательно наш мозг узнал, какие черты определяют кошку или собаку. Но трудно определить набор правил для компьютерной программы, которая так же сможет делать это успешно. Можете ли вы придумать универсальное правило, чтобы определить, содержит ли фотография кошку или собаку? Как бы вы закодировали это в виде компьютерной программы? Это очень трудно, потому что кошки, собаки или другие объекты имеют большое разнообразие форм, текстур, цветов и других особенностей, и это почти невозможно вручную закодировать в компьютерной программе. . 11. Что Сэмюэль имел в виду под “распределением веса” (Weight Assignment)? . “распределением веса” относится к текущим значениям параметров модели. Артур Сэмюэл далее упоминает “автоматическое средство проверки эффективности любого текущего распределение веса” и “механизм изменения значения веса таким образом, чтобы максимизировать производительность”. Это относится к оценке и обучению модели с целью получения набора значений параметров, которые максимизируют производительность модели. . 12. Какой термин мы обычно используем в глубоком обучении для тог, что Сэмюэл назвал “Весами”? . Вместо этого мы используем термин параметры. В глубоком обучении термин “вес” имеет другое значение. (Нейронная сеть имеет различные параметры, к которым мы подгоняем наши данные. Как показано в следующих главах, существуют два типа параметров нейронной сети - веса и смещение). . 13. Нарисуйте картинку, которая обобщает взгляд Артура Сэмюэля на модель машинного обучения. . . 14. Почему трудно принять, что модель глубокого обучения делает определенный прогноз? . Это хорошо изученная тема, известная как интерпретируемость моделей глубокого обучения. Модели глубокого обучения трудно понять отчасти из-за их “глубокой” природы. Представьте себе модель линейной регрессии. Просто у нас есть некоторые входные переменные/данные, которые умножаются на некоторые веса, давая нам на выход полученное значение. Мы можем понять, какие переменные более важны, а какие менее важны, основываясь на их весах. Аналогичная логика может применяться и для небольшой нейронной сети с 1-3 слоями. Однако глубокие нейронные сети имеют сотни, если не тысячи слоев. Трудно определить, какие факторы играют важную роль в определении конечного результата. Нейроны в сети взаимодействуют друг с другом, причем выходы из одних нейронов поступают в другие нейроны. В целом, из-за сложной природы моделей глубокого обучения очень трудно понять, почему нейронная сеть делает тот или иной прогноз. . 15. Как называется теорема о том, что нейронная сеть может решить любую математическую задачу с любой точностью? . Универсальная теорема аппроксимации утверждает, что нейронные сети теоретически могут решать любую математическую функцию. Однако важно понимать, что практически, в силу ограниченности имеющихся данных и компьютерного оборудования, обучить любую модель практически невозможно. Но мы можем подойти к решению очень близко! . 16. Что вам нужно для того, чтобы обучить модель? . Вам понадобится архитектура для задачи. Вам понадобятся данные для ввода в вашу модель. Для большинства случаев использования глубокого обучения вам понадобятся метки для ваших данных, чтобы сравнить предсказания вашей модели. Вам понадобится функция потерь, которая будет количественно измерять производительность вашей модели. И вам нужен способ обновить параметры модели, чтобы улучшить ее производительность (это называется оптимизация). . 17. Как цикл обратной связи может повлиять на внедрение прогностической полициской модели? . В прогностической полицейской модели мы могли бы получить положительную обратную связь, что привело бы к очень предвзятой модели с небольшой прогностической силой. Например, нам может понадобиться модель, которая предсказывала бы преступления, но мы используем информацию об арестах в качестве данных . Однако сами эти данные несколько искажены из-за предвзятости существующих полицейских процессов контроля. Обучение с этими данными приводит к необъективной модели. Правоохранительные органы могли бы использовать эту модель для определения того, где сосредоточить полицейскую деятельность, увеличивая число арестов в этих районах. Эти дополнительные аресты будут использоваться при обучении будущих итераций моделей, что приведет к еще более предвзятой модели. Этот цикл продолжается как положительная обратная связь. . 18. Всегда ли мы должны использовать изображения размером 224х224 пикселя в модели распознавания кошек? . Нет, мы этого не должны делаем. 224x224 обычно используется по историческим причинам. Вы можете увеличить размер и получить лучшую производительность, но заплатить скоростью и памятью. . 19. В чем разница между классификацией и регрессией? . Классификация ориентирована на предсказание класса или категории (например, типа домашнего животного). Регрессия ориентирована на предсказание числовой величины (например, возраста домашнего животного). . 20. Что такое проверочный набор (validation set)? Что такое тестовый набор(test set)? Зачем они нам нужны? . Проверочный набор - это часть данных, которая используется не для обучения модели, а для оценки модели во время обучения, чтобы предотвратить переобучение. Он гарантирует, что производительность модели не является результатом “мошейничиства” или запоминания набора данных, а скорее потому, что она изучает соответствующие возможности для прогнозирования. Однако вполне возможно, что мы также переобучаем проверочные данные. Это происходит потому, что разработчик модели также является частью процесса обучения, корректируя гиперпараметры и процедуры обучения в соответствии с значениями проверки. Поэтому для окончательной оценки модели используется другая неиспользованная часть набора данных-тестовый набор. Такое разбиение набора данных необходимо для обеспечения того, чтобы модель обобщалась на неиспользованных данных. . 21. Что сделает fastai, если вы не определите проверочный набор? . fastai автоматически создаст проверочный набор данных. Он случайным образом возьмет 20% данных и назначит их в качестве проверочного набора ( valid_pct = 0.2 . 22. Можем ли мы всегда использовать случайную выборку для проверочного набора? Почему или почему нет? . Хорошые проверочные и тестовые наборы должны быть репрезентативными для новых данных, которые модель будет использовать в будущем. Иногда это не так, если используется случайная выборка. Например, для данных временных рядов случайные выборки не имеют смысла. Вместо этого лучше определить различные периоды времени для тренировки, проверки и тестирования. . 23. Что такое переобучение? Приведите пример. . Переобучение является наиболее сложной проблемой, когда речь заходит о тренировки моделей машинного обучения. Переобучение относится к той ситуации, когда модель слишком близко подходит к ограниченному набору данных, но плохо работает на неиспользованных данных. Это особенно важно, когда речь заходит о нейронных сетях, потому что нейронные сети потенциально могут “запоминать” набор данных, на котором была обучена модель, и будут плохо работать с незадействованными данными, потому что они не “запоминали” основные истинные значения для этих данных. Вот почему необходима логичная структура проверки путем разделения данных на обучающие, проверочные и тестовые. . 24. Что такое метрика? В чем отличие от “потерь” (loss)? . Метрика - это функция, которая измеряет качество прогнозов модели с помощью набора валидации. Она похоже на потери, которая также является мерой производительности модели. Однако потери предназначены для алгоритма оптимизации (например, SGD) с целью эффективного обновления параметров модели, в то время как метрики являются интерпретируемым человеком показателями производительности. Иногда метрика также может быть хорошим выбором для потерь. . 25. Как могут помочь натренированные модели? . Предварительно натренированные модели обученые для задач, которые могут быть весьма схожи с текущей задачей. Например, предварительно обученные модели распознавания изображений часто обучались на наборе данных ImageNet, который содержит 1000 классов, ориентированных на множество различных типов визуальных объектов. Предварительно обученные модели полезны, потому что они уже научились обрабатывать множество простых функций, таких как распознавание краев и цветов. Однако, поскольку модель была обучена для другой задачи, чем решаемая, эта модель не может использоваться как есть. . 26. Что такое “голова”(head) модели? . При использовании предварительно обученной модели более поздние слои модели, которые были полезны для задачи, на которой первоначально обучалась модель, заменяются одним или несколькими новыми слоями с рандомизированными весами, подходящими по размеру для набора данных, с которым вы работаете. Эти новые слои называются “головой” модели. . 27. Какие особенности обнаруживаются в ранних слоях CNN и в более поздних слоях? . Более ранние слои изучают простые объекты, такие как диагональные, горизонтальные и вертикальные ребра. Более поздние слои изучают более продвинутые объекты, такие как автомобильные колеса, лепестки цветов и даже очертания животных. . 28. Являются ли модели изображений полезными только для фотографий? . Нет! Модели изображений могут быть полезны для других типов изображений, таких как чертежи, медицинские данные и т. д. | . Очень много информации можно представить в виде изображений. Например, звук может быть преобразован в спектрограмму, которая является визуальной интерпретацией звука. Временные ряды (например, финансовые данные) можно преобразовать в изображение, построив график. Более того, существуют различные преобразования, которые генерируют изображения из временных рядов и достигли хороших результатов для классификации временных рядов. Есть много других примеров, и, проявив творческий подход, вы можете сформулировать свою проблему как проблему классификации изображений и использовать предварительно подготовленные модели изображений для получения самых современных результатов! . 29. Что такое “архитектура”? . Архитектура-это шаблон или структура модели. Она определяет математическую модель, которую мы пытаемся обучить. . 30. Что такое сегментация? . По своей сути сегментация-это задача классификации по пикселям. Мы пытаемся предсказать метку для каждого отдельного пикселя изображения. В результате получаем шаблон части изображения соответствуют данной метке. . 31. Для чего используется y_range? Когда нам понадобится? . y_range используется для ограничения прогнозируемых значений, когда наша задача сосредоточена на предсказании числового значения в заданном диапазоне (например, прогнозирование рейтингов фильмов в диапазоне 0,5-5). . 32. Что такое “гиперпараметры”? . Обучающие модели требуют различных параметров, определяющих способ обучения модели. Например, нам нужно определить, как долго мы собираемся тренировать или скорость обучения (насколько быстро параметры модели могут изменяться). Такого рода параметры называются гиперпараметрами. . 33. Как лучше всего избежать неудач при использовании ИИ в организации? . Ключевые моменты, которые следует учитывать при использовании ИИ в организации: . Убедитесь, что обучающий, проверочный и тестовый набор правильно определены, чтобы соответствующим образом оценить модель. | Попробуйте построить простую базовую модель, которую будущая модель должны превзойти. Или даже этой простой базовой модели может быть достаточно в некоторых случаях. | .",
            "url": "https://zmey56.github.io/blog//markdown/fastai/russian/deep%20learning/2020/11/12/fastai-chapter1-solution.html",
            "relUrl": "/markdown/fastai/russian/deep%20learning/2020/11/12/fastai-chapter1-solution.html",
            "date": " • Nov 12, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi, I’m Alexander Gladkikh, and I made my own website on GitHub dedicated to my Hobbies: Machine learning, Deep Learning, and algorithmic trading. . I take part in kaggle competitions, have knowledge of R and Python (Pandas, NumPy, Scipy, Scikit-learn, XGBoost), Java . At the main work I participate in projects on the use of new technologies in the field of labor protection and ecology. . I have been engaged in technical analysis of financial markets for a long time. Familiar with software Amibroker, and Metatrader Quik (scripting). . At work I had to deal with the analysis of data in the performance of research in biology at the Institute and writing projects on environmental protection. . My degrees . Corporate Energy University, 2020 . Digital production technologies in the power industry . YANDEX, MIPT, 2019 . Machine learning and data analysis . City Business School, 2019 . MINI-MBA Professional .",
          "url": "https://zmey56.github.io/blog//about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://zmey56.github.io/blog//robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}