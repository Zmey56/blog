{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "2019-07-01-project-identification-of-internet-users-task.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uXK5_pITZTL"
      },
      "source": [
        "# Выпускной проект \"Идентификация интернет-пользователей\" Task\n",
        "\n",
        "> Graduation project \"Identification of Internet users\" Task\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- author: Zmey56\n",
        "- categories: [graduation project, machine learning, stepik, yandex]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqzlDz4I9awK"
      },
      "source": [
        "**Идентификация интернет-пользователей**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDEpyg_U-0zH"
      },
      "source": [
        "﻿В этом проекте мы будем решать задачу идентификации пользователя по его поведению в сети Интернет. Это сложная и интересная задача на стыке анализа данных и поведенческой психологии. В качестве примера, компания Яндекс решает задачу идентификации взломщика почтового ящика по его поведению. В двух словах, взломщик будет себя вести не так, как владелец ящика: он может не удалять сообщения сразу по прочтении, как это делал хозяин, он будет по-другому ставить флажки сообщениям и даже по-своему двигать мышкой. Тогда такого злоумышленника можно идентифицировать и \"выкинуть\" из почтового ящика, предложив хозяину войти по SMS-коду. Этот пилотный проект описан в статье на Хабрахабре. Похожие вещи делаются, например, в Google Analytics и описываются в научных статьях, найти можно многое по фразам \"Traversal Pattern Mining\" и \"Sequential Pattern Mining\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAk3nt5O_JHj"
      },
      "source": [
        "Мы будем решать похожую задачу: по последовательности из нескольких веб-сайтов, посещенных подряд одним и тем же человеком, мы будем идентифицировать этого человека. Идея такая: пользователи Интернета по-разному переходят по ссылкам, и это может помогать их идентифицировать (кто-то сначала в почту, потом про футбол почитать, затем новости, контакт, потом наконец – работать, кто-то – сразу работать, если это возможно).\n",
        "\n",
        "Будем использовать данные из [статьи](http://ceur-ws.org/Vol-1703/paper12.pdf) \"A Tool for Classification of Sequential Data\". И хотя мы не можем рекомендовать эту статью (описанные методы далеки от state-of-the-art, лучше обращаться к [книге](http://www.charuaggarwal.net/freqbook.pdf) \"Frequent Pattern Mining\" и последним статьям с ICDM), но данные там собраны аккуратно и представляют интерес.\n",
        "\n",
        "Имеются данные с прокси-серверов Университета Блеза Паскаля, их вид очень простой: ID пользователя, timestamp, посещенный веб-сайт.\n",
        "\n",
        "Скачать исходные данные можно по ссылке в статье (там же описание), для этого задания хватит данных не по всем 3000 пользователям, а по 10 и 150. [Ссылка](https://drive.google.com/open?id=11AqEDEITiodB8fcB8IZvp_5odfZuqAsS) на архив capstone_user_identification.zip (~7 Mb, в развернутом виде ~60 Mb).\n",
        "\n",
        "В ходе выполнения проекта вас ожидает 4 задания типа Programming Assignment, посвященных предобработке данных, первичному анализу, визуальному анализу данных, сравнению моделей классификации и настройке выбранной модели и изучению ее переобучения. Также у вас будет 3 взаимно оцениваемых задания (Peer Review) – по визуализации данных (в том числе со свеже созданными признаками), по оценке результатов участия в [соревновании](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) Kaggle Inclass и по всему проекту в целом.\n",
        "\n",
        "В ходе проекта мы будем работать с библиотекой Vowpal Wabbit. Если будут проблемы с ее установкой, можно воспользоваться Docker-образом, например, тем, что описан в [Wiki](https://github.com/Yorko/mlcourse_open/wiki/%D0%9F%D0%9E-%D0%B4%D0%BB%D1%8F-%D0%BF%D1%80%D0%BE%D1%85%D0%BE%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F-%D0%BA%D1%83%D1%80%D1%81%D0%B0-%D0%B8-Docker) репозитория [открытого курса](https://github.com/Yorko/mlcourse_open) OpenDataScience по машинному обучению."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRgJXMZw_u-A"
      },
      "source": [
        "**План проекта такой:**\n",
        "\n",
        "**1 неделя.** Подготовка данных к анализу и построению моделей. Programming Assignment\n",
        "\n",
        "Первая часть проекта посвящена подготовке данных для дальнейшего описательного анализа и построения прогнозных моделей. Надо будет написать код для предобработки данных (исходно посещенные веб-сайты указаны для каждого пользователя в отдельном файле) и формирования единой обучающей выборки. Также в этой части мы познакомимся с разреженным форматом данных (матрицы Scipy.sparse), который хорошо подходит для данной задачи.\n",
        "\n",
        "* Подготовка обучающей выборки\n",
        "* Работа с разреженным форматом данных\n",
        "\n",
        "**2 неделя.** Подготовка и первичный анализ данных. Programming Assignment\n",
        "\n",
        "На второй неделе мы продолжим подготовливать данные для дальнейшего анализа и построения прогнозных моделей. Конкретно, раньше мы определили что сессия – это последовательность из 10 посещенных пользователем сайтов, теперь сделаем длину сессии параметром, и потом при обучении прогнозных моделей выберем лучшую длину сессии. Также мы познакомимся с предобработанными данными и статистически проверим первые гипотезы, связанные с нашими наблюдениями.\n",
        "\n",
        "* Подготовка нескольких обучающих выборок для сравнения\n",
        "* Первичный анализ данных, проверка гипотез\n",
        "\n",
        "**3 неделя.** Визуальный анализ данных построение признаков. Peer-Review\n",
        "\n",
        "На 3 неделе мы займемся визуальным анализом данных и построением признаков. Сначала мы вместе построим и проанализируем несколько признаков, потом Вы сможете сами придумать и описать различные признаки. Задание имеет вид Peer-Review, так что творчество здесь активно приветствуется. Если задействуете IPython-виджеты, библиотеку Plotly, анимации и прочий интерактив, всем от этого будет только лучше.\n",
        "\n",
        "* Визуальный анализ данных\n",
        "* Построение признаков\n",
        "\n",
        "**4 неделя.** Сравнение алгоритмов классификации. Programming Assignment\n",
        "\n",
        "Тут мы наконец подойдем к обучению моделей классификации, сравним на кросс-валидации несколько алгоритмов, разберемся, какие параметры длины сессии (session_length и window_size) лучше использовать. Также для выбранного алгоритма построим кривые валидации (как качество классификации зависит от одного из гиперпараметров алгоритма) и кривые обучения (как качество классификации зависит от объема выборки).\n",
        "\n",
        "* Сравнение нескольких алгоритмов на сессиях из 10 сайтов\n",
        "* Выбор параметров – длины сессии и ширины окна\n",
        "* Идентификация конкретного пользователя и кривые обучения\n",
        "\n",
        "**5 неделя.** Соревнование Kaggle Inclass по идентификации пользователей. Peer-Review\n",
        "\n",
        "Здесь мы вспомним про концепцию стохастического градиентного спуска и попробуем классификатор Scikit-learn SGDClassifier, который работает намного быстрее на больших выборках, чем алгоритмы, которые мы тестировали на 4 неделе. Также мы познакомимся с данными соревнования Kaggle по идентификации пользователей и сделаем в нем первые посылки. По итогам этой недели дополнительные баллы получат те, кто побьет указанные в соревновании бенчмарки.\n",
        "\n",
        "**6 неделя.** Vowpal Wabbit. Tutorial + Programming Assignment\n",
        "\n",
        "На этой неделе мы познакомимся с популярной библиотекой Vowpal Wabbit и попробуем ее на данных по веб-сессиям. Знакомиться будем на данных Scikit-learn по новостям, сначала в режиме бинарной классификации, затем – в многоклассовом режиме. Затем будем классифицировать рецензии к фильмам с сайта IMDB. Наконец, применим Vowpal Wabbit к данным по веб-сессиям. Материала немало, но Vowpal Wabbit того стоит!\n",
        "\n",
        "* Статья про Vowpal Wabbit\n",
        "* Применение Vowpal Wabbit к данным по посещению сайтов\n",
        "\n",
        "**7 неделя.** Оформление финального проекта. Peer-Review\n",
        "\n",
        "В самом конце Вас ожидает взаимная проверка финальных версий проекта. Здесь можно будет разгуляться, поскольку свобода творчества есть на каждом этапе проекта: можно использовать все исходные данные по 3000 пользователям, можно создавать свои интересные признаки, строить красивые картинки, использовать свои модели или ансамбли моделей и делать выводы. Поэтому совет такой: по мере выполнения заданий параллельно копируйте код и описание в .ipynb-файл проекта или описывайте результаты по ходу в текстовом редакторе."
      ]
    }
  ]
}