{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "2019-07-01-project-identification-of-internet-users-task .ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uXK5_pITZTL"
      },
      "source": [
        "# Graduation project \"Identification of Internet users\" Task\n",
        "\n",
        "> Выпускной проект \"Идентификация интернет-пользователей\" Task\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- author: Zmey56\n",
        "- categories: [graduation project, machine learning, stepik, yandex, english]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqzlDz4I9awK"
      },
      "source": [
        "**Identification of Internet users**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDEpyg_U-0zH"
      },
      "source": [
        "In this project, we will solve the problem of identifying a user by his behavior on the Internet. This is a complex and interesting task at the intersection of data analysis and behavioral psychology. As an example, Yandex solves the problem of identifying a mailbox cracker by his behavior. In a nutshell, the hacker will behave differently from the owner of the mailbox: he may not delete messages immediately after reading, as the owner did, he will check the messages differently and even move the mouse in his own way. Then such an attacker can be identified and \"thrown out\" of the mailbox by inviting the owner to enter by SMS code. This pilot project is described in an article on Habrahabr. Similar things are done, for example, in Google Analytics and are described in scientific articles, you can find a lot by the phrases \"Traversal Pattern Mining\" and \"Sequential Pattern Mining\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAk3nt5O_JHj"
      },
      "source": [
        "We will solve a similar problem: by a sequence of several websites visited in a row by the same person, we will identify this person. The idea is this: Internet users follow links in different ways, and this can help identify them (someone first to the mail, then to read about football, then news, contact, then finally to work, someone to work immediately, if possible).\n",
        "\n",
        "We will use data from the [article](http://ceur-ws.org/Vol-1703/paper12.pdf) \"A Tool for Classification of Sequential Data\". And although we cannot recommend this article (the described methods are far from state-of-the-art, it is better to refer to the [book](http://www.charuaggarwal.net/freqbook.pdf) \"Frequent Pattern Mining\" and the latest articles with ICDM), but the data there are collected neatly and are of interest.\n",
        "\n",
        "There is data from the Blaise Pascal University proxy servers, their appearance is very simple: user ID, timestamp, visited website.\n",
        "\n",
        "You can download the source data from the link in the article (there is also a description), for this task there is enough data not for all 3000 users, but for 10 and 150. [Link](https://drive.google.com/open?id=11AqEDEITiodB8fcB8IZvp_5odfZuqAsS) to the archive capstone_user_identification.zip (~7 Mb, expanded ~60 Mb).\n",
        "\n",
        "In the course of the project, you will have 4 tasks of the Programming Assignment type, dedicated to data preprocessing, primary analysis, visual data analysis, comparison of classification models and setting up the selected model and studying its retraining. You will also have 3 mutually evaluated tasks (Peer Review) - on data visualization (including with newly created features), on evaluating the results of participation in [competition](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2 ) Kaggle Inclass and throughout the project as a whole.\n",
        "\n",
        "During the project, we will work with the Vowpal Wabbit library. If there are problems with its installation, you can use the Docker image, for example, the one described in [Wiki](https://github.com/Yorko/mlcourse_open/wiki/%D0%9F%D0%9E-%D0%B4%D0%BB%D1%8F-%D0%BF%D1%80%D0%BE%D1%85%D0%BE%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F-%D0%BA%D1%83%D1%80%D1%81%D0%B0-%D0%B8-Docker ) of the [open course](https://github.com/Yorko/mlcourse_open ) repository OpenDataScience on machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRgJXMZw_u-A"
      },
      "source": [
        "**The project plan is as follows:**\n",
        "\n",
        "**1 week.** Preparing data for analysis and model building. Programming Assignment\n",
        "\n",
        "The first part of the project is devoted to the preparation of data for further descriptive analysis and the construction of predictive models. It will be necessary to write code for preprocessing the data (the websites initially visited are indicated for each user in a separate file) and forming a single training sample. Also in this part we will get acquainted with the sparse data format (Scipy.sparse matrices), which is well suited for this task.\n",
        "\n",
        "* Preparing a training sample\n",
        "* Working with the sparse data format\n",
        "\n",
        "**2 week.** Preparation and initial analysis of data. Programming Assignment\n",
        "\n",
        "In the second week, we will continue to prepare data for further analysis and construction of forecast models. Specifically, earlier we determined that a session is a sequence of 10 sites visited by a user, now we will make the session length a parameter, and then when training predictive models we will choose the best session length. We will also get acquainted with the preprocessed data and statistically test the first hypotheses related to our observations.\n",
        "\n",
        "* Preparation of several training samples for comparison\n",
        "* Primary data analysis, hypothesis testing\n",
        "\n",
        "**3 week.** Visual data analysis and feature construction. Peer-Review\n",
        "\n",
        "In week 3, we will be engaged in visual data analysis and feature construction. First, we will build and analyze several signs together, then you will be able to come up with and describe various signs yourself. The task has the form of a Peer-Review, so creativity is actively welcome here. If you use IPython widgets, the Plotly library, animations and other interactive tools, it will only be better for everyone.\n",
        "\n",
        "* Visual data analysis\n",
        "* Building features\n",
        "\n",
        "**4 weeks.** Comparison of classification algorithms. Programming Assignment\n",
        "\n",
        "Here we will finally approach the training of classification models, compare several algorithms on cross-validation, and figure out which session length parameters (session_length and window_size) are better to use. Also, for the selected algorithm, we will construct validation curves (how the classification quality depends on one of the hyperparameters of the algorithm) and learning curves (how the classification quality depends on the sample size).\n",
        "\n",
        "* Comparison of several algorithms in sessions from 10 sites\n",
        "* Selection of parameters - session length and window width\n",
        "* User-specific identification and learning curves\n",
        "\n",
        "**Week 5.** Kaggle Inclass User Identification competition. Peer-Review\n",
        "\n",
        "Here we will recall the concept of stochastic gradient descent and try the Scikit-learn SGDClassifier classifier, which works much faster on large samples than the algorithms we tested in week 4. We will also get acquainted with the data of the Kaggle user identification competition and make the first parcels in it. At the end of this week, those who beat the benchmarks specified in the competition will receive additional points.\n",
        "\n",
        "**Week 6.** Vowpal Wabbit. Tutorial + Programming Assignment\n",
        "\n",
        "This week we will get acquainted with the popular Vowpal Wabbit library and try it on web session data. We will get acquainted with the Scikit-learn data on the news, first in binary classification mode, then in multiclass mode. Then we will classify movie reviews from the IMDB website. Finally, let's apply Vowpal Wabbit to web session data. There is a lot of material, but Vowpal Wabbit is worth it!\n",
        "\n",
        "* Article about Vowpal Wabbit\n",
        "* Applying Vowpal Wabbit to site visit data\n",
        "\n",
        "**Week 7.** Design of the final project. Peer-Review\n",
        "\n",
        "At the very end, mutual verification of the final versions of the project awaits you. It will be possible to roam around here, because there is freedom of creativity at every stage of the project: you can use all the source data for 3000 users, you can create your own interesting signs, build beautiful pictures, use your models or ensembles of models and draw conclusions. Therefore, the advice is as follows: as the tasks are completed, copy the code and description in parallel to the .ipynb file of the project or describe the results along the way in a text editor."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EtxD_s95qkII"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}