{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MY_week6_vowpal_checked.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Graduation project \"Identification of Internet users\" - Vowpal Wabbit. Tutorial + Programming Assignment\n",
        "\n",
        "> Выпускной проект \"Идентификация интернет-пользователей\" Week 6\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- author: Zmey56\n",
        "- categories: [graduation project, machine learning, stepik, yandex, VowpalWabbit, english]"
      ],
      "metadata": {
        "id": "uWqiuhW3e3Tn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 6. Vowpal Wabbit. Tutorial + Programming Assignment\n",
        "\n",
        "This week we will get acquainted with the popular Vowpal Wabbit library and try it on site visit data.\n",
        "\n",
        "**6 week plan:**\n",
        "- Part 1. Article on Vowpal Wabbit\n",
        "- Part 2. Application of Vowpal Wabbit to Site Visit data\n",
        "- 2.1. Data Preparation\n",
        "- 2.2. Validation by Deferred Sampling\n",
        "- 2.3. Validation by test Sampling (Public Leaderboard)\n",
        "\n",
        "**In this part of the project, videos of the following lectures of the course \"Learning from marked data\" may be useful to us:**\n",
        "* [Stochastic gradient спуск](https://www.coursera.org/learn/supervised-learning/lecture/xRY50/stokhastichieskii-ghradiientnyi-spusk)\n",
        "* [Linear models. `sklearn.linear_model`. Классификация](https://www.coursera.org/learn/supervised-learning/lecture/EBg9t/linieinyie-modieli-sklearn-linear-model-klassifikatsiia)\n",
        "   \n",
        "[Presentation] will also be useful(https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem08_vw.pdf ) lecturer of specialization Evgeny Sokolov. And, of course, [documentation](https://github.com/JohnLangford/vowpal_wabbit/wiki ) Vowpal Wabbit."
      ],
      "metadata": {
        "id": "dFL9NhBWfUxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1. Article about Vowpal Wabbit\n",
        "Let's read [the article](http://habrahabr.ru/company/tods/blog/326418/) about Vowpal Wabbit on Habra from the OpenDataScience open course series on machine learning. We can download [notebook](https://github.com/Yorko/mlcourse_open/blob/master/jupyter_russian/topic08_sgd_hashing_vowpal_wabbit/topic8_sgd_hashing_vowpal_wabbit.ipynb), attached to the article, view the code, study it and change it. This is the only way to deal with Vowpal Wabbit."
      ],
      "metadata": {
        "id": "B_nFsjSygoJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Applying Vowpal Wabbit to Site Visit Data"
      ],
      "metadata": {
        "id": "ei76Tdu9jSra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Data preparation"
      ],
      "metadata": {
        "id": "oWB5VEuUjWV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next, let's look at Vowpal Wabbit in action. However, in the task of our competition for binary classification of web sessions, we will not notice a difference - both in quality and in speed (although you can check). Therefore, we will demonstrate all the agility of VW in the task of classification into 400 classes. The initial data is still the same, but 400 users have been allocated, and the task of identifying them is being solved. Download the data [from here](https://www.kaggle.com/anton11/trainsessions), [and here we will fill in the result](https://www.kaggle.com/c/identify-me-if-you-can4/submit) - files `train_sessions_400users.csv` and `test_sessions_400users.csv`.**"
      ],
      "metadata": {
        "id": "GLlW3b26jzga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.sparse as sps\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "EnpbQFryoLEm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ruUXv497ehS4"
      },
      "outputs": [],
      "source": [
        "# Let's define our way to the data\n",
        "PATH_TO_DATA = '/content/drive/MyDrive/DATA/Stepik/Kaggle' "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's upload the training and test samples. It can be noticed that the test sessions here are clearly separated in time from the sessions in the training sample.**"
      ],
      "metadata": {
        "id": "lKVi3mC-pp0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_400 = pd.read_csv(os.path.join(PATH_TO_DATA,'train_sessions_400users.csv'), \n",
        "                           index_col='session_id')"
      ],
      "metadata": {
        "id": "R3D-TvJGoE9G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_400 = pd.read_csv(os.path.join(PATH_TO_DATA,'test_sessions_400users.csv'), \n",
        "                           index_col='session_id')"
      ],
      "metadata": {
        "id": "I1j0FSTLpv9e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_400.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F2HXOUlGiLm",
        "outputId": "47b7323f-da56-4cfc-ec55-15d5765b884c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46473, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_400.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "ue0hBwNjqJAD",
        "outputId": "76797dbe-67d9-42dd-a6eb-bd9a0147f0cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-366ab81a-d3bc-4a92-a854-53a547ab7afd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site1</th>\n",
              "      <th>time1</th>\n",
              "      <th>site2</th>\n",
              "      <th>time2</th>\n",
              "      <th>site3</th>\n",
              "      <th>time3</th>\n",
              "      <th>site4</th>\n",
              "      <th>time4</th>\n",
              "      <th>site5</th>\n",
              "      <th>time5</th>\n",
              "      <th>site6</th>\n",
              "      <th>time6</th>\n",
              "      <th>site7</th>\n",
              "      <th>time7</th>\n",
              "      <th>site8</th>\n",
              "      <th>time8</th>\n",
              "      <th>site9</th>\n",
              "      <th>time9</th>\n",
              "      <th>site10</th>\n",
              "      <th>time10</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23713</td>\n",
              "      <td>2014-03-24 15:22:40</td>\n",
              "      <td>23720.0</td>\n",
              "      <td>2014-03-24 15:22:48</td>\n",
              "      <td>23713.0</td>\n",
              "      <td>2014-03-24 15:22:48</td>\n",
              "      <td>23713.0</td>\n",
              "      <td>2014-03-24 15:22:54</td>\n",
              "      <td>23720.0</td>\n",
              "      <td>2014-03-24 15:22:54</td>\n",
              "      <td>23713.0</td>\n",
              "      <td>2014-03-24 15:22:55</td>\n",
              "      <td>23713.0</td>\n",
              "      <td>2014-03-24 15:23:01</td>\n",
              "      <td>23713.0</td>\n",
              "      <td>2014-03-24 15:23:03</td>\n",
              "      <td>23713.0</td>\n",
              "      <td>2014-03-24 15:23:04</td>\n",
              "      <td>23713.0</td>\n",
              "      <td>2014-03-24 15:23:05</td>\n",
              "      <td>653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8726</td>\n",
              "      <td>2014-04-17 14:25:58</td>\n",
              "      <td>8725.0</td>\n",
              "      <td>2014-04-17 14:25:59</td>\n",
              "      <td>665.0</td>\n",
              "      <td>2014-04-17 14:25:59</td>\n",
              "      <td>8727.0</td>\n",
              "      <td>2014-04-17 14:25:59</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2014-04-17 14:25:59</td>\n",
              "      <td>8725.0</td>\n",
              "      <td>2014-04-17 14:26:01</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2014-04-17 14:26:01</td>\n",
              "      <td>5320.0</td>\n",
              "      <td>2014-04-17 14:26:18</td>\n",
              "      <td>5320.0</td>\n",
              "      <td>2014-04-17 14:26:47</td>\n",
              "      <td>5320.0</td>\n",
              "      <td>2014-04-17 14:26:48</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>303</td>\n",
              "      <td>2014-03-21 10:12:24</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2014-03-21 10:12:36</td>\n",
              "      <td>303.0</td>\n",
              "      <td>2014-03-21 10:12:54</td>\n",
              "      <td>303.0</td>\n",
              "      <td>2014-03-21 10:13:01</td>\n",
              "      <td>303.0</td>\n",
              "      <td>2014-03-21 10:13:24</td>\n",
              "      <td>303.0</td>\n",
              "      <td>2014-03-21 10:13:36</td>\n",
              "      <td>303.0</td>\n",
              "      <td>2014-03-21 10:13:54</td>\n",
              "      <td>309.0</td>\n",
              "      <td>2014-03-21 10:14:01</td>\n",
              "      <td>303.0</td>\n",
              "      <td>2014-03-21 10:14:06</td>\n",
              "      <td>303.0</td>\n",
              "      <td>2014-03-21 10:14:24</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1359</td>\n",
              "      <td>2013-12-13 09:52:28</td>\n",
              "      <td>925.0</td>\n",
              "      <td>2013-12-13 09:54:34</td>\n",
              "      <td>1240.0</td>\n",
              "      <td>2013-12-13 09:54:34</td>\n",
              "      <td>1360.0</td>\n",
              "      <td>2013-12-13 09:54:34</td>\n",
              "      <td>1344.0</td>\n",
              "      <td>2013-12-13 09:54:34</td>\n",
              "      <td>1359.0</td>\n",
              "      <td>2013-12-13 09:54:34</td>\n",
              "      <td>1346.0</td>\n",
              "      <td>2013-12-13 09:54:34</td>\n",
              "      <td>1345.0</td>\n",
              "      <td>2013-12-13 09:54:34</td>\n",
              "      <td>1344.0</td>\n",
              "      <td>2013-12-13 09:58:19</td>\n",
              "      <td>1345.0</td>\n",
              "      <td>2013-12-13 09:58:19</td>\n",
              "      <td>601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11</td>\n",
              "      <td>2013-11-26 12:35:29</td>\n",
              "      <td>85.0</td>\n",
              "      <td>2013-11-26 12:35:31</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2013-11-26 12:35:31</td>\n",
              "      <td>85.0</td>\n",
              "      <td>2013-11-26 12:35:32</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2013-11-26 12:35:32</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2013-11-26 12:35:32</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2013-11-26 12:37:03</td>\n",
              "      <td>85.0</td>\n",
              "      <td>2013-11-26 12:37:03</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2013-11-26 12:37:03</td>\n",
              "      <td>85.0</td>\n",
              "      <td>2013-11-26 12:37:04</td>\n",
              "      <td>273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-366ab81a-d3bc-4a92-a854-53a547ab7afd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-366ab81a-d3bc-4a92-a854-53a547ab7afd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-366ab81a-d3bc-4a92-a854-53a547ab7afd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            site1                time1  ...               time10 user_id\n",
              "session_id                              ...                             \n",
              "1           23713  2014-03-24 15:22:40  ...  2014-03-24 15:23:05     653\n",
              "2            8726  2014-04-17 14:25:58  ...  2014-04-17 14:26:48     198\n",
              "3             303  2014-03-21 10:12:24  ...  2014-03-21 10:14:24      34\n",
              "4            1359  2013-12-13 09:52:28  ...  2013-12-13 09:58:19     601\n",
              "5              11  2013-11-26 12:35:29  ...  2013-11-26 12:37:04     273\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We see that there are 182793 sessions in the training sample, 46473 in the test sample, and the sessions really belong to 400 different users.**"
      ],
      "metadata": {
        "id": "Y7_TqAnXqaCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_400.shape, test_df_400.shape, train_df_400['user_id'].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NIu9nl0qLOe",
        "outputId": "13704499-ce81-49c0-e983-722827cf9b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((182793, 21), (46473, 20), 400)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vowpal Wabbit likes class labels to be distributed from 1 to K, where K is the number of classes in the classification problem (in our case, 400). Therefore, we will have to use LabelEncoder, and then add +1 (Label Encoder translates labels into the range from 0 to K-1). Then it will be necessary to apply the reverse transformation.**"
      ],
      "metadata": {
        "id": "KJxzoHhoqrdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = train_df_400.user_id\n",
        "class_encoder = preprocessing.LabelEncoder()\n",
        "y_for_vw = class_encoder.fit_transform(y)+1"
      ],
      "metadata": {
        "id": "Pu42gNqoq6nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next, we will compare VW with SGDClassifier and with logistic regression. All these models need input data preprocessing. Let's prepare sparse matrices for sklearn models, as we did in part 5:**\n",
        "\n",
        "* combine training and test samples\n",
        "* we will select only sites (signs from 'site1' to 'site10')\n",
        "* replace the omissions with zeros (our sites were numbered from 0)\n",
        "* we will translate into a sparse csr_matrix format\n",
        "* let's break back into the training and test parts"
      ],
      "metadata": {
        "id": "iz97hZMDrcQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# combine training and test samples\n",
        "\n",
        "train_test_df = pd.concat([train_df_400, test_df_400])"
      ],
      "metadata": {
        "id": "6QE22QdysFHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we will select only sites (signs from 'site1' to 'site10')\n",
        "\n",
        "sites = ['site' + str(i) for i in range(1, 11)]\n",
        "train_test_df_sites = train_test_df[sites]"
      ],
      "metadata": {
        "id": "9ATS7sbXsLO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace the null with zeros (our sites were numbered from 0)\n",
        "\n",
        "train_test_df_sites.isnull().sum().sum()\n",
        "train_test_df_sites = train_test_df_sites.fillna(0)"
      ],
      "metadata": {
        "id": "yHlPvM6ktvJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we will translate into a sparse csr_matrix format\n",
        "\n",
        "idx_split = train_df_400.shape[0]\n",
        "\n",
        "train_test_sparse = csr_matrix((np.ones(train_test_df_sites.values.size, dtype=np.uint8),\n",
        "                          train_test_df_sites.values.reshape(-1),\n",
        "                          np.arange(train_test_df_sites.values.shape[0] + 1) * train_test_df_sites.values.shape[1]))[:, 1:]\n",
        "X_train_sparse = train_test_sparse[:idx_split, :]\n",
        "X_test_sparse = train_test_sparse[idx_split:, :]\n",
        "y = train_df_400['user_id'].values"
      ],
      "metadata": {
        "id": "kT6J5C5g3JD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Validation by deferred sampling"
      ],
      "metadata": {
        "id": "NXAc-8DIlhD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's select the training (70%) and deferred (30%) parts of the original training sample. We do not mix the data, we take into account that the sessions are sorted by time.**"
      ],
      "metadata": {
        "id": "7jOdT_Sslqop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_share = int(.7 * train_df_400.shape[0])\n",
        "train_df_part = train_df_400[sites].iloc[:train_share, :]\n",
        "valid_df = train_df_400[sites].iloc[train_share:, :]\n",
        "X_train_part_sparse = X_train_sparse[:train_share, :]\n",
        "X_valid_sparse = X_train_sparse[train_share:, :]"
      ],
      "metadata": {
        "id": "sg6xCev4lqUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_part = y[:train_share]\n",
        "y_valid = y[train_share:]\n",
        "y_train_part_for_vw = y_for_vw[:train_share]\n",
        "y_valid_for_vw = y_for_vw[train_share:]"
      ],
      "metadata": {
        "id": "sRYfNMLBlqOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We implement a function, `arrays_to_vw`, which translates the training sample into the Vowpal Wabbit format.**\n",
        "\n",
        "Entrance:\n",
        "- X - matrix `NumPy' (training sample)\n",
        "- y (optional) - response vector (`NumPy`). Optional, since we will process the test matrix with the same function\n",
        "- train - flag, True in the case of a training sample, False in the case of a test sample\n",
        "- out_file – the path to the file .vw to which the recording will be made\n",
        "\n",
        "Details:\n",
        "- it is necessary to go through all the rows of the matrix `X` and write down all the values separated by a space, first adding the necessary class label from the vector `y` and the separator sign `|`\n",
        "- in the test sample, in place of the labels of the target class, you can write arbitrary, for example, 1"
      ],
      "metadata": {
        "id": "uKT8KtmpmOhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def arrays_to_vw(X, y=None, train=True, out_file='tmp.vw'):\n",
        "    X = np.nan_to_num(X)\n",
        "    X = X.astype(int)\n",
        "    \n",
        "    with open(out_file, 'w') as f:\n",
        "        print(X.shape)\n",
        "        for i in range(X.shape[0]):\n",
        "            string =  ' '.join([str(x) for x in X[i]])\n",
        "            if y is None:\n",
        "                f.write(str(1) + \" | \" + string + \"\\n\")\n",
        "            else:\n",
        "                f.write(str(y[i]) + \" | \" + string + \"\\n\")"
      ],
      "metadata": {
        "id": "oy0i-n_fvfpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's apply the written function to the part of the training sample `(train_df_part, y_train_part_for_vw)`, to the deferred sample `(valid_df, y_valid_for_vw)`, to the entire training sample and to the entire test sample. It should be noted that our method accepts matrices and vectors `NumPy` as input**"
      ],
      "metadata": {
        "id": "MCuMlJHOm2-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "arrays_to_vw(train_df_part.values, y_train_part_for_vw, True, os.path.join(PATH_TO_DATA,'train_part.vw'))\n",
        "arrays_to_vw(valid_df.values, y_valid_for_vw, False, os.path.join(PATH_TO_DATA,'valid.vw'))\n",
        "arrays_to_vw(train_df_400[sites].values, y_for_vw, True, os.path.join(PATH_TO_DATA,'train.vw'))\n",
        "arrays_to_vw(test_df_400[sites].values, None, False, os.path.join(PATH_TO_DATA,'test.vw'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0-vNc6lmnAt",
        "outputId": "0422867a-fb16-4e4e-8afb-5c72049f2a2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(127955, 10)\n",
            "(54838, 10)\n",
            "(182793, 10)\n",
            "(46473, 10)\n",
            "CPU times: user 4.03 s, sys: 22.6 ms, total: 4.05 s\n",
            "Wall time: 4.16 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's check the result**"
      ],
      "metadata": {
        "id": "pU487C8boiPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -3 $PATH_TO_DATA/train_part.vw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZgSfyugnDLn",
        "outputId": "4e2cfa8b-fc37-48ba-e01b-5064550d4089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262 | 23713 23720 23713 23713 23720 23713 23713 23713 23713 23713\n",
            "82 | 8726 8725 665 8727 45 8725 45 5320 5320 5320\n",
            "16 | 303 19 303 303 303 303 303 309 303 303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -3  $PATH_TO_DATA/valid.vw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JmIHUfjoSMt",
        "outputId": "aa008f82-e015-4cd0-db6d-2a12f8f56074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 | 7 923 923 923 11 924 7 924 838 7\n",
            "160 | 91 198 11 11 302 91 668 311 310 91\n",
            "312 | 27085 848 118 118 118 118 11 118 118 118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -3 $PATH_TO_DATA/test.vw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJNcljk6olri",
        "outputId": "7dc91fd5-73ad-4331-ee53-02c789177ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 | 9 304 308 307 91 308 312 300 305 309\n",
            "1 | 838 504 68 11 838 11 838 886 27 305\n",
            "1 | 190 192 8 189 191 189 190 2375 192 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's train the Vowpal Wabbit model on a sample of train_part.vw. We indicate that the classification problem with 400 classes (--oaa) is being solved, we will make 3 passes through the sample (--passes). Let's set some cache file (--cache_file, you can just specify the -c flag), so VW will be faster to do all the next passes after the first one (the last cache file is deleted using the -k argument). We also specify the value of the parameter b=26. This is the number of bits used for hashing, in this case you need more than 18 by default. Finally, specify random_seed=17. We are not changing the other parameters yet.**"
      ],
      "metadata": {
        "id": "OOgc6xpnpAnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_part_vw = os.path.join(PATH_TO_DATA, 'train_part.vw')\n",
        "valid_vw = os.path.join(PATH_TO_DATA, 'valid.vw')\n",
        "train_vw = os.path.join(PATH_TO_DATA, 'train.vw')\n",
        "test_vw = os.path.join(PATH_TO_DATA, 'test.vw')\n",
        "model = os.path.join(PATH_TO_DATA, 'vw_model.vw')\n",
        "pred = os.path.join(PATH_TO_DATA, 'vw_pred.csv')"
      ],
      "metadata": {
        "id": "XkkDSLKTooHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!vw --oaa 400 /content/drive/MyDrive/DATA/Stepik/Kaggle/train_part.vw --passes 3 -c -k -b 26 --random_seed 17 -f /content/drive/MyDrive/DATA/Stepik/Kaggle/vw_model.vw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uJwC2m6pLQD",
        "outputId": "54c703ba-10b9-43b7-ca47-75d1d3265909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final_regressor = /content/drive/MyDrive/DATA/Stepik/Kaggle/vw_model.vw\n",
            "Num weight bits = 26\n",
            "learning rate = 0.5\n",
            "initial_t = 0\n",
            "power_t = 0.5\n",
            "decay_learning_rate = 1\n",
            "tcmalloc: large alloc 1073741824 bytes == 0x5596c0ee8000 @  0x7f0c99005001 0x7f0c98ba1b5f 0x7f0c98bafa21 0x7f0c98c52e00 0x7f0c98c40be3 0x7f0c98c48395 0x7f0c98c48c44 0x5596be56c237 0x5596be56ba8b 0x7f0c981c0bf7 0x5596be56c05a\n",
            "creating cache_file = /content/drive/MyDrive/DATA/Stepik/Kaggle/train_part.vw.cache\n",
            "Reading datafile = /content/drive/MyDrive/DATA/Stepik/Kaggle/train_part.vw\n",
            "num sources = 1\n",
            "average  since         example        example  current  current  current\n",
            "loss     last          counter         weight    label  predict features\n",
            "1.000000 1.000000            1            1.0      262        1       11\n",
            "1.000000 1.000000            2            2.0       82      262       11\n",
            "1.000000 1.000000            4            4.0      241      262       11\n",
            "1.000000 1.000000            8            8.0      352      262       11\n",
            "1.000000 1.000000           16           16.0      135       16       11\n",
            "1.000000 1.000000           32           32.0       71      112       11\n",
            "0.968750 0.937500           64           64.0      358      231       11\n",
            "0.976562 0.984375          128          128.0      348      346       11\n",
            "0.941406 0.906250          256          256.0      202      202       11\n",
            "0.947266 0.953125          512          512.0       30        1       11\n",
            "0.925781 0.904297         1024         1024.0       36      290       11\n",
            "0.908203 0.890625         2048         2048.0       21      128       11\n",
            "0.880127 0.852051         4096         4096.0       80      229       11\n",
            "0.856323 0.832520         8192         8192.0      307      356       11\n",
            "0.828003 0.799683        16384        16384.0       59      193       11\n",
            "0.795441 0.762878        32768        32768.0      262       30       11\n",
            "0.760468 0.725494        65536        65536.0      171      238       11\n",
            "0.724008 0.724008       131072       131072.0        6        6       11 h\n",
            "0.697339 0.670672       262144       262144.0       12       12       11 h\n",
            "\n",
            "finished run\n",
            "number of examples per pass = 115160\n",
            "passes used = 3\n",
            "weighted example sum = 345480.000000\n",
            "weighted label sum = 0.000000\n",
            "average loss = 0.661352 h\n",
            "total feature number = 3800280\n",
            "CPU times: user 249 ms, sys: 48.4 ms, total: 297 ms\n",
            "Wall time: 34 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's write down the forecasts on the valid sample.vw in vw_valid_phead.csv.**"
      ],
      "metadata": {
        "id": "0ZUO15-XyDct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!vw -i /content/drive/MyDrive/DATA/Stepik/Kaggle/vw_model.vw -t -d /content/drive/MyDrive/DATA/Stepik/Kaggle/valid.vw -p /content/drive/MyDrive/DATA/Stepik/Kaggle/vw_valid_pred.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPOZUZpRvjry",
        "outputId": "8a759193-6e5e-44c0-8d28-58e509d768af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "only testing\n",
            "predictions = /content/drive/MyDrive/DATA/Stepik/Kaggle/vw_valid_pred.csv\n",
            "Num weight bits = 26\n",
            "learning rate = 0.5\n",
            "initial_t = 0\n",
            "power_t = 0.5\n",
            "using no cache\n",
            "Reading datafile = /content/drive/MyDrive/DATA/Stepik/Kaggle/valid.vw\n",
            "num sources = 1\n",
            "average  since         example        example  current  current  current\n",
            "loss     last          counter         weight    label  predict features\n",
            "1.000000 1.000000            1            1.0        4      188       11\n",
            "1.000000 1.000000            2            2.0      160      220       11\n",
            "0.750000 0.500000            4            4.0      143      143       11\n",
            "0.750000 0.750000            8            8.0      247      247       11\n",
            "0.687500 0.625000           16           16.0      341       30       11\n",
            "0.593750 0.500000           32           32.0      237      237       11\n",
            "0.609375 0.625000           64           64.0      178      178       11\n",
            "0.640625 0.671875          128          128.0      132      228       11\n",
            "0.656250 0.671875          256          256.0       14       14       11\n",
            "0.646484 0.636719          512          512.0      370      370       11\n",
            "0.663086 0.679688         1024         1024.0      189      189       11\n",
            "0.655762 0.648438         2048         2048.0      311      311       11\n",
            "0.657227 0.658691         4096         4096.0      195      318       11\n",
            "0.660156 0.663086         8192         8192.0      171      195       11\n",
            "0.657654 0.655151        16384        16384.0      362       51       11\n",
            "0.655121 0.652588        32768        32768.0      248      248       11\n",
            "\n",
            "finished run\n",
            "number of examples per pass = 54838\n",
            "passes used = 1\n",
            "weighted example sum = 54838.000000\n",
            "weighted label sum = 0.000000\n",
            "average loss = 0.654583\n",
            "total feature number = 603218\n",
            "CPU times: user 87 ms, sys: 31.6 ms, total: 119 ms\n",
            "Wall time: 11.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We count the forecasts of kaggle_data/vw_valid_phead.csv from the file and look at the proportion of correct answers on the deferred part.**"
      ],
      "metadata": {
        "id": "zK9Zv-CkypYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vw_valid = pd.read_csv( os.path.join(PATH_TO_DATA, 'vw_valid_pred.csv'), header=None)"
      ],
      "metadata": {
        "id": "nHcn7KyWyWfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The percentage of correct responses on the deferred sample for Vowpal Wabbit: %f' % accuracy_score(y_valid_for_vw, \n",
        "                                                                                             vw_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ6MNebszGPO",
        "outputId": "4c3d3657-e9af-4e92-e68e-5c84e2125b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage of correct responses on the deferred sample for Vowpal Wabbit: 0.345417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we will train SGDClassifier (3 sample passes, logistic loss function) and LogisticRegression on 70% of the sparse training sample – (X_train_part_sparse, y_train_part), make a forecast for the delayed sample (X_valid_sparse, y_valid) and calculate the proportion of correct answers. Logistic regression will not be trained quickly – this is normal. We will specify random_state=17, n_jobs=-1 everywhere. For SGDClassifier, we will also specify max_iter=3.**"
      ],
      "metadata": {
        "id": "rT-N3ouv0DR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logit = LogisticRegression(random_state=17, n_jobs=-1)\n",
        "sgd_logit =  SGDClassifier(loss='log', random_state=17, max_iter=3)"
      ],
      "metadata": {
        "id": "FU-VyreZzdtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "logit.fit(X_train_part_sparse, y_train_part)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg9Dunr_1hWJ",
        "outputId": "93f0cc15-98fc-46a6-8bee-da0480b97f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.86 s, sys: 289 ms, total: 2.14 s\n",
            "Wall time: 5min 57s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(n_jobs=-1, random_state=17)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "sgd_logit.fit(X_train_part_sparse, y_train_part)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCWmI-fY1kPx",
        "outputId": "76770b2e-8135-40dd-bdf1-0878fac69c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 24.6 s, sys: 6.5 ms, total: 24.6 s\n",
            "Wall time: 24.5 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(loss='log', max_iter=3, random_state=17)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color='red'>Question 1. </font> Calculate the proportion of correct answers on the deferred sample for Vowpal Wabbit, round to 3 decimal places.**\n",
        "\n",
        "**<font color='red'>Question 2. </font> Calculate the proportion of correct answers on the deferred sample for SGD, round to 3 decimal places.**\n",
        "\n",
        "**<font color='red'>Question 3. </font> Calculate the proportion of correct answers on the deferred sample for logistic regression, round to 3 decimal places.**"
      ],
      "metadata": {
        "id": "u8XMV11V2e6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vw_valid_acc = accuracy_score(y_valid_for_vw, vw_valid)\n",
        "sgd_valid_acc = accuracy_score(y_valid, sgd_logit.predict(X_valid_sparse))\n",
        "logit_valid_acc = accuracy_score(y_valid, logit.predict(X_valid_sparse))"
      ],
      "metadata": {
        "id": "Yz3quMYq2lyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_answer_to_file(answer, file_address):\n",
        "    with open(file_address, 'w') as out_f:\n",
        "        out_f.write(str(answer))"
      ],
      "metadata": {
        "id": "m6_u7V-79PWV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_answer_to_file(round(vw_valid_acc, 3), os.path.join(PATH_TO_DATA, 'answer6_1.txt'))\n",
        "write_answer_to_file(round(sgd_valid_acc, 3), os.path.join(PATH_TO_DATA, 'answer6_2.txt'))\n",
        "write_answer_to_file(round(logit_valid_acc, 3), os.path.join(PATH_TO_DATA, 'answer6_3.txt'))"
      ],
      "metadata": {
        "id": "_1Fg-lQz9aqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Валидация по тестовой выборке (Public Leaderboard)"
      ],
      "metadata": {
        "id": "vaWXgGNby3gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's train a VW model with the same parameters on the entire training sample - train.vw.**"
      ],
      "metadata": {
        "id": "NGs_YmsGzHAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!vw --oaa 400 /content/drive/MyDrive/DATA/Stepik/Kaggle/train.vw --passes 3 -c -k -b 26 --random_seed 17 -f /content/drive/MyDrive/DATA/Stepik/Kaggle/vw_model.vw"
      ],
      "metadata": {
        "id": "jpcFkF3a-Jy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "257ebd4a-042e-4c85-ef21-7cace8df1c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final_regressor = /content/drive/MyDrive/DATA/Stepik/Kaggle/vw_model.vw\n",
            "Num weight bits = 26\n",
            "learning rate = 0.5\n",
            "initial_t = 0\n",
            "power_t = 0.5\n",
            "decay_learning_rate = 1\n",
            "tcmalloc: large alloc 1073741824 bytes == 0x56465f178000 @  0x7f5207ec5001 0x7f5207a61b5f 0x7f5207a6fa21 0x7f5207b12e00 0x7f5207b00be3 0x7f5207b08395 0x7f5207b08c44 0x56465e302237 0x56465e301a8b 0x7f5207080bf7 0x56465e30205a\n",
            "creating cache_file = /content/drive/MyDrive/DATA/Stepik/Kaggle/train.vw.cache\n",
            "Reading datafile = /content/drive/MyDrive/DATA/Stepik/Kaggle/train.vw\n",
            "num sources = 1\n",
            "average  since         example        example  current  current  current\n",
            "loss     last          counter         weight    label  predict features\n",
            "1.000000 1.000000            1            1.0      262        1       11\n",
            "1.000000 1.000000            2            2.0       82      262       11\n",
            "1.000000 1.000000            4            4.0      241      262       11\n",
            "1.000000 1.000000            8            8.0      352      262       11\n",
            "1.000000 1.000000           16           16.0      135       16       11\n",
            "1.000000 1.000000           32           32.0       71      112       11\n",
            "0.968750 0.937500           64           64.0      358      231       11\n",
            "0.976562 0.984375          128          128.0      348      346       11\n",
            "0.941406 0.906250          256          256.0      202      202       11\n",
            "0.947266 0.953125          512          512.0       30        1       11\n",
            "0.925781 0.904297         1024         1024.0       36      290       11\n",
            "0.908203 0.890625         2048         2048.0       21      128       11\n",
            "0.880127 0.852051         4096         4096.0       80      229       11\n",
            "0.856323 0.832520         8192         8192.0      307      356       11\n",
            "0.828003 0.799683        16384        16384.0       59      193       11\n",
            "0.795441 0.762878        32768        32768.0      262       30       11\n",
            "0.760468 0.725494        65536        65536.0      171      238       11\n",
            "0.725319 0.690170       131072       131072.0      180      159       11\n",
            "0.692989 0.692989       262144       262144.0       88      221       11 h\n",
            "\n",
            "finished run\n",
            "number of examples per pass = 164514\n",
            "passes used = 3\n",
            "weighted example sum = 493542.000000\n",
            "weighted label sum = 0.000000\n",
            "average loss = 0.642595 h\n",
            "total feature number = 5428962\n",
            "CPU times: user 368 ms, sys: 49.4 ms, total: 417 ms\n",
            "Wall time: 44.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's make a forecast for the test sample.**"
      ],
      "metadata": {
        "id": "iqSXD50X0bIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!vw -t -d /content/drive/MyDrive/DATA/Stepik/Kaggle/test.vw -i /content/drive/MyDrive/DATA/Stepik/Kaggle/vw_model.vw -p /content/drive/MyDrive/DATA/Stepik/Kaggle/vw_test_pred.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QtyYGJE0Kl8",
        "outputId": "6e1175bc-28e4-4ef7-d66a-49a80741b61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "only testing\n",
            "predictions = /content/drive/MyDrive/DATA/Stepik/Kaggle/vw_test_pred.csv\n",
            "Num weight bits = 26\n",
            "learning rate = 0.5\n",
            "initial_t = 0\n",
            "power_t = 0.5\n",
            "using no cache\n",
            "Reading datafile = /content/drive/MyDrive/DATA/Stepik/Kaggle/test.vw\n",
            "num sources = 1\n",
            "average  since         example        example  current  current  current\n",
            "loss     last          counter         weight    label  predict features\n",
            "1.000000 1.000000            1            1.0        1       90       11\n",
            "1.000000 1.000000            2            2.0        1       21       11\n",
            "1.000000 1.000000            4            4.0        1      265       11\n",
            "1.000000 1.000000            8            8.0        1      137       11\n",
            "1.000000 1.000000           16           16.0        1      273       11\n",
            "1.000000 1.000000           32           32.0        1      384       11\n",
            "1.000000 1.000000           64           64.0        1      139       11\n",
            "1.000000 1.000000          128          128.0        1       85       11\n",
            "1.000000 1.000000          256          256.0        1       25       11\n",
            "0.994141 0.988281          512          512.0        1      364       11\n",
            "0.990234 0.986328         1024         1024.0        1      202       11\n",
            "0.992188 0.994141         2048         2048.0        1      181       11\n",
            "0.993652 0.995117         4096         4096.0        1       21       11\n",
            "0.994629 0.995605         8192         8192.0        1      137       11\n",
            "0.995300 0.995972        16384        16384.0        1      326       11\n",
            "0.994568 0.993835        32768        32768.0        1       10       11\n",
            "\n",
            "finished run\n",
            "number of examples per pass = 46473\n",
            "passes used = 1\n",
            "weighted example sum = 46473.000000\n",
            "weighted label sum = 0.000000\n",
            "average loss = 0.994642\n",
            "total feature number = 511203\n",
            "CPU times: user 109 ms, sys: 24.4 ms, total: 134 ms\n",
            "Wall time: 10.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's write the forecast to a file, apply the reverse conversion of labels (there was a LabelEncoder and then +1 in the label) and send the solution to Kaggle.**"
      ],
      "metadata": {
        "id": "ttIuF_MB1PQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_to_submission_file(predicted_labels, out_file,\n",
        "                             target='user_id', index_label=\"session_id\"):\n",
        "    # turn predictions into data frame and save as csv file\n",
        "    predicted_df = pd.DataFrame(predicted_labels,\n",
        "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
        "                                columns=[target])\n",
        "    predicted_df.to_csv(out_file, index_label=index_label)"
      ],
      "metadata": {
        "id": "sHhvIb100xXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vw_pred = pd.read_csv('/content/drive/MyDrive/DATA/Stepik/Kaggle/vw_test_pred.csv', header=None)"
      ],
      "metadata": {
        "id": "-WtutFj11VB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vw_subm = class_encoder.inverse_transform(np.ravel(vw_pred) - 1)"
      ],
      "metadata": {
        "id": "mOrz-VA71v3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_to_submission_file(vw_subm, os.path.join(PATH_TO_DATA, '/content/drive/MyDrive/DATA/Stepik/Kaggle/vw_pred_kaggle.csv'))"
      ],
      "metadata": {
        "id": "UlnFD3x91yiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's do the same for SGD and logistic regression.**"
      ],
      "metadata": {
        "id": "B1mdaMb82PGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_logit = SGDClassifier(loss='log', random_state=17, max_iter=3, n_jobs=-1)\n",
        "sgd_logit.fit(X_train_part_sparse, y_train_part)\n",
        "sgd_logit_test_pred = sgd_logit.predict(X_test_sparse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRZ_WFll2CKs",
        "outputId": "491b7acb-7ae5-45f8-8848-6f50f204588a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit = LogisticRegression(random_state=17, n_jobs=-1, solver = 'lbfgs')\n",
        "logit.fit(X_train_sparse, y)\n",
        "logit_test_pred = logit.predict(X_test_sparse)"
      ],
      "metadata": {
        "id": "8bYbhW6a2X9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_to_submission_file(sgd_logit_test_pred, \n",
        "                         os.path.join(PATH_TO_DATA, '/content/drive/MyDrive/DATA/Stepik/Kaggle/sgd_pred.csv'))\n",
        "write_to_submission_file(logit_test_pred, \n",
        "                         os.path.join(PATH_TO_DATA, '/content/drive/MyDrive/DATA/Stepik/Kaggle/logit_pred.csv'))"
      ],
      "metadata": {
        "id": "UkQByyXg2fKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the proportion of correct answers on the public part (public leaderboard) of the test sample [this](https://www.kaggle.com/c/identify-me-if-you-can4) competitions.\n",
        "\n",
        "**<font color='red'>Question 4. </font> What is the proportion of correct answers on the public part of the test sample (public leaderboard) for Vowpal Wabbit?**\n",
        "\n",
        "**<font color='red'>Question 5. </font> What is the proportion of correct answers on the public part of the test sample (public leaderboard) for SGD?**\n",
        "\n",
        "**<font color='red'>Question 6. </font> What is the proportion of correct answers on the public part of the test sample (public leaderboard) for logistic regression?**"
      ],
      "metadata": {
        "id": "aWiKY1IlOjdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vw_lb_score, sgd_lb_score, logit_lb_score = 0.18164, 0.16994, 0.19060\n",
        "\n",
        "write_answer_to_file(round(vw_lb_score, 3), os.path.join(PATH_TO_DATA,'answer6_4.txt'))\n",
        "write_answer_to_file(round(sgd_lb_score, 3), os.path.join(PATH_TO_DATA,'answer6_5.txt'))\n",
        "write_answer_to_file(round(logit_lb_score, 3), os.path.join(PATH_TO_DATA,'answer6_6.txt'))"
      ],
      "metadata": {
        "id": "0VV7Z8l4KcSU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression showed the best result among the other two algorithms Vowpal Wabbit and SGD, but more time is spent on its training. SGD showed the worst result, but nevertheless he learns quickly. Vowpal Wabbit showed higher quality than SGD.**"
      ],
      "metadata": {
        "id": "Sxu0LKcKLYMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NWKEh34BLanX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}