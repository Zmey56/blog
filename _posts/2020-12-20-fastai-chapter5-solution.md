---
toc: true
layout: post
comments: true
description: Ответы на пятую часть Fast.ai Deep Learning 2020
categories: [markdown, fastai, Russian, Deep Learning]
title: Russian - Fastbook Chapter 5 questionnaire solutions
---
Ответы на русском языке на [вопросы](https://forums.fast.ai/t/fastbook-chapter-5-questionnaire-solutions-wiki/69301) к пятой части курса Deep Learning 2020 на Fast.ai. Если есть притензии к переводу, как и к осталььным частям прошу писать в коментариях - поправлю.

**1. Почему мы сначала изменяем размер до большого размера на процессоре, а затем до меньшего размера на графическом процессоре?**

Эта концепция известна как проклеивание (presizing). Прирост данных часто применяется к изображениям, и на самом деле это делается на графическом процессоре. Однако увеличение объема данных может привести к ухудшению качества и появлению артефактов, особенно на краях. Поэтому, чтобы свести к минимуму ухудшение качества данных, дополнения выполняются на более крупном изображении, а затем выполняется RandomResizeCrop изменение размера до требуемого размера изображения.

**2. Если вы не знакомы с регулярными выражениями, найдите учебник по регулярным выражениям и задач и выполните их.**

Выполняется самостоятельно

**3. Каковы два наиболее распространенных способа предоставления данных для большинства наборов данных глубокого обучения?**

* Отдельные файлы, представляющие элементы данных, такие как текстовые документы или изображения.
* Таблица данных, например в формате CSV, где каждая строка является элементом и может включать имена файлов, обеспечивающие связь между данными в таблице и данными в других форматах, таких как текстовые документы и изображения.

**4. Посмотрите документацию на L и попробуйте использовать несколько новых методов.**

Выполняется [самостоятельно](https://fastcore.fast.ai/#L)

**5. Посмотрите документацию для модуля Python pathlib и попробуйте использовать несколько методов класса Path.**

Выполняется [самостоятельно](https://docs.python.org/3/library/pathlib.html)

**6. Приведите два примера того, как преобразования изображений могут ухудшить качество данных.**

* Вращение может являться причиной пустых областей в конечном изображении
* Другие операции могут потребовать интерполяции, которая основана на исходных пикселях изображения и в результате более низкое качество изображения

**7. Какой метод в fastai для просмотра данных в загрузчике данных (DataLoader)?**

DataLoader.show_batch

**8. Какой метод в fastai, чтобы помочь вам отладить DataBlock?**

DataBlock.summary

**9. Следует ли вам отложить обучение модели до тех пор, пока вы не очистите свои данные полностью?**

Нет. Лучше всего первоначально создать базовую модель.

**10. Что за два метода объединены в кросс-энтропию в PyTorch?**

Кросс энтропийные потери представляет собой комбинацию функции Softmax и отрицательной логарифмической потери правдоподобия.

**11. Каковы два свойства активаций, которые гарантирует softmax? Почему это так важно?**

Выходные данные в сумме дают один и модель может предсказать только один класс. Кроме того, усиливаются небольшие изменения в выходных активациях, что полезно, поскольку это означает, что модель выберет метку с более высокой увереностью (хорошо для проблем с конкретными метками).

**12. Когда вы хотите, чтобы ваши активации не имели этих свойств?**

Когда у вас есть проблемы с классификацией нескольких меток (возможно более одной метки).

**13. Вычислите столбцы exp и softmax.**

ПРОПУЩЕНО

**14. Почему мы не можем использовать torch.where для создания функции потерь для наборов данных, где наша метка может иметь более двух категорий?**

Потому что torch.where может выбирать только между двумя возможностями, в то время как для многоклассовой классификации у нас есть необходимость в выборе нескольких вариантов.

**15. Каково значение log (-2)? Почему?**

Значение не определено. Логарифм является обратной экспоненциальной функцией, а экспоненциальная функция всегда положительна, независимо от того, какое значение передается. Таким образом, логарифм не определен для отрицательных значений.

**16. Каковы два хороших эмпирических правила для выбора скорости обучения при использовании искателя скорости обучения?

Любой из этих двух пунктов должен быть использован для скорости обучения:

* на порядок меньше, чем там, где была достигнута минимальная потеря (то есть минимум, деленный на 10)
* последняя точка, где потеря явно уменьшилась.

**17. Какие два шага делает метод fine_tune?**

* Тренирует новую голову (со случайными весами) в течение одной эпохи
* Разморозет все слои и тренирует их все для требуемого количества эпох

**18. Как получить исходный код метода или функции в Jupyter notebook?**

Использовать ?? после функции. Пример: DataBlock.summary??

**19. Что такое дискриминационные показатели обучения?**

Дискриминативные скорости обучения относятся к тренировочному трюку использования различных скоростей обучения для разных слоев модели. Это обычно используется в трансфертном обучении. Идея заключается в том, что при обучении предварительно подготовленной модели вы не хотите резко менять более ранние слои, поскольку она содержит информацию о простых объектах, таких как ребра и формы. Но более поздние слои могут быть изменены немного больше, поскольку они могут содержать информацию о чертах лица или других объектах, которые могут не иметь отношения к вашей задаче. Таким образом, более ранние слои имеют более низкую скорость обучения, а более поздние слои имеют более высокую скорость обучения.

**20. Как объект slice на языке Python интерпретируется при передаче в качестве скорости обучения в fastai?**

Первое значение объекта среза - это скорость обучения для самого раннего слоя, а второе-скорость обучения для последнего слоя. Промежуточные слои будут иметь скорости обучения, которые мультипликативно равноудалены во всем этом диапазоне.

**21. Почему ранняя остановка является плохим выбором при использовании одного цикла тренировок?**

Если используется ранняя остановка, обучение может не успеть достичь более низких значений скорости на графике, что могло бы способствовать совершенствованию модели. Поэтому рекомендуется переучивать модель и выбирать количество эпох исходя из того, где были найдены предыдущие лучшие результаты.

**22. В чем разница между resnet 50 и resnet101?**

Числа 50 и 101 относятся к числу слоев в моделях. Таким образом, ResNet101-это более крупная модель с большим количеством слоев по сравнению с ResNet50. Эти варианты моделей обычно используются, поскольку существуют модели с предварительно подготовленными весами ImageNet.

**23. Что делает to_fp16?**

Это позволяет проводить обучение со смешанной точностью, в котором для ускорения обучения используются менее точные числа.