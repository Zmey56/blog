---
toc: true
layout: post
comments: true
description: Ответы на восьмую часть Fast.ai Deep Learning 2020
categories: [markdown, fastai, Russian, Deep Learning]
title: Russian - Fastbook Chapter 8 questionnaire solutions
---
Ответы на русском языке на [вопросы](https://forums.fast.ai/t/fastbook-chapter-8-questionnaire-solutions-wiki/69926) к восьмой части курса Deep Learning 2020 на Fast.ai. Если есть притензии к переводу, как и к осталььным частям прошу писать в коментариях - поправлю.

**1. Какую проблему решает коллаборативная фильтрация?**

Она решает задачу прогнозирования интересов пользователей на основе интересов других пользователей и рекомендации на основе этих интересов.

**2. Как она работает?**

Ключевая идея коллаборативной фильтрации-скрытые (латентные) факторы. Идея заключается в том, что модель может сказать, какие предметы вам могут понравиться (например, вам нравятся научно-фантастические фильмы/книги), и эти факторы изучаются (с помощью базового градиентного спуска) на основе того, какие предметы нравятся другим пользователям со схожими интересами.

**3. Почему прогностическая модель коллаборативной фильтрации может быть не очень полезной рекомендательной системой?**

Если для обучения модели не так много рекомендаций или не достаточно данных о пользователе, чтобы дать полезные рекомендации, то такие системы коллаборативной фильтрации могут оказаться бесполезными.

**4. Как выглядит перекрестное представление данных совместной фильтрации?**

В представлении перекрестной таблицы пользователи и элементы представляют собой строки и столбцы (или наоборот) большой матрицы со значениями, заполненными на основе рейтинга элемента выставленного пользователем.

**5. Напишите код для создания перекрестного представления данных MovieLens (возможно, вам придется выполнить некоторый поиск в интернете!)**

Выполняется самостоятельно.

**6. Что такое латентный фактор? Почему он "латентный"?**

Как описано выше, латентный фактор - это факторы, которые важны для прогнозирования рекомендаций, но явно не указаны модели, а вместо этого исследованы (отсюда и “латентные”).

**7. Что такое скалярное произведение? Вычислить скалярное произведение вручную с использованием чистого питона и списков.**

Скалярное произведение - это когда вы умножаете соответствующие элементы двух векторов и складываете их. Если мы представим векторы в виде списков одинакового размера, то вот как мы можем выполнить скалярное произведение:

```python
a = [1, 2, 3, 4]
b = [5, 6, 7, 8]
dot_product = sum(i[0]*i[1] for i in zip(a,b))
```

**8. Что делает *pandas.DataFrame.merge*?**

Он позволяет объединять несколько DataFrame в один.

**9. Что такое матрица эмбедингов?**

Это то, что вы получаете через умножение и в случае совместной фильтрации изучаете.

**10. Какова связь между эмбедингом и матрицей one-hot encoded векторов?**

Эмбединг - это матрица one-hot encoded векторов, которая в вычислительном отношении более эффективна.

**11. Зачем нам нужен эмбендинг, если мы можем использовать one-hot encoded векторы для того же самого?**

Вычислительная эфективность эмбендинга более эфективна. Умножение с помощью one-hot encoded векторов эквивалентно индексации в эмбендинг матрице, что делает эмбендинг слой. Однако градиент вычисляется таким образом, что он эквивалентен умножению с one-hot encoded вектором.

**12. Что содержит эмбендинг перед началом обучения (предполагая, что мы не используем предварительно обученную модель)?**

Эмбендинг инициализируется случайным образом.

**13. Создайте класс (по возможности не подглядывая!) и используйте его.**

Делать это должен читатель. Пример в главе:

```python
class Example:
    def __init__(self, a): self.a = a
    def say(self,x): return f'Hello {self.a}, {x}.'
```

**14. Что возвращает x[:,0]?**

Идентификаторы пользователей

**15. Перепишите класс DotProduct (по возможности не подглядывая!) и обучите с его помощью модель.**

Код, приведенный в главе:
```python
class DotProduct(Module):
    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):
        self.user_factors = Embedding(n_users, n_factors)
        self.movie_factors = Embedding(n_movies, n_factors)
        self.y_range = y_range
        
    def forward(self, x):
        users = self.user_factors(x[:,0])
        movies = self.movie_factors(x[:,1])
        return sigmoid_range((users * movies).sum(dim=1), *self.y_range)
```

**16. Какая неплохая функция потерь используется для MovieLens? Почему?**

Мы можем использовать среднеквадратичную ошибку (MSE), которая является вполне разумной потерей, поскольку у нас в качестве целей используются количественные значения, и данная ошибка позволяет получить точность модели.

**17. Что произойдет, если мы используем CrossEntropy потери в MovieLens? Как нам нужно будет изменить модель?**

Нам нужно было бы обеспечить, чтобы модель выводила 5 прогнозов. Например, с помощью нейросетевой модели нам нужно изменить последний линейный слой, чтобы вывести 5, а не 1, предсказаний. Затем они передаются в CrossEntropy потери.

**18. Что есть использование предвзятости в модели скалярного умножения?**

Предвзятость компенсирует тот факт, что некоторые фильмы просто потрясающие или довольно плохие. Это также компенсирует пользователей, которым свойственно давать больше положительных или отрицательных рекомендаций в целом.

**19. Как еще называется понижение веса?**

L2 регуляризация.

**20. Напишите уравнение для снижения веса (не подглядывая!)**

```
loss_with_wd = loss + wd * (parameters**2).sum()
```

**21. Напишите уравнение для градиента снижения веса. Почему он работает?**

Добавим к градиентам *2\*wd\*parameters*. Это помогает создавать небольшие, менее неровные/островыпуклые поверхности, которые лучше обобщаются и предотвращают переобучение.,,

**22. Почему уменьшение веса приводит к лучшему обобщению?**

Так как оно приведит к более пологим поверхностям, так как более крутые приводят к переобочению.

**23. Что делает argsort в PyTorch?**

Получает индексы в том порядке, в котором сортируется исходный тензор в PyTorch.

**24. Дает ли сортировка предубеждений к фильмам тот же результат, что и усреднение в целом рейтингов фильмов? Почему / почему нет?**

Нет и есть большое отличие. Предубеждение учитывает жанр, актеров или другие факторы. Например, фильмы с низким значением предубеждения означают, что даже если вам нравятся эти типы фильмов, то вам может все равно не понравиться этот фильм из-за других характеристик.

**25. Как вывести на печать имена и детали слоев в модели?**

Просто набрав *learn.model*

**26. Что такое “проблема начальной загрузки(bootstrapping problem)” в коллаборативной фильтрации?**

Что модель / система не может давать никаких рекомендаций или делать какие-либо выводы для пользователей или элементов, о которых она еще не собрала достаточной информации. Это также называется проблемой холодного старта.

**27. Как вы могли бы справиться с проблемой начальной загрузки для новых пользователей? Для новых фильмов?**

Вы можете решить эту проблему, придумав среднее подставляемое значение для пользователя или фильма. Или подобрать среднего пользователя/фильм. Кроме того, вы можете задать несколько вопросов, которые помогут инициализировать векторы внедряемых значений для новых пользователей и фильмов.

**28. Как циклы обратной связи могут влиять на системы коллаборативной фильтрации?**

Рекомендации могут страдать от предвзятости из-за того, что небольшое количество людей сильно влияет на систему. Например: Очень восторженные поклонники аниме, которые оценивают фильмы гораздо чаще, чем другие, могут заставить систему рекомендовать аниме чаще, чем ожидалось (также и для нелюбителей аниме).

**29. При использовании нейронной сети в коллаборативной фильтрации почему у нас может быть разное количество факторов для фильма и пользователя?**

В этом случае мы не берем скалярное произведение, а вместо этого объединяем включаемые матрицы. Поэтому количество факторов может быть разным.

**30. Для чего существует *nn.Sequential* в модели *CollabNN?***

Он позволяет нам соединить несколько слоев nn.Module вместе для использования. В этом случае два линейных слоя соединяются вместе, и включения могут быть непосредственно переданы в линейные слои.

**31. Какую модель следует использовать, если мы хотим добавить метаданные о пользователях и элементах или такую информацию, как дата и время, в модель коллабартивной фильтрации?**

Мы должны использовать табличную модель, которая обсуждается в следующей главе!