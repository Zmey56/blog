---
toc: true
layout: post
comments: true
description: Ответы на четвертую часть Fast.ai Deep Learning 2020
categories: [markdown, fastai, Russian, Deep Learning]
title: Russian - Fastbook Chapter 4 questionnaire solutions
---
Ответы на русском языке на [вопросы](https://forums.fast.ai/t/fastbook-chapter-4-questionnaire-solutions-wiki/67253) к четвертой части курса Deep Learning 2020 на Fast.ai. Напоминаю, что третья часть отдана этики.

**1. Как представлено на компьютере изображение в градиентах серого? Как цветное изображение?**

Изображения представлены массивами со значениями пикселей, представляющими содержимое изображения. Для изображений в оттенках серого используется 2-мерный массив с пикселями, представляющими значения в оттенках серого, в диапазоне от 0 до 256. Значение 0 - белый цвет, а значение 255 - черный, а между ними различные оттенки серого. Для цветных изображений обычно используются три цветовых канала (красный, зеленый, синий), причем для каждого канала используется отдельный 256-диапазонный 2D-массив. Значение пикселя 0 снова представляет белый цвет, а 255 - сплошной красный, зеленый или синий. Три 2-D массива образуют окончательный 3-D массив (тензор ранга 3), представляющий цветное изображение.

**2. Как структурированы файлы и папки в наборе данных MNIST_SAMPLE? Почему?**

Есть две подпапки, train и valid, первая содержит данные для обучения модели, вторая содержит данные для проверки подтверждения модели после каждого шага обучения. Оценка модели на валидационном наборе служит двум целям: а) сообщить о такой интерпретируемой человеком метрике, как точность (в отличие от часто абстрактных функций потерь, используемых для обучения), б) облегчить обнаружение переобучения путем оценки модели на наборе данных, на котором она не была обучена (короче говоря, модель переобучения работает все лучше на обучающем наборе, но все меньше на валидационном наборе). Конечно, каждый практик мог генерировать свои собственные тренировочные / валидационые разделения данных. Общедоступные наборы данных обычно предварительно разделяются для упрощения сравнения результатов между реализациями/публикациями.

Каждая подпапка имеет две подпапки 3 и 7, которые содержат файлы ф формате jpg для соответствующего класса изображений. Это распространенный способ организации наборов данных, состоящих из изображений. Для полного набора данных MNIST существует 10 подпапок, по одной для изображений каждой цифры.

**3. Объясните, как работает подход ”пиксельного сходства (pixel similarity)" к классификации цифр.**

В подходе "сходства пикселей" мы генерируем образец для каждого класса, который хотим идентифицировать. В нашем случае мы хотим отличить изображения трех от изображений семи. Мы определяем образец трех как среднее значение по пикселям всех трех в обучающем наборе. Аналогично для семерки. Вы можете визуализировать два образца и увидеть, что они на самом деле являются размытыми версиями чисел, которые они представляют.
Чтобы определить, является ли ранее нерассматриваемое изображение 3 или 7, мы вычисляем его расстояние до двух образцов (здесь: средняя абсолютная разница в пикселях). Мы говорим, что новый образ-это 3, если его расстояние до образца трех меньше, чем ддля образца семи.

**4. Что такое представление списков (list comprehension)? Теперь создайте тот, который выбирает нечетные числа из списка и удваивает их.**

Списки (массивы на других языках программирования) часто генерируются с помощью цикла for. Представление списков (list comprehension) - это Питонический способ конденсирования создания списка с помощью цикла for в одно выражение. редставление списков (list comprehension) также часто будет включать условия для фильтрации.

```python
lst_in = range(10)
lst_out = [2*el for el in lst_in if el%2==1]
# is equivalent to:
lst_out = []
for el in lst_in:
   if el%2==1:
       lst_out.append(2*el)
```

**5. Что такое "тензор ранга 3"?**

Ранг тензора-это число измерений, которые он имеет. Простой способ определить ранг - это количество индексов, которые вам понадобятся для ссылки на число внутри тензора. Скаляр может быть представлен как тензор ранга 0 (без индекса), вектор может быть представлен как тензор ранга 1 (один индекс, например, v[i]), матрица может быть представлена как тензор ранга 2 (два индекса, например,a[i, j]), а тензор ранга 3-это кубоид или “стек матриц” (три индекса, например,b[i,j, k]). В частности, ранг тензора не зависит от его формы или размерности, например, тензор формы 2x2x2 и тензор формы 3x5x7 имеют ранг 3.
Обратите внимание, что термин “ранг” имеет различные значения в контексте тензоров и матриц (где он относится к числу линейно независимых векторов столбцов).

**6. В чем разница между тензорным рангом и формой (shape)?**

Ранг - это число осей или измерений в Тензоре; форма (shape)-размер каждой оси тензора.

*Как вы получаете ранг от формы?*

Длина формы тензора - это его ранг.

Итак, если у нас есть изображения папки 3 из набора данных MINST_SAMPLE в Тензоре под названием stacked_threes, и мы находим его форму вот так.

```python
In [ ]: stacked_threes.shape
Out[ ]: torch.Size([6131, 28, 28])
```

Нам просто нужно найти его длину, чтобы узнать его ранг. Это делается следующим образом.

```python
In [ ]: len(stacked_threes.shape)
Out[ ]: 3
```

Вы также можете получить ранг тензора непосредственно с помощью ndim.

```python
In [ ]: stacked_threes.ndim
Out[ ]: 3
```

**7. Что такое норма RMSE и L1?**

Среднеквадратичная ошибка (RMSE), также называемая нормой L2, и средняя абсолютная разность (MAE), также называемая нормой L1, являются двумя широко используемыми методами измерения “расстояния”. Простые вычитания не работают, потому что некоторые различия положительны, а другие отрицательны и в результате они отменяют друг друга. Поэтому для правильного измерения расстояний необходима функция, которая фокусируется на величинах разностей. Проще всего было бы сложить абсолютные значения разностей, что и есть MAE. RMSE берет среднее значение квадрата (делает все положительным), а затем берет квадратный корень (отменяет возведение в квадрат).

**8. Как вы можете выполнить вычисление на тысячах чисел одновременно, во много тысяч раз быстрее, чем цикл на Python?**

Поскольку циклы в Python очень медленные, лучше всего представлять операции как операции массива, а не циклически перебирать отдельные элементы. Если это можно сделать, то использование NumPy или PyTorch будет в тысячи раз быстрее, так как они используют базовый код C, который намного быстрее, чем чистый Python. Еще лучше то, что PyTorch позволяет запускать операции на GPU, которые будут иметь значительное ускорение, если есть параллельные операции, которые можно выполнить.

**9. Создайте тензор 3x3 или массив, содержащий числа от 1 до 9. Удвоьте его. Выберите в правом нижнем углу 4 цифры.**

```python
    In [ ]: a = torch.Tensor(list(range(1,10))).view(3,3); print(a)
    Out [ ]: tensor([[1., 2., 3.],
                     [4., 5., 6.],
                     [7., 8., 9.]])
    In [ ]: b = 2*a; print(b)
    Out [ ]: tensor([[ 2.,  4.,  6.],
                     [ 8., 10., 12.],
                     [14., 16., 18.]])
    In [ ]:  b[1:,1:]
    Out []: tensor([[10., 12.],
                    [16., 18.]])
```

**10. Что такое бродкастинг?**

Бродкастинг (broadcasting) - Научные / числовые пакеты Python, такие как NumPy и PyTorch, часто реализуют бродкастинг, который часто облегчает написание кода. В случае PyTorch тензоры с меньшим рангом расширяются, чтобы иметь тот же размер, что и тензор большего ранга. Таким образом, операции могут выполняться между тензорами с различным рангом.

**11. Обычно метрики рассчитываются с использованием обучающего набора или набора проверки? Почему?**

Метрики обычно рассчитываются на основе набора валидации. Поскольку набор валидации является данными, которые не использовались для обучения модели, оценка метрик в наборе валидации лучше для того, чтобы определить, есть ли какое-либо переобучение и насколько хорошо модель могла бы обобщить, если бы ей были даны аналогичные данные.

**12. Что такое SGD?**

SGD, или стохастический градиентный спуск, - это алгоритм оптимизации. В частности, SGD-это алгоритм, который будет обновлять параметры модели для того, чтобы минимизировать заданную функцию потерь, которая была оценена по прогнозам и цели. Ключевая идея SGD (и многих алгоритмов оптимизации, если на то пошло) заключается в том, что градиент функции потерь дает представление о том, как эта функция потерь изменяется в пространстве параметров, которое мы можем использовать, чтобы определить, как лучше всего обновить параметры, чтобы минимизировать функцию потерь. Это то, что делает SGD.

**13. Почему SGD использует мини-пакеты?**

Нам нужно вычислить нашу функцию потерь (и наш градиент) на одной или нескольких точках данных. Мы не можем рассчитывать на всех наборах данных из-за компьютерных ограничений и ограничений по времени. Однако если мы будем перебирать каждую точку данных, градиент будет неустойчивым и неточным и не пригодным для обучения. В качестве компромисса мы рассчитываем средние потери для небольшого подмножества набора данных за один раз. Это подмножество называется мини-пакетом. Использование мини-пакетов также более эффективно с вычислительной точки зрения, чем отдельные элементы на графическом процессоре.

**14. Какие 7 шагов в SGD машинного обучения?**

1. Инициализируйте параметры-случайные значения часто работают лучше всего.
2. Рассчитать прогнозы-это делается на тренировочном наборе, по одному мини-пакету за раз.
3. Вычислить потери – вычисляется средняя потеря по минипакету**
4. Вычисление градиентов-это аппроксимация того, как должны изменяться параметры, чтобы минимизировать функцию потерь
5. Шаг Весов-обновление параметров на основе вычисленных Весов
6. Повторить процесс
7. Остановка-на практике это либо основано на временных ограничениях, либо обычно основано на том, когда потери в обучении/валидации и показатели перестают улучшаться.

**15. Как мы инициализируем веса в модели?**

Случайные веса работают довольно хорошо.

**16. Что такое "потеря"?**

Функция потерь будет возвращать значение, основанное на заданных прогнозах и целевых показателях, где более низкие значения соответствуют лучшим прогнозам модели.

**17. Почему мы не можем всегда использовать высокую скорость обучения?**

Потери могут "отскакивать" вокруг (колебаться) или даже расходиться, так как оптимизатор делает слишком большие шаги и обновляет параметры быстрее, чем это должно быть.

**18. Что такое "градиент"?**

Градиенты говорят нам, насколько мы должны изменить каждый вес, чтобы сделать нашу модель лучше. По сути, это мера того, как изменяется функция потерь при изменении Весов модели (производной).

**19. Вам нужно знать, как самостоятельно вычислять градиенты?**

Ручной расчет градиентов не требуется, так как библиотеки глубокого обучения автоматически рассчитают градиенты для вас. Эта функция известна как автоматическая дифференциация. В PyTorch, если requires_grad=True, градиенты могут быть возвращены  методом обратного вызова: a.backward()

**20. Почему мы не можем использовать точность как функцию потерь?**

Функция потерь должна изменяться по мере корректировки Весов. Точность меняется только в том случае, если меняются предсказания модели. Таким образом, если в модели есть небольшие изменения, которые, скажем, повышают уверенность в предсказании, но не изменяют предсказание, точность все равно не изменится. Таким образом, градиенты будут равны нулю везде, кроме тех случаев, когда фактические прогнозы изменяются. Таким образом, модель не может учиться на градиентах, равных нулю, и веса модели не будут обновляться и не будут обучаться. Хорошая функция потерь дает немного лучшие потери, когда модель дает немного лучшие прогнозы. Немного лучшие предсказания означают, что модель более уверена в правильности предсказания. Например, предсказание 0,9 против 0,7 для вероятности того, что изображение MNIST является 3, было бы немного лучшим предсказанием. Функция потерь должна отражать это.

**21. Нарисуйте сигмовидную функцию. Что особенного в ее форме?**

![](/images/sigmoid.png)

Сигмоидная функция-это гладкая кривая у которой все значения лежат между 0 и 1. У функций потерь значения вероятности или доверительного уровня лежат между 0 и 1, поэтому на конце модели используется сигмоидная функция.

**22. В чем разница между потерями и метриками?**

Ключевое различие заключается в том, что метрики служат для человеческого понимания, а потери - автоматизированного обучения. Чтобы потеря была полезна для обучения, она должна иметь значимую производную. Многие показатели, такие как например точность, не подходят. Метрики в свою очередь это цифры которые волнуют людей и отражают производительность модели.
 
**23. Что является функцией для вычисления новых весов с использованием скорости обучения?**
 
Функция оптимизации шага
 
**24. Что класс DataLoader делает?**
 
 Класс DataLoader может взять любую коллекцию Python и превратить ее в итератор для пакетов.
 
 **25. Напишите псевдокод, показывающий основные шаги, предпринятые каждой эпохой для SGD.**
 
```python
 for x,y in dl:
   pred = model(x)
   loss = loss_func(pred, y)
   loss.backward()
   parameters -= parameters.grad * lr
```

**26. Создайте функцию, которая при передаче двух аргументов [1,2,3,4] и ‘abcd’ возвращает [(1, ‘a’), (2, ‘b’), (3, ‘c’), (4, ‘d’)] . Что особенного в этой структуре выходных данных?**

```python
def func(a,b): return list(zip(a,b))
```
Эта структура данных полезна для моделей машинного обучения, когда вам нужны списки кортежей, где каждый кортеж будет содержать входные данные и метку.
 
**27. Что делает *view* в *PyTorch*?**

Он изменяет форму тензора, не изменяя его содержания.

**28. Какая функция у параметра "смещения(bias)" в нейронной сети? Зачем он нам нужен?
 
Без параметров смещения, если на вход подается нуль, выход всегда будет равен нулю. Поэтому использование параметров смещения добавляет модели дополнительную гибкость.

**29. Что оператор @ делает в python?**

Это оператор умножения матриц.

**30. Что делает метод *backward* делает?**

Этот метод возвращает текущие градиенты.

**31. Почему мы должны обнулять градиенты?**

PyTorch будет добавлять градиенты переменных в любые из ранее сохраненных градиентов. Если функция цикла обучения вызывается несколько раз, не обнуляя градиенты, градиент текущих потерь будет добавлен к ранее сохраненному значению градиента.

**32. Какую информацию мы должны передать *Learner*?**

Нам нужно передать DataLoader, модель, функцию оптимизации, функцию потерь и, возможно, метрики для вывода.

**33. Покажите python или псевдокод для основных шагов обучающего цикла.**

```python
def train_epoch(model, lr, params):
    for xb,yb in dl:
        calc_grad(xb, yb, model)
        for p in params:
            p.data -= p.grad*lr
            p.grad.zero_()
for i in range(20):
    train_epoch(model, lr, params)
```

**34. Что такое "ReLU"? Нарисуйте график для значений от -2 до +2.**

ReLU просто означает "заменить любые отрицательные числа нулем". Это обычно используемая функция активации.

![](/images/relu.png)

**35. Что такое "функция активации"?**

Функция активации-это еще одна функция, входящая в состав нейронной сети, цель которой-обеспечить нелинейность модели. Идея состоит в том, что без функции активации есть несколько линейных функций вида y=mx+b. Однако ряд линейных слоев эквивалентен одному линейному слою, поэтому наша модель может подогнать только линию к данным. Вводя нелинейность между линейными слоями,это уже не так. Каждый слой несколько отделен от остальных слоев, и теперь модель может соответствовать гораздо более сложным функциям. На самом деле можно математически доказать, что такая модель может решить любую вычислимую задачу с произвольно высокой точностью, если модель достаточно велика с соответствующими весами. Это известно как универсальная аппроксимационная теорема.

**36. В чем разница между *F.relu* и *nn.ReLU*?

F.relu - это функция Python для активации relu. С другой стороны, nn.ReLU-это модуль PyTorch. Это означает, что класс Python может быть вызван как функция таким же образом, как и F.relu.

**37. Универсальная аппроксимационная теорема показывает, что любая функция может быть аппроксимирована настолько близко, насколько это необходимо, используя только одну нелинейность. Так почему же мы обычно используем больше?

Использование более чем одной нелинейности дает практические преимущества. Мы можем использовать более глубокую модель с меньшим количеством параметров, лучшей производительностью, более быстрым обучением и меньшими требованиями к вычислениям и памяти.